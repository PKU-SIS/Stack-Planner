import json
import os
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Annotated, Any, Dict, List, Literal, Optional, Type, Union, cast

from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.runnables import RunnableConfig
from langgraph.types import Command

from src.agents.sub_agent_registry import get_sub_agents_by_global_type
from src.config.agents import AGENT_LLM_MAP
from src.llms.llm import get_llm_by_type
from src.memory import MemoryStack, MemoryStackEntry
from src.prompts.template import apply_prompt_template, get_prompt_template
from src.utils.json_utils import repair_json_output
from src.utils.logger import logger
from src.utils.statistics import global_statistics
# from src.prompts.central_decision import Decision, DelegateParams
from src.utils.reference_utils import global_reference_map
from ..graph.types import State
# from .SubAgentConfig import get_sub_agents_by_global_type
# from src.factstruct.llm_wrapper import FactStructLLMWrapper
# from src.factstruct.batch_mab import BatchMAB
# from src.factstruct.outline_node import OutlineNode
from src.factstruct import FactStructLLMWrapper, BatchMAB, OutlineNode, create_search_engine_adapter,Embedder



from src.utils.statistics import global_statistics, timed_step

# -------------------------
# æ ¸å¿ƒæšä¸¾å®šä¹‰
# -------------------------
class OutlineTool(Enum):
    """Outline Agent å¯æ‰§è¡Œçš„ç»“æ„æ€§å·¥å…·"""

    INITIALIZATION = "initialization"
    EXPANDATION = "expandation"
    REDUCTION = "reduction"
    REFLECT = "reflect"
    FINISH = "finish"



# -------------------------
# ä¸­æ¢Agentæ ¸å¿ƒæ¨¡å—--ä¸­æ¢Agentçš„action
# exp: ä¸prompt/Outline_decision.pyä¸­çš„Decisionç±»ä¸åŒçš„æ˜¯ï¼Œé‚£é‡Œæ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œè¿™é‡Œæ˜¯æšä¸¾ç±»å‹ï¼Œæ‰€ä»¥è¦å®šä¹‰ä¸¤æ¬¡
# -------------------------
@dataclass
class OutlineToolDecision:
    """Outline Agent çš„å†³ç­–ç»“æœ"""

    tool: OutlineTool                 # ä½¿ç”¨çš„å·¥å…·
    reasoning: str                    # ä¸ºä»€ä¹ˆè¿™ä¹ˆåš
    params: Optional[Dict[str, Any]]  # å·¥å…·å‚æ•°ï¼ˆå„ tool è‡ªå·±è§£é‡Šï¼‰



#ä¸çŸ¥é“ä¸ºå•¥è¦ä¸¤ä¸ªï¼Œé‚£å°±å®ç°æˆä¸¤ä¸ªå§
from pydantic import BaseModel

class OutlineToolDecision_Base(BaseModel):
    tool: Literal[
        "initialization",
        "expandation",
        "reduction",
        "reflect",
        "finish",
    ]
    reasoning: str
    params: Optional[Dict[str, Any]] = None





class OutlineAgent:
    """
    å¤§çº²Agentæ ¸å¿ƒç±»ï¼Œè´Ÿè´£å¤§çº²å†³ç­–ä¸ä»»åŠ¡ç¼–æ’
    """
    
    def __init__(
        self,
        initial_query: str,
        central_guidance: str | None = None,
        state: State | None = None,
        llm=None,#è¿™ä¸‰ä¸ªå°±æ˜¯ None
        search_engine=None,
        embedder=None,
        max_trys: int = 5,#è¿™ä¸¤ä¸ªæ˜¯é»˜è®¤å‚æ•°
    ):
        #å¤„ç†ä¸Šæ¸¸è¾“å…¥ä¿¡æ¯
        # --- Core task signal ---
        self.initial_query = initial_query
        # --- High-level planning signals ---
        self.central_guidance = central_guidance
        self.replan_result = state.get("replan_result")
        self.total_word_limit = state.get("total_word_limit")
        
        
        #å¤„ç†å½“å‰çŠ¶æ€ï¼Œè¿™ç©æ„æ˜¯ä¸æ˜¯åº”è¯¥æ”¾åˆ° decision é‡Œé¢ä¹Ÿè¦å•Š
        # --- Current outline state ---
        self.factstruct_outline = state.get("factstruct_outline")
        self.factstruct_memory = state.get("factstruct_memory")
        self.outline_feedback = state.get("outline_feedback")
        self.max_trys = max_trys

        
        # === Search Engine ===
        self.search_engine = (search_engine or create_search_engine_adapter())

        # === Embedderï¼ˆé‡èµ„æºï¼Œåªåˆå§‹åŒ–ä¸€æ¬¡ï¼‰===
        self.embedder = (embedder or Embedder(model_name="../../Model/MiniLM/all-MiniLM-L6-v2"))


        # === LLM ===
        if llm is None:
            llm_type = AGENT_LLM_MAP.get("outline", "basic")
            self.llm = get_llm_by_type(llm_type)
        else:
            self.llm = llm
            
        self.llm_wrapper = FactStructLLMWrapper(self.llm)
        
        
        # --- Batch MABï¼ˆæ ¸å¿ƒï¼‰---
        self.batch_mab = BatchMAB(
            llm_wrapper=self.llm_wrapper,
            embedder=self.embedder,
            search_engine=self.search_engine,
            max_iterations=4,
            batch_size=2,
        )

        # --- Tool handlers ---
        self.tool_handlers = {
            "initialization": self._tool_initialization,
            "expandation": self._tool_expansion,
            # "reduction": self._tool_reduction,#æœªå®ç°ï¼Œæš‚æ—¶æ³¨é‡Š
            # "reflect": self._tool_reflect,#æœªå®ç°ï¼Œæš‚æ—¶æ³¨é‡Š
            "finish": self._tool_finish,
        }


    async def execute(self, state: State, config: RunnableConfig) -> Command:
        """
        OutlineAgent çš„ä¸»å¾ªç¯ï¼š
        decision â†’ tool â†’ state update â†’ until finish
        """
        logger.info("OutlineAgent æ‰§è¡Œå¼€å§‹")
        #ä¸‡ä¸€æœ‰æŠ¥é”™ä¿¡æ¯
        last_decision = None
        last_error = None

        for step in range(self.max_trys):
            logger.info(f"OutlineAgent Step {step + 1}/{self.max_trys}")#ä¸€å…±è¿­ä»£äº†å¤šå°‘æ­¥

            try:
                # === 1. å†³ç­– ===
                decision = self.make_decision(state, config)
                last_decision = decision

                logger.info(f"OutlineAgent Decision: {decision.tool} | {decision.reasoning}")

                # === 2. æ‰§è¡Œå·¥å…· ===
                command = await self.execute_tool(decision, state, config)
            
                # === 3. åˆå¹¶ state ===
                if command and command.update:
                    state.update(command.update)
                
                # === 4. æ˜¯å¦å®Œæˆ ===
                if decision.tool == "finish":
                    logger.info("OutlineAgent æ”¶åˆ° finish æŒ‡ä»¤ï¼Œé€€å‡ºå¾ªç¯")
                    break
                
            except Exception as e:
                import traceback

                logger.error("OutlineAgent æ‰§è¡Œå¼‚å¸¸")
                logger.error(traceback.format_exc())
                last_error = str(e)
                break

        # =========================
        # === ç»Ÿä¸€ç»“æœæ•´ç†é˜¶æ®µ ===
        # =========================
        factstruct_outline = state.get("factstruct_outline")
        factstruct_memory = state.get("factstruct_memory")
        report_outline = state.get("report_outline")
        if not report_outline: #æ²¡æœ‰å¤§çº²çš„æƒ…å†µä¸‹è¦åé¦ˆ
            report_outline = "å¤§çº²æœªå®Œæˆç”Ÿæˆï¼ˆOutlineAgent æœªæ­£å¸¸ finishï¼‰"
            state["report_outline"] = report_outline
  
            
        return Command(
            update={
                "factstruct_outline": state.get("factstruct_outline"),
                "factstruct_memory": state.get("factstruct_memory"),
                "report_outline": state.get("report_outline"),
            }
        )





    def make_decision(
        self, state: State, config: RunnableConfig, retry_count: int = 0
    ) -> OutlineToolDecision:
        """
        ä¸­æ¢Agentå†³ç­–æ ¸å¿ƒé€»è¾‘ï¼Œåˆ†æå½“å‰çŠ¶æ€ç”Ÿæˆå†³ç­–ç»“æœ

        Args:
            state: å½“å‰ç³»ç»ŸçŠ¶æ€
            config: è¿è¡Œé…ç½®

        Returns:
            å†³ç­–ç»“æœå¯¹è±¡
        """
        max_retries = 3
        logger.info("Outline Agentè¿›è¡Œå†³ç­–...")
        start_time = datetime.now()

        # æ„å»ºå†³ç­–prompt
        messages = self._build_decision_prompt(state, config)
        logger.debug(f"outline å†³ç­–prompt: {messages}")


        try:
            llm = get_llm_by_type(
                AGENT_LLM_MAP.get("outline", "default")
            ).with_structured_output(
                OutlineToolDecision_Base,   # âœ… ç»™ LLM ç”¨çš„ schema
                method="json_mode",
            )

            response: OutlineToolDecision_Base = llm.invoke(messages)

            logger.info(f"Outline å†³ç­–ç»“æœ(raw): {response}")

            # âœ… ä» LLM åè®®å¯¹è±¡ â†’ ç³»ç»Ÿå†…éƒ¨å¯¹è±¡
            decision = OutlineToolDecision(
                tool=response.tool,
                reasoning=response.reasoning,
                params=response.params,
            )

            end_time = datetime.now()
            global_statistics.add_time_entry(
                {
                    "step_name": "outline_decision",
                    "start_time": start_time.isoformat(),
                    "end_time": end_time.isoformat(),
                    "duration": (end_time - start_time).total_seconds(),
                }
            )

            return decision

        except Exception as e:
            import traceback

            logger.error(
                f"Outline å†³ç­–è§£æå¤±è´¥ (å°è¯• {retry_count + 1}/{max_retries}): {e}"
            )
            logger.error(traceback.format_exc())

            if retry_count < max_retries - 1:
                return self.make_decision(state, config, retry_count + 1)

            # ğŸš¨ å…œåº•ï¼šå¼ºåˆ¶ finishï¼Œé˜²æ­¢ç³»ç»Ÿå¡æ­»
            return OutlineToolDecision(
                tool="finish",
                reasoning="Outline decision parsing failed repeatedly, forcing termination.",
                params=None,
            )


    def _build_decision_prompt(
        self,
        state: State,
        config: RunnableConfig,
    ) -> List[Union[AIMessage, HumanMessage]]:
        """
        æ„å»º Outline Agent çš„å†³ç­– prompt
        """

        context = {
            # å¿…é¡»é¡¹
            "user_query": state.get("initial_query"),

            # å¯é€‰é¡¹ï¼ˆprompt é‡Œæœ‰ if åˆ¤æ–­ï¼‰
            "central_guidance": state.get("central_guidance"),
            "factstruct_outline": state.get("factstruct_outline"),
            "total_word_limit": state.get("total_word_limit"),
            "outline_feedback": state.get("outline_feedback"),
        }

        # åˆå¹¶ configï¼ˆå¦‚éœ€è¦ï¼‰
        context = {**context, **config}

        return apply_prompt_template(
            "outline_decision",   # âœ… å¯¹åº” src/prompts/outline_decision.md
            state,
            extra_context=context,
        )


    def execute_tool(
        self,
        decision: OutlineToolDecision,
        state: State,
        config: RunnableConfig,
    ) -> Command:
        """
        æ ¹æ® Outline Agent çš„ tool å†³ç­–ï¼Œè°ƒç”¨å¯¹åº”çš„ outline å·¥å…·å‡½æ•°
        """

        tool_name = decision.tool
        handler = self.tool_handlers.get(tool_name)

        if not handler:
            error_msg = f"æœªçŸ¥ outline tool: {tool_name}"
            logger.error(error_msg)
            #è¿™ä¸ªåœ°æ–¹è¦ä¸è¦è¿™ä¹ˆè·³ï¼Œè¿˜ä¸ä¸€å®šï¼Œè¿˜éœ€è¦å†çœ‹ä¸€çœ‹
            return Command(
                update={
                    "messages": [
                        AIMessage(
                            content=f"é”™è¯¯ï¼šæœªçŸ¥ outline tool: {tool_name}",
                            name="outline_error",
                        )
                    ],
                    "current_node": "central_agent",
                },
                goto="central_agent",
            )


        logger.info(
            f"Outline Agent æ‰§è¡Œå·¥å…·: {tool_name}, params={decision.params}"
        )

        return handler(
            decision=decision,
            state=state,
            config=config,
        )


    def _tool_initialization(
        self,
        decision: OutlineToolDecision,
        state: State,
        config: RunnableConfig,
    ) -> Command:
        """
        åˆå§‹åŒ–å¤§çº²ç»“æ„ï¼ˆinitialization toolï¼‰
        """
        logger.info("Outline Tool: initialization")

        initial_query = state["initial_query"]
        central_guidance = state.get("central_guidance")
        replan_result = state.get("replan_result")
        factstruct_outline = state.get("factstruct_outline")
        initial_docs = state.get("initial_docs")
        
        #æå–decisionå½“ä¸­çš„å‚æ•°
        params = decision.params or {}
        instruction=params.get("instruction",None)

        # å·²æœ‰ outlineï¼Œä¸åº”å†æ¬¡åˆå§‹åŒ–
        if factstruct_outline is not None:
            logger.warning("Outline already exists, skip initialization.")
            return Command(
                update={
                    "outline_feedback": "Initialization skipped: outline already exists."
                },
            )

        # --- Step 1: åˆå§‹æ£€ç´¢ ---
        if initial_docs is None:
            logger.info("å¼€å§‹é¢„æ£€ç´¢")
            initial_docs = self.search_engine(initial_query, k=5, config=config)

        # --- Step 2: å‘é‡åŒ– ---
        initial_docs_with_embed = self.embedder.embed_docs(initial_docs)

        # --- Step 3: å­˜å…¥ FactStruct Memory ---
        self.factstruct_memory.store_docs(initial_docs_with_embed)

        # --- Step 4: ç”Ÿæˆåˆå§‹å¤§çº² ---
        logger.info("Generating initial outline...")
        self.outline_root = self.llm_wrapper.generate_initial_outline(
            query=initial_query,
            docs=initial_docs_with_embed,
            central_guidance=central_guidance,
            replan_result=replan_result,
            instruction=instruction,
        )

        logger.info(f"Generated outline root id: {self.outline_root.id}")

        # --- Step 5: æ–‡æ¡£ç»‘å®š ---
        self.factstruct_memory.map_node_to_docs(self.outline_root.id, initial_docs_with_embed)

        # --- Step 6: æ—¥å¿— ---
        try:
            from .integration import outline_node_to_markdown
            logger.info("Initial Outline:\n"+ outline_node_to_markdown(self.outline_root, include_root=True))
        except Exception:
            logger.info(self.outline_root.to_text_tree())

        # --- Step 7: æ›´æ–°çŠ¶æ€å¹¶å›åˆ° outline agent ---
        return Command(
            update={
                "factstruct_outline": self.outline_root,
                "factstruct_memory":self.factstruct_memory,
                "initial_docs": initial_docs,
                "outline_tool_feedback": "Outline initialized successfully.",
            },
        )

    def _tool_expansion(
        self,
        decision: OutlineToolDecision,
        state: State,
        config: RunnableConfig,
    ) -> Command:
        """
        æ‰©å±•ç°æœ‰å¤§çº²ï¼ˆBatch-MAB é©±åŠ¨ï¼‰
        """
        logger.info(f"Outline Tool: expansion | reasoning={decision.reasoning}")


        outline_root = state.get("factstruct_outline")
        memory = state.get("factstruct_memory")
        #é”™è¯¯æ’æŸ¥ï¼Œé˜²æ­¢æ²¡åˆå§‹åŒ–
        if outline_root is None or memory is None:
            logger.warning("Expansion skipped: outline or memory missing")
            return Command(
                update={
                    "outline_feedback": "Expansion skipped: outline or memory missing."
                }
            )



        #æå– decision å‚æ•°
        params = decision.params or {}
        max_iterations = params.get("max_iterations",state.get("factstruct_max_iterations", 4),)
        batch_size = params.get("batch_size",state.get("factstruct_batch_size", 2),)
        logger.info(f"Expansion params resolved: max_iterations={max_iterations}, batch_size={batch_size}")
        
        

        try:
            # === è°ƒç”¨ç®—æ³•å±‚ ===
            outline_root, memory = self.batch_mab.run_expansion(
                outline_root=outline_root,
                memory=memory,
                max_iterations=max_iterations,
                batch_size=batch_size,
                config=config,
            )

            logger.info(
                f"Outline expanded: {len(outline_root.get_all_nodes())} nodes total"
            )
            
            #æš‚æ—¶åœ¨è¿™é‡Œæ”¾ä¸€ä¸ªå¤§çº²å­—æ•°åŒ¹é…å§
            total_word_limit = state.get("total_word_limit", 5000)
            if total_word_limit > 0:
                logger.info(f"æ£€æµ‹åˆ°å­—æ•°é™åˆ¶ {total_word_limit}ï¼Œæ‰§è¡Œå­—æ•°è§„åˆ’...")
                outline_root = self.execute_word_planning(
                    outline_root, total_word_limit
                )
                outline_response = outline_root.to_text_tree(
                    include_word_limit=True
                )
            else:
                outline_response = outline_node_to_markdown(
                    outline_root, max_depth=None, include_root=True
                )

            factstruct_outline_dict = outline_node_to_dict(outline_root)
            factstruct_memory_dict = memory_to_dict(memory)

            logger.info(f"FactStruct Stage 1 å®Œæˆ: "f"{len(outline_root.get_all_nodes())} ä¸ªèŠ‚ç‚¹")

            return Command(
                update={
                    "factstruct_outline": outline_root,
                    "factstruct_memory": memory,
                    "outline_feedback": "Outline expansion completed successfully.",
                }
            )

        except Exception as e:
            import traceback
            logger.error("Outline expansion failed")
            logger.error(traceback.format_exc())

            return Command(
                update={
                    "outline_feedback": f"Outline expansion failed: {str(e)}"
                }
            )



    def _tool_finish(
        self,
        decision: OutlineToolDecision,
        state: State,
        config: RunnableConfig,
    ) -> Command:
        """
        å®Œæˆ OutlineAgent æ‰§è¡Œï¼Œç”Ÿæˆæ€»ç»“æ€§åé¦ˆè¿”å›ç»™ CentralAgent
        """
        logger.info(f"Outline Tool: finish | reasoning={decision.reasoning}")

        outline_root = state.get("factstruct_outline")
        memory = state.get("factstruct_memory")
        total_word_limit = state.get("total_word_limit")

        # === å…œåº•å¤„ç† ===
        if outline_root is None:
            logger.warning("Finish called but outline is missing")

            return Command(
                update={
                    "report_outline": "å¤§çº²æœªæˆåŠŸç”Ÿæˆï¼ˆOutlineAgent åœ¨ finish å‰ç¼ºå¤± outlineï¼‰",
                    "outline_feedback": "Finish reached without valid outline.",
                }
            )

        # === åŸºæœ¬ç»“æ„ä¿¡æ¯ ===
        node_count = len(outline_root.get_all_nodes())
        leaf_count = len(outline_root.get_leaf_nodes())

        # === å¯è¯»å¤§çº²è¾“å‡ºï¼ˆç»™ Central / Reporter ç”¨ï¼‰===
        try:
            outline_text = outline_root.to_text_tree(
                include_word_limit=bool(total_word_limit)
            )
        except Exception:
            outline_text = outline_root.to_text_tree()

        # === æ„å»ºç»™ LLM çš„æ€»ç»“ promptï¼ˆå¯é€‰ï¼Œä½†å¾ˆæœ‰ä»·å€¼ï¼‰===
        try:
            llm = get_llm_by_type(
                AGENT_LLM_MAP.get("outline", "default")
            )

            context_lines = []

            if state.get("initial_query"):
                context_lines.append(f"ç”¨æˆ·åŸå§‹é—®é¢˜ï¼š{state.get('initial_query')}")

            if state.get("central_guidance"):
                context_lines.append(f"ä¸­æ¢ç­–ç•¥æŒ‡å¯¼ï¼š{state.get('central_guidance')}")

            if total_word_limit:
                context_lines.append(f"ç›®æ ‡æ€»å­—æ•°é™åˆ¶ï¼š{total_word_limit}")

            context_block = "\n".join(context_lines) if context_lines else "ï¼ˆæ— é¢å¤–ä¸Šä¸‹æ–‡ï¼‰"

            summary_prompt = [
                {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯ä¸€ä¸ªç ”ç©¶å¤§çº²è¯„ä¼°åŠ©æ‰‹ï¼Œ"
                        "ä½ çš„ä»»åŠ¡ä¸æ˜¯ç”Ÿæˆå†…å®¹ï¼Œè€Œæ˜¯åˆ¤æ–­å½“å‰å¤§çº²æ˜¯å¦å·²ç»è¾¾åˆ°"
                        "å¯ä»¥è¿›å…¥æ­£å¼å†…å®¹ç”Ÿæˆé˜¶æ®µçš„ç»“æ„æˆç†Ÿåº¦ã€‚"
                    ),
                },
                {
                    "role": "user",
                    "content": (
                        f"{context_block}\n\n"
                        f"=== å½“å‰å¤§çº²ç»“æ„æŒ‡æ ‡ ===\n"
                        f"- èŠ‚ç‚¹æ€»æ•°: {node_count}\n"
                        f"- å¶å­èŠ‚ç‚¹æ•°: {leaf_count}\n\n"
                        f"=== å½“å‰å¤§çº² ===\n"
                        f"{outline_text}\n\n"
                        "è¯·åŸºäºã€ç”¨æˆ·é—®é¢˜ã€‘å’Œã€ä¸­æ¢ç­–ç•¥æŒ‡å¯¼ã€‘ï¼Œåˆ¤æ–­è¯¥å¤§çº²ï¼š\n"
                        "1. æ˜¯å¦è¦†ç›–äº†ç”¨æˆ·é—®é¢˜çš„ä¸»è¦æ–¹é¢\n"
                        "2. ç»“æ„å±‚çº§æ˜¯å¦æ¸…æ™°ã€ç²’åº¦æ˜¯å¦åˆé€‚\n"
                        "3. æ˜¯å¦é€‚åˆåœ¨å½“å‰å­—æ•°é™åˆ¶ä¸‹å±•å¼€æ­£æ–‡\n\n"
                        "è¯·ç»™å‡ºä¸€å¥ç®€æ´çš„æ€»ç»“æ€§åˆ¤æ–­ï¼ˆä¸è¶…è¿‡ 2 å¥è¯ï¼‰ï¼Œ"
                        "ç”¨äºä¸Šæ¸¸ Agent çš„å†³ç­–å‚è€ƒã€‚"
                    ),
                },
            ]


            llm_response = llm.invoke(summary_prompt)
            finish_summary = llm_response.content.strip()

        except Exception as e:
            logger.warning(f"Finish summary LLM failed: {e}")
            finish_summary = (
                "å¤§çº²ç»“æ„å·²ç”Ÿæˆï¼ŒèŠ‚ç‚¹å±‚çº§å®Œæ•´ï¼Œå¯è¿›å…¥å†…å®¹ç”Ÿæˆé˜¶æ®µã€‚"
            )

        # === å†™å› stateï¼ˆè¿™æ˜¯ CentralAgent æœ€å…³å¿ƒçš„éƒ¨åˆ†ï¼‰===
        return Command(
            update={
                "report_outline": outline_text,              # âœ… ç»™ reporter / central
                "outline_feedback": finish_summary,           # âœ… å†³ç­–çº§æ€»ç»“
            }
        )




    @timed_step("execute_word_planning")
    def execute_word_planning(
        self, outline_root: OutlineNode, total_word_limit: int
    ) -> OutlineNode:
        """
        æ‰§è¡Œå­—æ•°è§„åˆ’ï¼Œä¸ºå¤§çº²ä¸­çš„æ¯ä¸ªå¶å­èŠ‚ç‚¹åˆ†é…å­—æ•°é…é¢

        Args:
            outline_root: å¤§çº²æ ¹èŠ‚ç‚¹
            total_word_limit: ç”¨æˆ·æŒ‡å®šçš„æ€»å­—æ•°é™åˆ¶

        Returns:
            æ›´æ–°äº†å­—æ•°é…é¢çš„å¤§çº²æ ¹èŠ‚ç‚¹
        """
        import json

        logger.info(f"å¼€å§‹å­—æ•°è§„åˆ’ï¼Œæ€»å­—æ•°é™åˆ¶: {total_word_limit}")

        # æ„å»ºå¤§çº²ç»“æ„ä¿¡æ¯ä¾›LLMåˆ†æ
        def build_outline_info(node: OutlineNode, depth: int = 0) -> list:
            nodes_info = []
            nodes_info.append(
                {
                    "id": node.id,
                    "title": node.title,
                    "depth": depth,
                    "is_leaf": node.is_leaf(),
                }
            )
            for child in node.children:
                nodes_info.extend(build_outline_info(child, depth + 1))
            return nodes_info

        outline_info = build_outline_info(outline_root)
        leaf_nodes = [n for n in outline_info if n["is_leaf"]]

        # æ„å»ºLLMè¯·æ±‚
        outline_text = outline_root.to_text_tree()
        prompt_content = f"""è¯·ä¸ºä»¥ä¸‹æŠ¥å‘Šå¤§çº²åˆ†é…å­—æ•°ã€‚

        ## å¤§çº²ç»“æ„
        {outline_text}

        ## å¶å­èŠ‚ç‚¹åˆ—è¡¨
        {json.dumps(leaf_nodes, ensure_ascii=False, indent=2)}

        ## æ€»å­—æ•°é™åˆ¶
        {total_word_limit} å­—

        è¯·æ ¹æ®æ¯ä¸ªå¶å­èŠ‚ç‚¹çš„é‡è¦æ€§å’Œå†…å®¹å¤æ‚åº¦ï¼Œæ™ºèƒ½åˆ†é…å­—æ•°é…é¢ã€‚
        ä½ å¿…é¡»åªè¾“å‡ºä¸€ä¸ªåˆæ³•çš„ JSON å¯¹è±¡ã€‚ç¦æ­¢è¾“å‡ºä»»ä½•è§£é‡Šã€è¯´æ˜ã€æ³¨é‡Šã€æ ‡é¢˜æˆ–é¢å¤–æ–‡æœ¬ã€‚å¦‚æœè¾“å‡ºåŒ…å«é JSON å†…å®¹ï¼Œå°†è¢«è§†ä¸ºé”™è¯¯ã€‚
        """

        try:
            messages = apply_prompt_template("word_planner", {"messages": []}) + [
                HumanMessage(content=prompt_content)
            ]
            llm = get_llm_by_type(AGENT_LLM_MAP.get("outline", "default"))
            response = llm.invoke(messages)
            result = response.content

            # è§£æJSONç»“æœ
            logger.info(f"result:{result}")
            # result = result.replace("```json", "").replace("```", "").strip()

            match = re.search(r"\{[\s\S]*\}", result)
            if not match:
                raise ValueError("No JSON object found in LLM output")

            allocations = json.loads(match.group(0))

            # å°†å­—æ•°é…é¢å†™å…¥èŠ‚ç‚¹
            for alloc in allocations.get("allocations", []):
                node_id = alloc.get("node_id")
                word_limit = alloc.get("word_limit", 0)
                node = outline_root.find_node_by_id(node_id)
                if node:
                    node.word_limit = word_limit
                    logger.debug(
                        f"èŠ‚ç‚¹ {node_id} ({node.title}) åˆ†é…å­—æ•°: {word_limit}"
                    )

            # è‡ªåº•å‘ä¸Šè®¡ç®—éå¶å­èŠ‚ç‚¹çš„å­—æ•°
            def update_parent_word_limits(node: OutlineNode) -> int:
                if node.is_leaf():
                    return node.word_limit
                total = sum(update_parent_word_limits(child) for child in node.children)
                node.word_limit = total
                return total

            update_parent_word_limits(outline_root)
            logger.info(f"å­—æ•°è§„åˆ’å®Œæˆï¼Œæ ¹èŠ‚ç‚¹æ€»å­—æ•°: {outline_root.word_limit}")

        except Exception as e:
            logger.error(f"å­—æ•°è§„åˆ’å¤±è´¥: {str(e)}")
            # Fallback: å¹³å‡åˆ†é…
            leaf_nodes_obj = outline_root.get_leaf_nodes()
            avg_words = total_word_limit // len(leaf_nodes_obj) if leaf_nodes_obj else 0
            for node in leaf_nodes_obj:
                node.word_limit = avg_words
            logger.warning(f"ä½¿ç”¨å¹³å‡åˆ†é…ç­–ç•¥ï¼Œæ¯ä¸ªå¶å­èŠ‚ç‚¹: {avg_words} å­—")

        logger.info(f"outline_root:{outline_root}")
        # exit()
        return outline_root
