import json
import os
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Annotated, Any, Dict, List, Literal, Optional, Type, Union, cast

from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.runnables import RunnableConfig
from langgraph.types import Command

from src.agents.sub_agent_registry import get_sub_agents_by_global_type
from src.config.agents import AGENT_LLM_MAP
from src.llms.llm import get_llm_by_type
from src.memory import MemoryStack, MemoryStackEntry
from src.prompts.template import apply_prompt_template, get_prompt_template
from src.utils.json_utils import repair_json_output
from src.utils.logger import logger
from src.utils.statistics import global_statistics
from src.prompts.central_decision import Decision, DelegateParams

from ..graph.types import State

# from .SubAgentConfig import get_sub_agents_by_global_type


# -------------------------
# æ ¸å¿ƒæšä¸¾å®šä¹‰
# -------------------------
class CentralAgentAction(Enum):
    """ä¸­æ¢AgentåŠ¨ä½œæšä¸¾ï¼Œå®šä¹‰ç³»ç»Ÿæ ¸å¿ƒå†³ç­–ç±»å‹"""

    THINK = "think"  # åˆ†æå½“å‰çŠ¶æ€å¹¶æ€è€ƒä¸‹ä¸€æ­¥è¡ŒåŠ¨
    REFLECT = "reflect"  # åæ€ä¹‹å‰çš„åŠ¨ä½œå’Œç»“æœ
    SUMMARIZE = "summarize"  # æ€»ç»“å½“å‰å·²è·å¾—çš„ä¿¡æ¯
    DELEGATE = "delegate"  # å§”æ´¾å­Agentæ‰§è¡Œä¸“é¡¹ä»»åŠ¡
    FINISH = "finish"  # åˆ¤æ–­ä»»åŠ¡å®Œæˆå¹¶ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š


# -------------------------
# ä¸­æ¢Agentæ ¸å¿ƒæ¨¡å—--ä¸­æ¢Agentçš„action
# exp: ä¸prompt/central_decision.pyä¸­çš„Decisionç±»ä¸åŒçš„æ˜¯ï¼Œé‚£é‡Œæ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œè¿™é‡Œæ˜¯æšä¸¾ç±»å‹ï¼Œæ‰€ä»¥è¦å®šä¹‰ä¸¤æ¬¡
# -------------------------
@dataclass
class CentralDecision:
    """ä¸­æ¢Agentå†³ç­–ç»“æœæ•°æ®æ¨¡å‹"""

    action: CentralAgentAction  # å†³ç­–åŠ¨ä½œ
    reasoning: str  # å†³ç­–æ¨ç†è¿‡ç¨‹
    params: Dict[DelegateParams, Any] = field(
        default_factory=dict
    )  # åŠ¨ä½œå‚æ•°=>delegateæœ‰å‚æ•°
    instruction: Optional[str] = None  # åŠ¨ä½œå¯¹åº”çš„æŒ‡ä»¤è¯´æ˜


class CentralAgent:
    """
    ä¸­æ¢Agentæ ¸å¿ƒç±»ï¼Œè´Ÿè´£ç³»ç»Ÿæ•´ä½“å†³ç­–ä¸ä»»åŠ¡ç¼–æ’

    é‡‡ç”¨åŸºäºè®°å¿†æ ˆçš„å†³ç­–æœºåˆ¶ï¼Œé€šè¿‡çŠ¶æ€åˆ†æåŠ¨æ€å§”æ´¾å­Agentæ‰§è¡Œä¸“é¡¹ä»»åŠ¡ï¼Œ
    å¹¶æœ€ç»ˆæ•´åˆç»“æœç”Ÿæˆå®ŒæˆæŠ¥å‘Š
    """

    def __init__(self, graph_format: str = "sp"):
        self.memory_stack = MemoryStack()
        from src.agents.SubAgentManager import SubAgentManager

        self.sub_agent_manager = SubAgentManager(self)

        sub_agents = get_sub_agents_by_global_type(graph_format)
        logger.info(f"åˆå§‹åŒ–ä¸­æ¢Agentï¼Œä½¿ç”¨å­Agentç±»å‹: {sub_agents}")

        # åˆå§‹åŒ–å­Agentç›¸å…³ä¿¡æ¯
        self.available_sub_agents = [agent["name"] for agent in sub_agents]
        self.sub_agents_description = ""
        for agent in sub_agents:
            self.sub_agents_description += (
                f"- **{agent['name']}**: {agent['description']}\n"
            )

        # åŠ¨ä½œå¤„ç†å™¨æ˜ å°„è¡¨
        self.action_handlers = {
            CentralAgentAction.THINK: self._handle_think,
            CentralAgentAction.REFLECT: self._handle_reflect,
            CentralAgentAction.SUMMARIZE: self._handle_summarize,
            CentralAgentAction.DELEGATE: self._handle_delegate,
            CentralAgentAction.FINISH: self._handle_finish,
        }

        # åŠ¨ä½œç±»å‹å¯¹åº”çš„æŒ‡ä»¤æ¨¡æ¿
        self.action_instructions = {
            CentralAgentAction.THINK: "åˆ†æå½“å‰çŠ¶æ€å¹¶æ€è€ƒä¸‹ä¸€æ­¥è¡ŒåŠ¨",
            CentralAgentAction.REFLECT: "åæ€ä¹‹å‰çš„åŠ¨ä½œå’Œç»“æœ",
            CentralAgentAction.SUMMARIZE: "æ€»ç»“å½“å‰å·²è·å¾—çš„ä¿¡æ¯",
            CentralAgentAction.DELEGATE: "å†³å®šå§”æ´¾å“ªä¸ªå­Agentæ‰§è¡Œä»»åŠ¡",
            CentralAgentAction.FINISH: "åˆ¤æ–­æ˜¯å¦å¯ä»¥å®Œæˆä»»åŠ¡å¹¶ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š",
        }

    def make_decision(
        self, state: State, config: RunnableConfig, retry_count: int = 0
    ) -> CentralDecision:
        """
        ä¸­æ¢Agentå†³ç­–æ ¸å¿ƒé€»è¾‘ï¼Œåˆ†æå½“å‰çŠ¶æ€ç”Ÿæˆå†³ç­–ç»“æœ

        Args:
            state: å½“å‰ç³»ç»ŸçŠ¶æ€
            config: è¿è¡Œé…ç½®

        Returns:
            å†³ç­–ç»“æœå¯¹è±¡
        """
        max_retries = 3
        logger.info("ä¸­æ¢Agentæ­£åœ¨è¿›è¡Œå†³ç­–...")
        start_time = datetime.now()

        #å¢åŠ  SOP éƒ¨åˆ†ï¼Œç”¨äºåŠ å…¥ decision æ¨¡å—
        #SOPæ”¹æˆä¸­æ–‡ï¼ŒSOPåº”è¯¥è¦çš„æ˜¯æŠ½è±¡çš„ã€‚ä¸èƒ½å†™æ˜¯outlineï¼Œreplannerï¼Œå…·ä½“è°æ¥ç”Ÿæˆæ˜¯è®© CentralAgent è‡ªå·±æ‰¾
        DECISION_SOP_SP = '''### æ‰§è¡Œæµç¨‹æŒ‡å—ï¼ˆExecution Workflow Guidelinesï¼‰

        ä½ æ­£åœ¨ä¸€ä¸ªå…·æœ‰**ä¸¥æ ¼é˜¶æ®µçº¦æŸä¸ä¸å¯å›é€€èŠ‚ç‚¹**çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­è¿è¡Œã€‚
        ä½ çš„èŒè´£æ˜¯**ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æµç¨‹æ¨è¿›ä»»åŠ¡ç›´è‡³å®Œæˆ**ï¼Œå¹¶éµå®ˆæ¯ä¸ªé˜¶æ®µçš„è¿›å…¥ä¸é€€å‡ºè§„åˆ™ã€‚
        ä»»ä½•è¿åé˜¶æ®µçº¦æŸçš„è¡Œä¸ºéƒ½è¢«è§†ä¸ºæ‰§è¡Œé”™è¯¯ã€‚

        ---

        #### å¼ºåˆ¶æ€§çš„é«˜å±‚æ‰§è¡Œæµç¨‹ï¼ˆMandatory High-Level Workflowï¼‰

        ### 1. æ„ŸçŸ¥ä¸æ¾„æ¸…é˜¶æ®µï¼ˆPerception Phaseï¼Œå¼ºåˆ¶ï¼Œç¬¬ä¸€æ­¥ï¼Œä¸”ä»…æ­¤ä¸€æ¬¡ï¼‰

        - ä½  **å¿…é¡»** åœ¨ä»»åŠ¡å¼€å§‹æ—¶é¦–å…ˆå§”æ´¾ç»™ **perception agent**ã€‚
        - perception é˜¶æ®µæ˜¯ä¸€ä¸ª **ä¸€æ¬¡æ€§ã€ä¸å¯é‡å…¥ï¼ˆnon-reentrantï¼‰ã€ä¸å¯å›é€€ï¼ˆirreversibleï¼‰çš„é˜¶æ®µ**ã€‚
        - è¯¥é˜¶æ®µçš„å”¯ä¸€ç›®æ ‡æ˜¯è¿›è¡Œä»»åŠ¡çš„å‰ç½®æ„ŸçŸ¥ä¸éœ€æ±‚æ¾„æ¸…ï¼Œè€Œ**ä¸æ˜¯**æ¨ç†ã€è§„åˆ’æˆ–å†…å®¹ç”Ÿæˆã€‚
        - perception agent è´Ÿè´£ï¼š
        - è¯†åˆ«ç”¨æˆ·è¯·æ±‚ä¸­çš„ä¸ç¡®å®šæ€§ã€ä¿¡æ¯ç¼ºå¤±æˆ–æ­§ä¹‰ï¼›
        - ç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„è¡¨å•æˆ–é—®é¢˜é›†åˆï¼Œç”¨äºå‘äººç±»ç”¨æˆ·æ”¶é›†å¿…è¦çš„è¡¥å……ä¿¡æ¯ã€‚
        - perception agent çš„è¾“å‡º **å¿…é¡»** è¢«è¿”å›ç»™äººç±»ç”¨æˆ·ä»¥å®Œæˆä¿¡æ¯è¡¥å……æˆ–ç¡®è®¤ã€‚
        - **ä¸€æ—¦ perception é˜¶æ®µå®Œæˆå¹¶é€€å‡ºï¼š**
        - åœ¨æ•´ä¸ªä»»åŠ¡ç”Ÿå‘½å‘¨æœŸä¸­ï¼Œ**ç»å¯¹ç¦æ­¢å†æ¬¡è°ƒç”¨ perception agent**ï¼›
        - å³ä½¿åç»­é˜¶æ®µå‘ç°ä¿¡æ¯ä¸è¶³ã€æ­§ä¹‰æˆ–ä¸ç¡®å®šæ€§ï¼Œ**ä¹Ÿä¸å¾—é€šè¿‡ perception é˜¶æ®µé‡æ–°å‘ç”¨æˆ·æé—®**ï¼›
        - æ‰€æœ‰åç»­å¤„ç†å¿…é¡»åœ¨æ—¢æœ‰è¾“å…¥å’Œç³»ç»Ÿèƒ½åŠ›èŒƒå›´å†…å®Œæˆã€‚

        ---

        ### 2. å¤§çº²æ„å»ºé˜¶æ®µï¼ˆOutline Construction Phaseï¼Œå¼ºåˆ¶ï¼Œæ„ŸçŸ¥å®Œæˆä¹‹åï¼Œä»…ä¸€æ¬¡ï¼‰

        - åœ¨ perception é˜¶æ®µå®Œæˆï¼Œä¸”äººç±»ç”¨æˆ·å·²ç¡®è®¤æˆ–è¡¥å……ç›¸å…³ä¿¡æ¯åï¼Œä½  **å¿…é¡»** å§”æ´¾ç»™ **outline agent**ã€‚
        - outline é˜¶æ®µåŒæ ·æ˜¯ä¸€ä¸ª **ä¸å¯é‡å…¥é˜¶æ®µ**ï¼Œåœ¨æ•´ä¸ªä»»åŠ¡ä¸­ **å¿…é¡»ä¸”åªèƒ½æ‰§è¡Œä¸€æ¬¡**ã€‚
        - outline agent è´Ÿè´£åŸºäºï¼š
        - åŸå§‹ç”¨æˆ· queryï¼›
        - å·²ç¡®è®¤çš„äººç±»è¾“å…¥ï¼ˆè¡¨å•æˆ–è¡¥å……ä¿¡æ¯ï¼‰ï¼›
        - ç°æœ‰ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœ‰ï¼‰ï¼Œ
        ç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„å¤§çº²ã€‚
        - è¯¥å¤§çº²ç”¨äºå®šä¹‰ä»»åŠ¡æˆ–å†…å®¹çš„æ•´ä½“ç»“æ„ã€å±‚çº§å…³ç³»ä¸è¦†ç›–èŒƒå›´ã€‚
        - outline agent çš„è¾“å‡º **å¿…é¡»** è¢«æäº¤ç»™äººç±»ç”¨æˆ·è¿›è¡Œç¡®è®¤ã€‚
        - ä¸€æ—¦å¤§çº²è¢«ç¡®è®¤ï¼Œè¯¥ç»“æ„è¢«è§†ä¸º **å†»ç»“ï¼ˆstructure frozenï¼‰**ï¼Œåç»­é˜¶æ®µä¸å¾—å¯¹å…¶è¿›è¡Œé‡æ–°ç”Ÿæˆæˆ–æ ¹æœ¬æ€§é‡æ„ã€‚

        ---

        ### 3. æ¨ç†ä¸ç ”ç©¶é˜¶æ®µï¼ˆReasoning & Research Phaseï¼Œå¼ºåˆ¶ï¼Œå¤§çº²ç¡®è®¤ä¹‹åï¼‰

        - åœ¨å¤§çº²è¢«ç¡®è®¤ä¹‹åï¼Œä½  **å¿…é¡»** æ‰§è¡Œä¸€ä¸ªé›†ä¸­å¼çš„æ¨ç†ä¸ç ”ç©¶é˜¶æ®µã€‚
        - åœ¨è¯¥é˜¶æ®µï¼Œä¸­æ¢æ™ºèƒ½ä½“ï¼ˆcentral agentï¼‰**å¿…é¡»**ï¼š
        - è‡³å°‘è°ƒç”¨ **Researcher agent** ä¸€æ¬¡ï¼›
        - ä½¿ç”¨å¯ç”¨å·¥å…·ã€æ–‡æ¡£æˆ–å¤–éƒ¨ä¿¡æ¯æºï¼Œå¯¹å·²ç¡®è®¤çš„å¤§çº²è¿›è¡ŒéªŒè¯ã€è¡¥å……æˆ–è´¨ç–‘ã€‚
        - è‹¥åœ¨è¯¥é˜¶æ®µå‘ç°ä¿¡æ¯ä¸è¶³æˆ–ä¸ç¡®å®šæ€§ï¼š
        - **å¿…é¡»é€šè¿‡ç ”ç©¶ã€å‡è®¾æ£€éªŒæˆ–æ˜¾å¼è¯´æ˜ä¸ç¡®å®šæ€§æ¥å¤„ç†**ï¼›
        - **ä¸å¾—é€šè¿‡å†æ¬¡å‘ç”¨æˆ·æé—®æˆ–é‡æ–°è¿›å…¥ perception é˜¶æ®µæ¥è§£å†³**ã€‚
        - **æ— è®ºå½“å‰ä¿¡æ¯æ˜¯å¦çœ‹ä¼¼å……åˆ†ï¼Œè¯¥é˜¶æ®µéƒ½å¿…é¡»ä¸ºæ¯ä¸€ä¸ªä»»åŠ¡æ‰§è¡Œä¸€æ¬¡**ã€‚

        ---

        ### 4. å†…å®¹ç”Ÿæˆé˜¶æ®µï¼ˆContent Generation Phaseï¼Œå¼ºåˆ¶ï¼Œæœ€ç»ˆé˜¶æ®µï¼‰

        - åœ¨æ¨ç†ä¸ç ”ç©¶é˜¶æ®µå®Œæˆåï¼Œä½  **å¿…é¡»** å§”æ´¾ç»™ **reporter agent**ã€‚
        - reporter agent å¿…é¡» **ä¸¥æ ¼ä¾æ®å·²ç¡®è®¤çš„å¤§çº²ç»“æ„ä¸ç ”ç©¶ç»“è®º** ç”Ÿæˆæœ€ç»ˆå†…å®¹ã€‚
        - åœ¨ reporter agent å°šæœªç”Ÿæˆæœ€ç»ˆå†…å®¹ä¹‹å‰ï¼Œ**ä¸å¾—è¿›å…¥ FINISH çŠ¶æ€**ã€‚
        - è¯¥é˜¶æ®µæ˜¯ä»»åŠ¡å®Œæˆçš„ **å¿…è¦ä¸”ç»ˆç»“æ€§æ¡ä»¶**ã€‚

        ---

        #### æ‰§è¡Œçº¦æŸä¸ç¦æ­¢è¡Œä¸ºï¼ˆHard Constraints & Prohibited Actionsï¼‰

        - æ‰§è¡Œé¡ºåº **å¿…é¡»ä¸¥æ ¼éµå¾ª**ï¼š  
        **æ„ŸçŸ¥ä¸æ¾„æ¸… â†’ å¤§çº²æ„å»º â†’ æ¨ç†ä¸ç ”ç©¶ â†’ å†…å®¹ç”Ÿæˆ**
        - perception é˜¶æ®µä¸ outline é˜¶æ®µï¼š
        - **å‡ä¸ºä¸€æ¬¡æ€§é˜¶æ®µ**
        - **å‡ä¸å¯é‡å¤ã€ä¸å¯å›é€€ã€ä¸å¯é‡æ–°è¿›å…¥**
        - åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼š
        - **éƒ½ä¸å¾—åœ¨ perception é˜¶æ®µå®Œæˆåå†æ¬¡å‘ç”¨æˆ·å‘èµ·æ¾„æ¸…æ€§äº¤äº’**
        - **éƒ½ä¸å¾—ä»¥ä»»ä½•ç†ç”±é‡æ–°è°ƒç”¨ perception agent**
        - è‹¥åç»­é˜¶æ®µæš´éœ²å‡ºä¿¡æ¯ä¸è¶³ï¼Œåªèƒ½é€šè¿‡ï¼š
        - ç ”ç©¶è¡¥å……ï¼›
        - åˆç†å‡è®¾å¹¶æ˜ç¡®æ ‡æ³¨ï¼›
        - æˆ–åœ¨æœ€ç»ˆå†…å®¹ä¸­æ˜¾å¼è¯´æ˜é™åˆ¶æ¡ä»¶ï¼Œ
        æ¥è¿›è¡Œå¤„ç†ã€‚

        ---

        #### å¼ºåˆ¶ç ”ç©¶è°ƒç”¨è§„åˆ™ï¼ˆMandatory Research Invocationï¼‰

        - åœ¨ **æ¯ä¸€æ¬¡ä»»åŠ¡æ‰§è¡Œä¸­**ï¼ŒResearcher agent **å¿…é¡»** ä½œä¸ºã€Œæ¨ç†ä¸ç ”ç©¶é˜¶æ®µã€çš„ä¸€éƒ¨åˆ†è¢«çœŸå®è°ƒç”¨ã€‚
        - **ä¸å¾—è·³è¿‡ã€ä¼ªé€ æˆ–æ¨¡æ‹Ÿè¯¥é˜¶æ®µ**ã€‚
        - åœ¨æœªçœŸå®è°ƒç”¨ Researcher agent çš„æƒ…å†µä¸‹ç»§ç»­æ‰§è¡Œï¼Œæ˜¯è¢«æ˜ç¡®ç¦æ­¢çš„ã€‚

        ---

        ä½ çš„ç›®æ ‡æ˜¯ï¼š  
        åœ¨ä¸¥æ ¼éµå¾ªä¸Šè¿°ä¸å¯å›é€€æ‰§è¡Œæµç¨‹çš„å‰æä¸‹ï¼Œç¡®ä¿ä»»åŠ¡åœ¨ç»“æ„ä¸Šç¨³å®šã€åœ¨äººæœºäº¤äº’ä¸Šå¯æ§ï¼Œå¹¶å®ç°å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å¯é ååŒã€‚
        '''

        #è¿™ä¸ªä¼¼ä¹è¦æ”¹å…¶ä»–åœ°æ–¹ï¼Œåæ­£åé¢ç”¨ä¸ä¸Šï¼Œä¸è¦äº†
        # graph_format=config["configurable"]["graph_format"]
        # if graph_format=="sp_xxqg":
        #     state["sop"] = DECISION_SOP_SP
        #     logger.info(f"ä½¿ç”¨ SP çš„ SOP")
        # else:
        #     state["sop"] = None
        #     logger.info(f"ä¸ä½¿ç”¨ SOP")
        state["sop"] = DECISION_SOP_SP
        logger.info(f"ä½¿ç”¨ SP çš„ SOP")
        
        # æ„å»ºå†³ç­–prompt
        messages = self._build_decision_prompt(state, config)
        logger.debug(f"å†³ç­–prompt: {messages}")

        # è·å–LLMå†³ç­–å¹¶å¤„ç†å¼‚å¸¸
        try:
            llm = get_llm_by_type(
                AGENT_LLM_MAP.get("central_agent", "default")
            ).with_structured_output(
                Decision,
                method="json_mode",
            )
            response = llm.invoke(messages)

            # è§£æå†³ç­–ç»“æœ
            action = CentralAgentAction(response.action)
            reasoning = response.reasoning
            params = response.params or {}
            instruction = response.instruction or self.action_instructions.get(
                action, ""
            )
            if state.get("locale") == None:
                locale = response.locale or "zh-CN"
                # å°† locale æ·»åŠ åˆ° state
                state["locale"] = locale

            logger.info(f"å†³ç­–ç»“æœ: {response}")
            end_time = datetime.now()
            time_entry = {
                "step_name": "central decision" + start_time.isoformat(),
                "start_time": start_time.isoformat(),
                "end_time": end_time.isoformat(),
                "duration": (end_time - start_time).total_seconds(),
            }
            global_statistics.add_time_entry(time_entry)

            return CentralDecision(
                action=action,
                reasoning=reasoning,
                params=params,
                instruction=instruction,
            )

        except Exception as e:
            import traceback

            logger.error(
                f"å†³ç­–è§£æå¤±è´¥:  (å°è¯• {retry_count + 1}/{max_retries}): {str(e)}"
            )
            logger.error("è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼š\n" + traceback.format_exc())
            if retry_count < max_retries - 1:
                return self.make_decision(state, config, retry_count + 1)
            # å¼‚å¸¸æƒ…å†µä¸‹è¿”å›é»˜è®¤å†³ç­–
            end_time = datetime.now()
            time_entry = {
                "step_name": "central_decision" + start_time.isoformat(),
                "start_time": start_time.isoformat(),
                "end_time": end_time.isoformat(),
                "duration": (end_time - start_time).total_seconds(),
            }
            global_statistics.add_time_entry(time_entry)
            return CentralDecision(
                action=CentralAgentAction.THINK,
                reasoning="å†³ç­–è§£æå¤±è´¥ï¼Œé»˜è®¤é€‰æ‹©æ€è€ƒåŠ¨ä½œ",
                params={},
                instruction=self.action_instructions[CentralAgentAction.THINK],
            )

    def _build_decision_prompt(
        self,
        state: State,
        config: RunnableConfig,
    ) -> List[Union[AIMessage, HumanMessage]]:
        """
        æ„å»ºä¸­æ¢Agentå†³ç­–æç¤ºè¯ï¼Œä½¿ç”¨ç»Ÿä¸€çš„promptæ¨¡æ¿

        Args:
            context: å†³ç­–ä¸Šä¸‹æ–‡ï¼ˆå·²åŒ…å«æ‰€æœ‰å…³é”®å‚æ•°ï¼‰
            config: è¿è¡Œé…ç½®
            action_options: å¯ç”¨åŠ¨ä½œé€‰é¡¹

        Returns:
            æ ¼å¼åŒ–çš„æç¤ºè¯æ¶ˆæ¯åˆ—è¡¨
        """
        messages_history = state.get("messages", [])
        SOP=state.get("sop",None)
        converted_messages = []
        for msg in messages_history:
            if isinstance(msg, (HumanMessage, AIMessage)):
                converted_messages.append(
                    {
                        "role": msg.type,
                        "content": msg.content,
                        "additional_kwargs": getattr(msg, "additional_kwargs", {}),
                    }
                )
            else:
                converted_messages.append(msg)

        # æå–ç”¨æˆ·åé¦ˆå¹¶æ ¼å¼åŒ–ä¸ºå¼ºè°ƒæ–‡æœ¬
        user_feedback_text = ""
        hitl_feedback = state.get("hitl_feedback", "")
        if hitl_feedback:
            user_feedback_text = f"\n\nğŸ”´ **CRITICAL USER FEEDBACK**: {hitl_feedback}\n\nThis feedback MUST be considered in your decision-making process."

        # ä»è®°å¿†æ ˆä¸­æå–æ‰€æœ‰ç”¨æˆ·åé¦ˆ
        user_feedbacks_from_memory = []
        for entry in self.memory_stack.get_all():
            if entry.action == "human_feedback":
                feedback_content = entry.content
                if entry.result:
                    feedback_type = entry.result.get("feedback_type", "")
                    if feedback_type == "content_modify":
                        request = entry.result.get("request", "")
                        user_feedbacks_from_memory.append(f"- {request}")
                    else:
                        user_feedbacks_from_memory.append(f"- {feedback_content}")
                else:
                    user_feedbacks_from_memory.append(f"- {feedback_content}")

        if user_feedbacks_from_memory:
            user_feedback_text += (
                "\n\nğŸ”´ **USER FEEDBACK HISTORY**:\n"
                + "\n".join(user_feedbacks_from_memory)
                + "\n\nâš ï¸ All feedback above MUST be addressed. When delegating to reporter, ensure these requirements are fulfilled."
            )

        context = {
            "available_actions": [action.value for action in CentralAgentAction],
            "available_sub_agents": self.available_sub_agents,
            "sub_agents_description": self.sub_agents_description,
            "current_action": "decision",
            "messages_history": converted_messages,
            "locale": state.get("locale", "zh-CN"),  # ç¡®ä¿localeè¢«ä¼ é€’åˆ°æ¨¡æ¿
            "user_feedback": user_feedback_text,  # æ·»åŠ ç”¨æˆ·åé¦ˆåˆ°ä¸Šä¸‹æ–‡
            "SOP":SOP,
        }
        action_options = list(CentralAgentAction)
        # åŠ è½½æ­£ç¡®çš„æ¨¡æ¿åç§°å¹¶åˆå¹¶åŠ¨ä½œé€‰é¡¹
        context_with_actions = {
            **context,
            **config,
            "available_actions": ", ".join([a.value for a in action_options]),
        }
        return apply_prompt_template(
            "central_agent", state, extra_context=context_with_actions
        )

    def execute_action(
        self, decision: CentralDecision, state: State, config: RunnableConfig
    ) -> Command:
        """
        æ‰§è¡Œå†³ç­–åŠ¨ä½œï¼Œè°ƒåº¦å¯¹åº”çš„åŠ¨ä½œå¤„ç†å™¨

        Args:
            decision: å†³ç­–ç»“æœ
            state: å½“å‰ç³»ç»ŸçŠ¶æ€
            config: è¿è¡Œé…ç½®

        Returns:
            åŠ¨ä½œæ‰§è¡Œç»“æœCommandå¯¹è±¡
        """
        handler = self.action_handlers.get(decision.action)
        if not handler:
            error_msg = f"æœªçŸ¥åŠ¨ä½œ: {decision.action}"
            logger.error(error_msg)
            return Command(
                update={
                    "messages": [
                        AIMessage(
                            content=f"é”™è¯¯ï¼šæœªçŸ¥åŠ¨ä½œ: {decision.action}",
                            name="central_error",
                        )
                    ],
                    "locale": state.get("locale"),
                    "current_node": "central_agent",
                    "memory_stack": self.memory_stack.to_dict(),
                },
                goto="central_agent",
            )

        return handler(decision, state, config)

    def _handle_think(
        self, decision: CentralDecision, state: State, config: RunnableConfig
    ) -> Command:
        """å¤„ç†æ€è€ƒåŠ¨ä½œï¼Œåˆ†æå½“å‰çŠ¶æ€ç”Ÿæˆä¸‹ä¸€æ­¥è®¡åˆ’"""
        logger.info("ä¸­æ¢Agentæ­£åœ¨æ€è€ƒ...")
        start_time = datetime.now()
        context = {
            "current_action": "think",
            "current_progress": state.get("observations", []),
            "decision_reasoning": decision.reasoning,
            "instruction": decision.instruction,
            "locale": state.get("locale", "zh-CN"),  # ç¡®ä¿localeè¢«ä¼ é€’åˆ°æ¨¡æ¿
        }

        # åº”ç”¨ç»Ÿä¸€çš„å†³ç­–æç¤ºæ¨¡æ¿
        messages = apply_prompt_template("central_agent", state, extra_context=context)

        llm = get_llm_by_type(AGENT_LLM_MAP.get("central_agent", "default"))
        response = llm.invoke(messages)

        # è®°å½•æ€è€ƒè¿‡ç¨‹åˆ°è®°å¿†æ ˆ
        memory_entry = MemoryStackEntry(
            timestamp=datetime.now().isoformat(),
            action="think",
            content=response.content,
        )
        self.memory_stack.push(memory_entry)

        logger.info(f"central_think: {response.content}")
        end_time = datetime.now()
        time_entry = {
            "step_name": "central_think" + start_time.isoformat(),
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration": (end_time - start_time).total_seconds(),
        }
        global_statistics.add_time_entry(time_entry)
        return Command(
            update={
                "messages": [AIMessage(content=response.content, name="central_think")],
                "current_node": "central_agent",
                "memory_stack": json.dumps(
                    [entry.to_dict() for entry in self.memory_stack.get_all()]
                ),
                "locale": state.get("locale"),
            },
            goto="central_agent",
        )

    def _handle_reflect(
        self, decision: CentralDecision, state: State, config: RunnableConfig
    ) -> Command:
        """å¤„ç†åæ€åŠ¨ä½œï¼Œè¯„ä¼°ä¹‹å‰çš„æ­¥éª¤å¹¶æ¸…ç†è®°å¿†æ ˆ"""
        logger.info("ä¸­æ¢Agentæ­£åœ¨åæ€...")
        start_time = datetime.now()

        # è·å–åæ€ç›®æ ‡å’Œä¸Šä¸‹æ–‡
        # recent_memory = self.memory_stack.get_recent(5)  # è·å–æœ€è¿‘5æ¡è®°å¿†

        context = {
            "current_action": "reflect",
            "decision_reasoning": decision.reasoning,
            "instruction": decision.instruction,
            "locale": state.get("locale", "zh-CN"),  # ç¡®ä¿localeè¢«ä¼ é€’åˆ°æ¨¡æ¿
        }

        # åº”ç”¨åæ€æç¤ºæ¨¡æ¿
        messages = apply_prompt_template("central_agent", state, extra_context=context)

        llm = get_llm_by_type(AGENT_LLM_MAP.get("central_agent", "default"))
        response = llm.invoke(messages)

        # è§£æåæ€ç»“æœçš„JSON
        try:
            reflection_data = json.loads(repair_json_output(response.content))
            analysis = reflection_data.get("analysis", "åæ€åˆ†æ")
            pop_count = reflection_data.get("pop_count", 0)
            reasoning = reflection_data.get("reasoning", "åæ€å®Œæˆ")

            # éªŒè¯pop_countæ˜¯æœ‰æ•ˆæ•°å­—
            if not isinstance(pop_count, int) or pop_count < 0:
                logger.warning(f"æ— æ•ˆçš„pop_count: {pop_count}ï¼Œè®¾ç½®ä¸º0")
                pop_count = 0

        except Exception as e:
            logger.error(f"åæ€ç»“æœè§£æå¤±è´¥: {e}")
            analysis = response.content
            pop_count = 0
            reasoning = "JSONè§£æå¤±è´¥ï¼Œä¿æŒç°æœ‰è®°å¿†æ ˆ"

        logger.debug(f"reflectå†³å®šæ¸…ç†{pop_count}æ¡æ¶ˆæ¯")
        # æ‰§è¡Œè®°å¿†æ ˆæ¸…ç†
        removed_items = []
        if pop_count > 0:
            reflection_content = (
                f"åæ€åˆ†æ: {analysis}\n"
                f"åæ€åŸå› : {reasoning}\n"
                f"æ¸…ç†äº† {pop_count} æ¡è®°å¿†ã€‚"
            )

            memory_entry = MemoryStackEntry(
                timestamp=datetime.now().isoformat(),
                action="reflect",
                content=reflection_content,
            )

            self.memory_stack.push_with_pop(memory_entry, pop_count)

            removed_items = self.memory_stack.pop(pop_count)

            logger.info(f"æˆåŠŸä»è®°å¿†æ ˆä¸­ç§»é™¤äº† {pop_count} é¡¹è®°å¿†")
            # logger.info(
            #     f"ä»è®°å¿†æ ˆä¸­ç§»é™¤äº† {len(removed_items)} é¡¹: {[item.action for item in removed_items]}"
            # )
        else:
            logger.info("ä¸ç§»é™¤ä»»ä½•è®°å¿†æ ˆé¡¹ç›®")

        logger.info(f"central_reflect: {analysis}")
        end_time = datetime.now()
        time_entry = {
            "step_name": "central_reflect" + start_time.isoformat(),
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration": (end_time - start_time).total_seconds(),
        }
        global_statistics.add_time_entry(time_entry)
        return Command(
            update={
                "messages": [AIMessage(content=analysis, name="central_reflect")],
                "reflection": {
                    "analysis": analysis,
                    "pop_count": len(removed_items),
                    "reasoning": reasoning,
                    "removed_items": removed_items,
                },
                "current_node": "central_agent",
                "memory_stack": json.dumps(
                    [entry.to_dict() for entry in self.memory_stack.get_all()]
                ),
                "locale": state.get("locale"),
            },
            goto="central_agent",
        )

    def _handle_summarize(
        self, decision: CentralDecision, state: State, config: RunnableConfig
    ) -> Command:
        """å¤„ç†æ€»ç»“åŠ¨ä½œï¼Œå½’çº³å½“å‰å·²è·å¾—çš„ä¿¡æ¯"""
        logger.info("ä¸­æ¢Agentæ­£åœ¨æ€»ç»“...")
        start_time = datetime.now()

        context = {
            "current_action": "summarize",
            "summarization_focus": decision.reasoning,
            "instruction": decision.instruction,
            "locale": state.get("locale", "zh-CN"),  # ç¡®ä¿localeè¢«ä¼ é€’åˆ°æ¨¡æ¿
        }

        # æ‰“å°ä¸Šä¸‹æ–‡ç”¨äºè°ƒè¯•
        logger.debug(
            f"Summarize context: {json.dumps(context, ensure_ascii=False, indent=2)}"
        )

        # åº”ç”¨ç»Ÿä¸€çš„æ€»ç»“æç¤ºæ¨¡æ¿
        messages = apply_prompt_template("central_agent", state, extra_context=context)

        llm = get_llm_by_type(AGENT_LLM_MAP.get("central_agent", "default"))
        response = llm.invoke(messages)

        # æ›´æ–°è®°å¿†æ ˆï¼Œæ›¿æ¢æœ€æ–°çš„æ€»ç»“ç»“æœ
        new_entry = MemoryStackEntry(
            timestamp=datetime.now().isoformat(),
            action="summarize",
            content=context.get("summarization_focus", ""),
            result={"summary_result": response.content},
        )

        # logger.info("NEW_ENTRY", new_entry)
        # logger.info("*"*100)

        self.memory_stack.push_with_pop(new_entry)

        # logger.info(f"central_summarize: {response.content}")
        end_time = datetime.now()
        time_entry = {
            "step_name": "central_summarize" + start_time.isoformat(),
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration": (end_time - start_time).total_seconds(),
        }
        global_statistics.add_time_entry(time_entry)
        return Command(
            update={
                "messages": [
                    AIMessage(content=response.content, name="central_summarize")
                ],
                "summary": response.content,
                "current_node": "central_agent",
                "memory_stack": json.dumps(
                    [entry.to_dict() for entry in self.memory_stack.get_all()]
                ),
                "locale": state.get("locale"),
            },
            goto="central_agent",
        )

    def _handle_delegate(
        self, decision: CentralDecision, state: State, config: RunnableConfig
    ) -> Command:
        """å¤„ç†å§”æ´¾åŠ¨ä½œï¼Œè°ƒåº¦å­Agentæ‰§è¡Œä¸“é¡¹ä»»åŠ¡"""
        agent_type = decision.params.agent_type
        task_description = decision.params.task_description
        # agent_type = decision.agent_type
        # task_description = decision.task_description or "æœªæŒ‡å®šä»»åŠ¡"

        # éªŒè¯å­Agentç±»å‹æœ‰æ•ˆæ€§
        if not agent_type or agent_type not in self.available_sub_agents:
            error_msg = (
                f"æ— æ•ˆçš„å­Agentç±»å‹: {agent_type}ï¼Œå¯ç”¨ç±»å‹: "
                f"{self.available_sub_agents}"
            )
            logger.error(f"central_error: {error_msg}")
            return Command(
                update={
                    "messages": [AIMessage(content=error_msg, name="central_error")],
                    "current_node": "central_agent",
                },
                goto="central_agent",
            )

        logger.info(f"ä¸­æ¢Agentå§”æ´¾ {agent_type} æ‰§è¡Œä»»åŠ¡: {task_description}")

        # è®°å½•å§”æ´¾åŠ¨ä½œåˆ°è®°å¿†æ ˆ
        memory_entry = MemoryStackEntry(
            timestamp=datetime.now().isoformat(),
            action="delegate",
            agent_type=agent_type,
            content=f"å§”æ´¾ä»»åŠ¡: {task_description}",
        )
        self.memory_stack.push(memory_entry)

        # æ„å»ºå­Agentæ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆåŒ…å«è®°å¿†æ ˆæ‘˜è¦ï¼‰
        delegation_context = {
            "task_description": task_description,
            "agent_type": agent_type,
            "memory_context": self.memory_stack.get_summary(include_full_history=True),
            "original_query": state.get("user_query", ""),
        }

        logger.info(f"central_delegate: å§”æ´¾{agent_type}æ‰§è¡Œ: {task_description}")
        return Command(
            update={
                "messages": [
                    AIMessage(
                        content=f"å§”æ´¾{agent_type}æ‰§è¡Œ: {task_description}",
                        name="central_delegate",
                    )
                ],
                "delegation_context": delegation_context,
                "current_node": "central_agent",
                "memory_stack": json.dumps(
                    [entry.to_dict() for entry in self.memory_stack.get_all()]
                ),
                "locale": state.get("locale"),
            },
            goto=agent_type,
        )

    def _handle_finish(
        self, decision: CentralDecision, state: State, config: RunnableConfig
    ) -> Command:
        """å¤„ç†å®ŒæˆåŠ¨ä½œï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¹¶ç»“æŸä»»åŠ¡"""
        logger.info("ä¸­æ¢Agentå®Œæˆä»»åŠ¡...")

        final_report = state.get("final_report", None)
        if not final_report:
            logger.info("æœªæ‰¾åˆ°æœ€ç»ˆæŠ¥å‘Šï¼Œå§”æ´¾Reporter Agentç”ŸæˆæŠ¥å‘Š...")

            # è®°å½•å§”æ´¾åŠ¨ä½œåˆ°è®°å¿†æ ˆ
            memory_entry = MemoryStackEntry(
                timestamp=datetime.now().isoformat(),
                action="delegate",
                agent_type="reporter",
                content="æœªç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šï¼Œå§”æ´¾Reporter Agentç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š",
            )
            self.memory_stack.push(memory_entry)

            # æ„å»ºReporteræ‰§è¡Œä¸Šä¸‹æ–‡
            delegation_context = {
                "task_description": "æ ¹æ®æ‰€æœ‰æ”¶é›†åˆ°çš„ä¿¡æ¯ç”Ÿæˆå®Œæ•´çš„æœ€ç»ˆæŠ¥å‘Š",
                "agent_type": "reporter",
                "memory_context": self.memory_stack.get_summary(
                    include_full_history=True
                ),
                "original_query": state.get("user_query", ""),
                "report_type": "final_report",
                "execution_history": [
                    entry.to_dict() for entry in self.memory_stack.get_all()
                ],
            }

            logger.info("central_delegate_reporter: å§”æ´¾Reporter Agentç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
            return Command(
                update={
                    "messages": [
                        AIMessage(
                            content="å§”æ´¾Reporter Agentç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š",
                            name="central_delegate_reporter",
                        )
                    ],
                    "delegation_context": delegation_context,
                    "current_node": "central_agent",
                    "memory_stack": json.dumps(
                        [entry.to_dict() for entry in self.memory_stack.get_all()]
                    ),
                    "pending_finish": True,  # æ ‡è®°ç­‰å¾…æŠ¥å‘Šå®Œæˆåå†finish
                },
                goto="reporter",
            )
        logger.info(f"final_report: {final_report}")

        # æ„å»ºæ‰§è¡Œæ‘˜è¦ï¼ˆåŒ…å«å®Œæ•´è®°å¿†æ ˆå†å²ï¼‰
        execution_summary = {
            "user_query": state.get("user_query", "æœªçŸ¥æŸ¥è¯¢"),
            "execution_history": [
                entry.to_dict() for entry in self.memory_stack.get_all()
            ],
            "final_report": final_report,
            "completion_time": datetime.now().isoformat(),
            "statistics": global_statistics.get_statistics(),
        }

        # ä¿å­˜æ‰§è¡Œæ‘˜è¦åˆ°æ–‡ä»¶
        os.makedirs("./reports", exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"./reports/execution_report_{timestamp}.json"

        try:
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(execution_summary, f, ensure_ascii=False, indent=4)
            report_msg = f"ä»»åŠ¡å®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜: {filename}"
        except Exception as e:
            logger.error(f"æŠ¥å‘Šä¿å­˜å¤±è´¥: {str(e)}")
            report_msg = f"ä»»åŠ¡å®Œæˆï¼Œä½†æŠ¥å‘Šä¿å­˜å¤±è´¥: {str(e)}"
            execution_summary["error"] = str(e)

        logger.info(report_msg)
        logger.info(global_statistics.get_statistics())
        return Command(
            goto="zip_data",  # ç»“æŸæ‰§è¡Œ
        )
