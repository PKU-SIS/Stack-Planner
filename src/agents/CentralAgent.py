import json
import os
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Annotated, Any, Dict, List, Literal, Optional, Type, Union, cast

from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.runnables import RunnableConfig
from langgraph.types import Command

from src.agents.sub_agent_registry import get_sub_agents_by_global_type
from src.config.agents import AGENT_LLM_MAP
from src.llms.llm import get_llm_by_type
from src.memory import MemoryStack, MemoryStackEntry
from src.prompts.template import apply_prompt_template, get_prompt_template
from src.utils.json_utils import repair_json_output
from src.utils.logger import logger
from src.utils.statistics import global_statistics
from src.prompts.central_decision import Decision, DelegateParams

from ..graph.types import State

# from .SubAgentConfig import get_sub_agents_by_global_type


# -------------------------
# æ ¸å¿ƒæšä¸¾å®šä¹‰
# -------------------------
class CentralAgentAction(Enum):
    """ä¸­æ¢AgentåŠ¨ä½œæšä¸¾ï¼Œå®šä¹‰ç³»ç»Ÿæ ¸å¿ƒå†³ç­–ç±»å‹"""

    THINK = "think"  # åˆ†æå½“å‰çŠ¶æ€å¹¶æ€è€ƒä¸‹ä¸€æ­¥è¡ŒåŠ¨
    REFLECT = "reflect"  # åæ€ä¹‹å‰çš„åŠ¨ä½œå’Œç»“æœ
    SUMMARIZE = "summarize"  # æ€»ç»“å½“å‰å·²è·å¾—çš„ä¿¡æ¯
    DELEGATE = "delegate"  # å§”æ´¾å­Agentæ‰§è¡Œä¸“é¡¹ä»»åŠ¡
    FINISH = "finish"  # åˆ¤æ–­ä»»åŠ¡å®Œæˆå¹¶ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š


# -------------------------
# ä¸­æ¢Agentæ ¸å¿ƒæ¨¡å—--ä¸­æ¢Agentçš„action
# exp: ä¸prompt/central_decision.pyä¸­çš„Decisionç±»ä¸åŒçš„æ˜¯ï¼Œé‚£é‡Œæ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œè¿™é‡Œæ˜¯æšä¸¾ç±»å‹ï¼Œæ‰€ä»¥è¦å®šä¹‰ä¸¤æ¬¡
# -------------------------
@dataclass
class CentralDecision:
    """ä¸­æ¢Agentå†³ç­–ç»“æœæ•°æ®æ¨¡å‹"""

    action: CentralAgentAction  # å†³ç­–åŠ¨ä½œ
    reasoning: str  # å†³ç­–æ¨ç†è¿‡ç¨‹
    params: Dict[DelegateParams, Any] = field(
        default_factory=dict
    )  # åŠ¨ä½œå‚æ•°=>delegateæœ‰å‚æ•°
    instruction: Optional[str] = None  # åŠ¨ä½œå¯¹åº”çš„æŒ‡ä»¤è¯´æ˜


class CentralAgent:
    """
    ä¸­æ¢Agentæ ¸å¿ƒç±»ï¼Œè´Ÿè´£ç³»ç»Ÿæ•´ä½“å†³ç­–ä¸ä»»åŠ¡ç¼–æ’

    é‡‡ç”¨åŸºäºè®°å¿†æ ˆçš„å†³ç­–æœºåˆ¶ï¼Œé€šè¿‡çŠ¶æ€åˆ†æåŠ¨æ€å§”æ´¾å­Agentæ‰§è¡Œä¸“é¡¹ä»»åŠ¡ï¼Œ
    å¹¶æœ€ç»ˆæ•´åˆç»“æœç”Ÿæˆå®ŒæˆæŠ¥å‘Š
    """

    def __init__(self, graph_format: str = "sp"):
        self.memory_stack = MemoryStack()
        from src.agents.SubAgentManager import SubAgentManager

        self.sub_agent_manager = SubAgentManager(self)

        sub_agents = get_sub_agents_by_global_type(graph_format)
        logger.info(f"åˆå§‹åŒ–ä¸­æ¢Agentï¼Œä½¿ç”¨å­Agentç±»å‹: {sub_agents}")

        # åˆå§‹åŒ–å­Agentç›¸å…³ä¿¡æ¯
        self.available_sub_agents = [agent["name"] for agent in sub_agents]
        self.sub_agents_description = ""
        for agent in sub_agents:
            self.sub_agents_description += (
                f"- **{agent['name']}**: {agent['description']}\n"
            )

        # åŠ¨ä½œå¤„ç†å™¨æ˜ å°„è¡¨
        self.action_handlers = {
            CentralAgentAction.THINK: self._handle_think,
            CentralAgentAction.REFLECT: self._handle_reflect,
            CentralAgentAction.SUMMARIZE: self._handle_summarize,
            CentralAgentAction.DELEGATE: self._handle_delegate,
            CentralAgentAction.FINISH: self._handle_finish,
        }

        # åŠ¨ä½œç±»å‹å¯¹åº”çš„æŒ‡ä»¤æ¨¡æ¿
        self.action_instructions = {
            CentralAgentAction.THINK: "åˆ†æå½“å‰çŠ¶æ€å¹¶æ€è€ƒä¸‹ä¸€æ­¥è¡ŒåŠ¨",
            CentralAgentAction.REFLECT: "åæ€ä¹‹å‰çš„åŠ¨ä½œå’Œç»“æœ",
            CentralAgentAction.SUMMARIZE: "æ€»ç»“å½“å‰å·²è·å¾—çš„ä¿¡æ¯",
            CentralAgentAction.DELEGATE: "å†³å®šå§”æ´¾å“ªä¸ªå­Agentæ‰§è¡Œä»»åŠ¡",
            CentralAgentAction.FINISH: "åˆ¤æ–­æ˜¯å¦å¯ä»¥å®Œæˆä»»åŠ¡å¹¶ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š",
        }

    def make_decision(
        self, state: State, config: RunnableConfig, retry_count: int = 0
    ) -> CentralDecision:
        """
        ä¸­æ¢Agentå†³ç­–æ ¸å¿ƒé€»è¾‘ï¼Œåˆ†æå½“å‰çŠ¶æ€ç”Ÿæˆå†³ç­–ç»“æœ

        Args:
            state: å½“å‰ç³»ç»ŸçŠ¶æ€
            config: è¿è¡Œé…ç½®

        Returns:
            å†³ç­–ç»“æœå¯¹è±¡
        """
        max_retries = 3
        logger.info("ä¸­æ¢Agentæ­£åœ¨è¿›è¡Œå†³ç­–...")
        start_time = datetime.now()

        # å¢åŠ  SOP éƒ¨åˆ†ï¼Œç”¨äºåŠ å…¥ decision æ¨¡å—
        # SOPæ”¹æˆä¸­æ–‡ï¼ŒSOPåº”è¯¥è¦çš„æ˜¯æŠ½è±¡çš„ã€‚ä¸èƒ½å†™æ˜¯outlineï¼Œreplannerï¼Œå…·ä½“è°æ¥ç”Ÿæˆæ˜¯è®© CentralAgent è‡ªå·±æ‰¾
        DECISION_SOP_SP = """### æ‰§è¡Œæµç¨‹æŒ‡å—ï¼ˆExecution Workflow Guidelinesï¼‰

        ä½ æ­£åœ¨ä¸€ä¸ªå…·æœ‰**ä¸¥æ ¼é˜¶æ®µçº¦æŸä¸ä¸å¯å›é€€èŠ‚ç‚¹**çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­è¿è¡Œã€‚
        ä½ çš„èŒè´£æ˜¯**ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æµç¨‹æ¨è¿›ä»»åŠ¡ç›´è‡³å®Œæˆ**ï¼Œå¹¶éµå®ˆæ¯ä¸ªé˜¶æ®µçš„è¿›å…¥ä¸é€€å‡ºè§„åˆ™ã€‚
        ä»»ä½•è¿åé˜¶æ®µçº¦æŸçš„è¡Œä¸ºéƒ½è¢«è§†ä¸ºæ‰§è¡Œé”™è¯¯ã€‚

        ---

        #### ğŸ”´ Human Agent ä½¿ç”¨è¯´æ˜ï¼ˆCriticalï¼‰

        **Human Agent** æ˜¯ä¸“é—¨è´Ÿè´£ä¸äººç±»äº¤äº’çš„å­Agentã€‚ä½  **å¿…é¡»** åœ¨ä»¥ä¸‹æƒ…å†µå§”æ´¾ç»™å®ƒï¼š

        1. å½“ä»»æ„ agent è¿”å›æ—¶ï¼Œæ£€æŸ¥ state ä¸­çš„ `need_human_interaction` å­—æ®µï¼š
           - å¦‚æœä¸º `true`ï¼Œ**å¿…é¡»ç«‹å³** å§”æ´¾ç»™ human agent
           - æ ¹æ® `human_interaction_type` è®¾ç½®æ­£ç¡®çš„äº¤äº’ç±»å‹

        2. äº¤äº’ç±»å‹è¯´æ˜ï¼š
           - `form_filling`: perception agent ç”Ÿæˆè¡¨å•åï¼Œéœ€è¦äººç±»å¡«å†™
           - `outline_confirmation`: outline agent ç”Ÿæˆå¤§çº²åï¼Œéœ€è¦äººç±»ç¡®è®¤
           - `report_feedback`: reporter agent ç”ŸæˆæŠ¥å‘Šåï¼Œéœ€è¦äººç±»åé¦ˆ
           - `proactive_question`: ä½ åˆ¤æ–­ä¿¡æ¯ä¸è¶³æ—¶ï¼Œä¸»åŠ¨å‘äººç±»æé—®

        3. ğŸ”´ **äººç±»åé¦ˆä¼˜å…ˆçº§æœ€é«˜**ï¼š
           - æ”¶åˆ° human agent è¿”å›åï¼Œ**å¿…é¡»** å°†äººç±»åé¦ˆä½œä¸ºæœ€é«˜ä¼˜å…ˆçº§è€ƒè™‘
           - **ä¸å¾—** å¿½ç•¥æˆ–è¦†ç›–äººç±»çš„æ˜ç¡®æŒ‡ç¤º
           - åœ¨åç»­ delegate æŒ‡ä»¤ä¸­ï¼Œ**å¿…é¡»** åŒ…å«äººç±»åé¦ˆçš„å…³é”®ä¿¡æ¯

        ---

        #### å¼ºåˆ¶æ€§çš„é«˜å±‚æ‰§è¡Œæµç¨‹ï¼ˆMandatory High-Level Workflowï¼‰

        ### 1. æ„ŸçŸ¥ä¸æ¾„æ¸…é˜¶æ®µï¼ˆPerception Phaseï¼Œå¼ºåˆ¶ï¼Œç¬¬ä¸€æ­¥ï¼Œä¸”ä»…æ­¤ä¸€æ¬¡ï¼‰

        - ä½  **å¿…é¡»** åœ¨ä»»åŠ¡å¼€å§‹æ—¶é¦–å…ˆå§”æ´¾ç»™ **perception agent**
        - perception agent ç”Ÿæˆè¡¨å•åï¼Œä¼šè¿”å›ç»™ä½ å¹¶æ ‡è®° `need_human_interaction: true`
        - æ”¶åˆ°æ­¤æ ‡è®°åï¼Œä½  **å¿…é¡»** ç«‹å³å§”æ´¾ç»™ **human agent**ï¼ˆè®¾ç½® `interaction_type: form_filling`ï¼‰
        - ğŸ”´ äººç±»å¡«å†™çš„è¡¨å•å†…å®¹å…·æœ‰æœ€é«˜ä¼˜å…ˆçº§ï¼Œåç»­æ‰€æœ‰å†³ç­–å¿…é¡»åŸºäºæ­¤
        - **ä¸€æ—¦ perception é˜¶æ®µå®Œæˆå¹¶é€€å‡ºï¼š**
          - åœ¨æ•´ä¸ªä»»åŠ¡ç”Ÿå‘½å‘¨æœŸä¸­ï¼Œ**ç»å¯¹ç¦æ­¢å†æ¬¡è°ƒç”¨ perception agent**

        ---

        ### 2. å¤§çº²æ„å»ºé˜¶æ®µï¼ˆOutline Construction Phaseï¼Œå¼ºåˆ¶ï¼Œæ„ŸçŸ¥å®Œæˆä¹‹åï¼Œä»…ä¸€æ¬¡ï¼‰

        - åœ¨äººç±»å¡«å†™è¡¨å•åï¼Œä½  **å¿…é¡»** å§”æ´¾ç»™ **outline agent**
        - outline agent ç”Ÿæˆå¤§çº²åï¼Œä¼šè¿”å›ç»™ä½ å¹¶æ ‡è®° `need_human_interaction: true`
        - æ”¶åˆ°æ­¤æ ‡è®°åï¼Œä½  **å¿…é¡»** ç«‹å³å§”æ´¾ç»™ **human agent**ï¼ˆè®¾ç½® `interaction_type: outline_confirmation`ï¼‰
        - ğŸ”´ äººç±»ç¡®è®¤/ä¿®æ”¹çš„å¤§çº²å…·æœ‰æœ€é«˜ä¼˜å…ˆçº§
        - å¤§çº²ç¡®è®¤åå³å†»ç»“ï¼Œä¸å¾—é‡æ–°ç”Ÿæˆ

        ---

        ### 3. æ¨ç†ä¸ç ”ç©¶é˜¶æ®µï¼ˆReasoning & Research Phaseï¼Œå¼ºåˆ¶ï¼Œå¤§çº²ç¡®è®¤ä¹‹åï¼‰

        - åœ¨å¤§çº²è¢«ç¡®è®¤ä¹‹åï¼Œä½  **å¿…é¡»** æ‰§è¡Œä¸€ä¸ªé›†ä¸­å¼çš„æ¨ç†ä¸ç ”ç©¶é˜¶æ®µ
        - åœ¨è¯¥é˜¶æ®µï¼Œä¸­æ¢æ™ºèƒ½ä½“ï¼ˆcentral agentï¼‰**å¿…é¡»**ï¼š
          - è‡³å°‘è°ƒç”¨ **Researcher agent** ä¸€æ¬¡
          - ä½¿ç”¨å¯ç”¨å·¥å…·ã€æ–‡æ¡£æˆ–å¤–éƒ¨ä¿¡æ¯æºï¼Œå¯¹å·²ç¡®è®¤çš„å¤§çº²è¿›è¡ŒéªŒè¯ã€è¡¥å……æˆ–è´¨ç–‘
        - è‹¥å‘ç°ä¿¡æ¯ä¸è¶³ï¼Œå¯ä»¥å§”æ´¾ç»™ **human agent** è¿›è¡Œä¸»åŠ¨æé—®ï¼ˆè®¾ç½® `interaction_type: proactive_question`ï¼‰
        - **æ— è®ºå½“å‰ä¿¡æ¯æ˜¯å¦çœ‹ä¼¼å……åˆ†ï¼Œè¯¥é˜¶æ®µéƒ½å¿…é¡»ä¸ºæ¯ä¸€ä¸ªä»»åŠ¡æ‰§è¡Œä¸€æ¬¡**

        ---

        ### 4. å†…å®¹ç”Ÿæˆé˜¶æ®µï¼ˆContent Generation Phaseï¼Œå¼ºåˆ¶ï¼Œæœ€ç»ˆé˜¶æ®µï¼‰

        - åœ¨æ¨ç†ä¸ç ”ç©¶é˜¶æ®µå®Œæˆåï¼Œä½  **å¿…é¡»** å§”æ´¾ç»™ **reporter agent**
        - reporter agent ç”ŸæˆæŠ¥å‘Šåï¼Œä¼šè¿”å›ç»™ä½ å¹¶æ ‡è®° `need_human_interaction: true`
        - æ”¶åˆ°æ­¤æ ‡è®°åï¼Œä½  **å¿…é¡»** å§”æ´¾ç»™ **human agent**ï¼ˆè®¾ç½® `interaction_type: report_feedback`ï¼‰
        - æ ¹æ®äººç±»åé¦ˆå†³å®šæ˜¯å¦éœ€è¦ä¿®æ”¹æŠ¥å‘Š
        - åœ¨ reporter agent å°šæœªç”Ÿæˆæœ€ç»ˆå†…å®¹ä¹‹å‰ï¼Œ**ä¸å¾—è¿›å…¥ FINISH çŠ¶æ€**

        ---

        ### 4.1 ç”¨æˆ·åé¦ˆå¤„ç†å¾ªç¯ï¼ˆUser Feedback Loopï¼Œå…³é”®è¡¥å……ï¼‰

        - ç”¨æˆ·åé¦ˆåˆ†ä¸ºä¸¤ç±»ï¼š
          - **é£æ ¼åˆ‡æ¢**ï¼ˆ[CHANGED_STYLE]ï¼‰ï¼šç›´æ¥å§”æ´¾ reporter agent ä½¿ç”¨æ–°é£æ ¼é‡æ–°ç”ŸæˆæŠ¥å‘Š
          - **å…¶ä»–ä¿®æ”¹æ„è§**ï¼ˆ[CONTENT_MODIFY] ç­‰ï¼‰ï¼šä½ éœ€è¦æ ¹æ®ä¿®æ”¹æ„è§çš„å…·ä½“å†…å®¹å’Œå½“å‰ä¸Šä¸‹æ–‡ï¼Œè‡ªè¡Œåˆ¤æ–­åº”è¯¥å§”æ´¾å“ªäº› agentã€ä»¥ä»€ä¹ˆé¡ºåºæ‰§è¡Œã€‚ä¾‹å¦‚ï¼š
            - å¦‚æœä¿®æ”¹æ„è§æ¶‰åŠè¡¥å……ä¿¡æ¯æˆ–æœç´¢æ›´å¤šèµ„æ–™ï¼Œå¯ä»¥å…ˆå§”æ´¾ researcherï¼Œå†å§”æ´¾ reporter
            - å¦‚æœä¿®æ”¹æ„è§ä»…æ¶‰åŠæªè¾æˆ–ç»“æ„è°ƒæ•´ï¼Œå¯ä»¥ç›´æ¥å§”æ´¾ reporter
            - æ— è®ºç»è¿‡å¤šå°‘ä¸­é—´æ­¥éª¤ï¼Œæœ€ç»ˆéƒ½å¿…é¡»ç”± reporter é‡æ–°ç”ŸæˆæŠ¥å‘Š
        - **reporter agent æ¯æ¬¡é‡æ–°ç”ŸæˆæŠ¥å‘Šåï¼Œéƒ½ä¼šè¿”å›å¹¶æ ‡è®° `need_human_interaction: true`ã€`human_interaction_type: "report_feedback"`**
        - ğŸ”´ **æ­¤æ—¶ä½ å¿…é¡»å†æ¬¡å§”æ´¾ç»™ human agent**ï¼Œè®©ç”¨æˆ·æŸ¥çœ‹æ–°æŠ¥å‘Šå¹¶å†³å®šä¸‹ä¸€æ­¥æ“ä½œ
        - ğŸ”´ **ç»å¯¹ç¦æ­¢åœ¨ `need_human_interaction: true` æ—¶é€‰æ‹© FINISH**â€”â€”è¿™ä¼šå¯¼è‡´ç”¨æˆ·æ°¸è¿œçœ‹ä¸åˆ°é‡æ–°ç”Ÿæˆçš„æŠ¥å‘Š
        - è¿™ä¸ªå¾ªç¯å¯èƒ½é‡å¤å¤šæ¬¡ï¼Œæ¯æ¬¡éƒ½å¿…é¡»ç»è¿‡ human agent
        - **åªæœ‰å½“ç”¨æˆ·æ˜ç¡®å‘é€ [SKIP]ã€[END] æˆ– [FINISH] åé¦ˆåï¼Œæ‰å¯ä»¥è¿›å…¥ FINISH çŠ¶æ€**

        ---

        #### ä¸»åŠ¨æé—®æœºåˆ¶ï¼ˆProactive Questioningï¼‰

        åœ¨ä»»ä½•é˜¶æ®µï¼Œå¦‚æœä½ åˆ¤æ–­å½“å‰ä¿¡æ¯ä¸è¶³ä»¥ç»§ç»­æ‰§è¡Œä»»åŠ¡ï¼Œå¯ä»¥å§”æ´¾ç»™ **human agent** è¿›è¡Œä¸»åŠ¨æé—®ï¼š

        ```json
        {
          "action": "delegate",
          "reasoning": "å½“å‰ä¿¡æ¯ä¸è¶³ï¼Œéœ€è¦å‘ç”¨æˆ·è¯¢é—®å…·ä½“é—®é¢˜",
          "params": {
            "agent_type": "human",
            "task_description": "å‘ç”¨æˆ·è¯¢é—®å…³äºXXXçš„å…·ä½“ä¿¡æ¯",
            "interaction_type": "proactive_question",
            "question": "ä½ éœ€è¦é—®çš„å…·ä½“é—®é¢˜"
          },
          "instruction": "å§”æ´¾ç»™ Human Agent è¿›è¡Œä¸»åŠ¨æé—®"
        }
        ```

        ---

        #### DELEGATE to Human Agent ç¤ºä¾‹

        å½“æ”¶åˆ° `need_human_interaction: true` æ—¶ï¼Œå¿…é¡»è¿™æ ·å§”æ´¾ï¼š

        ```json
        {
          "action": "delegate",
          "reasoning": "Perception agent å·²ç”Ÿæˆè¡¨å•ï¼Œéœ€è¦äººç±»å¡«å†™åæ‰èƒ½ç»§ç»­",
          "params": {
            "agent_type": "human",
            "task_description": "è¯·äººç±»å¡«å†™è¡¨å•",
            "interaction_type": "form_filling"
          },
          "instruction": "å§”æ´¾ç»™ Human Agent æ”¶é›†äººç±»è¾“å…¥"
        }
        ```

        ---

        #### æ‰§è¡Œçº¦æŸä¸ç¦æ­¢è¡Œä¸ºï¼ˆHard Constraints & Prohibited Actionsï¼‰

        - æ‰§è¡Œé¡ºåº **å¿…é¡»ä¸¥æ ¼éµå¾ª**ï¼š
          **æ„ŸçŸ¥ â†’ [Human] â†’ å¤§çº² â†’ [Human] â†’ ç ”ç©¶ â†’ æŠ¥å‘Š â†’ [Human] â†’ (åé¦ˆå¾ªç¯: [æ ¹æ®åé¦ˆå†…å®¹è‡ªè¡Œå†³å®šä¸­é—´æ­¥éª¤] â†’ æŠ¥å‘Š â†’ [Human] â†’) â†’ å®Œæˆ**
        - ğŸ”´ å½“ `need_human_interaction: true` æ—¶ï¼Œ**å¿…é¡»** å§”æ´¾ç»™ human agentï¼Œ**ä¸å¾—è·³è¿‡**ï¼Œ**ä¸å¾—é€‰æ‹© FINISH æˆ–å…¶ä»–ä»»ä½•åŠ¨ä½œ**
        - ğŸ”´ **FINISH çš„å‰ç½®æ¡ä»¶**ï¼šåªæœ‰å½“ `need_human_interaction` ä¸º `false` ä¸”ç”¨æˆ·å·²æ˜ç¡®ç¡®è®¤ï¼ˆå‘é€ [SKIP]/[END]/[FINISH]ï¼‰åï¼Œæ‰å…è®¸è¿›å…¥ FINISH çŠ¶æ€
        - perception é˜¶æ®µä¸ outline é˜¶æ®µï¼š
          - **å‡ä¸ºä¸€æ¬¡æ€§é˜¶æ®µ**
          - **å‡ä¸å¯é‡å¤ã€ä¸å¯å›é€€ã€ä¸å¯é‡æ–°è¿›å…¥**

        ---

        #### å¼ºåˆ¶ç ”ç©¶è°ƒç”¨è§„åˆ™ï¼ˆMandatory Research Invocationï¼‰

        - åœ¨ **æ¯ä¸€æ¬¡ä»»åŠ¡æ‰§è¡Œä¸­**ï¼ŒResearcher agent **å¿…é¡»** ä½œä¸ºã€Œæ¨ç†ä¸ç ”ç©¶é˜¶æ®µã€çš„ä¸€éƒ¨åˆ†è¢«çœŸå®è°ƒç”¨
        - **ä¸å¾—è·³è¿‡ã€ä¼ªé€ æˆ–æ¨¡æ‹Ÿè¯¥é˜¶æ®µ**
        - åœ¨æœªçœŸå®è°ƒç”¨ Researcher agent çš„æƒ…å†µä¸‹ç»§ç»­æ‰§è¡Œï¼Œæ˜¯è¢«æ˜ç¡®ç¦æ­¢çš„

        ---

        ä½ çš„ç›®æ ‡æ˜¯ï¼š
        åœ¨ä¸¥æ ¼éµå¾ªä¸Šè¿°ä¸å¯å›é€€æ‰§è¡Œæµç¨‹çš„å‰æä¸‹ï¼Œç¡®ä¿ä»»åŠ¡åœ¨ç»“æ„ä¸Šç¨³å®šã€åœ¨äººæœºäº¤äº’ä¸Šå¯æ§ï¼Œå¹¶å®ç°å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å¯é ååŒã€‚
        """

        # è¿™ä¸ªä¼¼ä¹è¦æ”¹å…¶ä»–åœ°æ–¹ï¼Œåæ­£åé¢ç”¨ä¸ä¸Šï¼Œä¸è¦äº†
        # graph_format=config["configurable"]["graph_format"]
        # if graph_format=="sp_xxqg":
        #     state["sop"] = DECISION_SOP_SP
        #     logger.info(f"ä½¿ç”¨ SP çš„ SOP")
        # else:
        #     state["sop"] = None
        #     logger.info(f"ä¸ä½¿ç”¨ SOP")
        state["sop"] = DECISION_SOP_SP
        logger.info(f"ä½¿ç”¨ SP çš„ SOP")

        # æ„å»ºå†³ç­–prompt
        messages = self._build_decision_prompt(state, config)
        logger.debug(f"å†³ç­–prompt: {messages}")

        # è·å–LLMå†³ç­–å¹¶å¤„ç†å¼‚å¸¸
        try:
            llm = get_llm_by_type(
                AGENT_LLM_MAP.get("central_agent", "default")
            ).with_structured_output(
                Decision,
                method="json_mode",
            )
            response = llm.invoke(messages)

            # è§£æå†³ç­–ç»“æœ
            action = CentralAgentAction(response.action)
            reasoning = response.reasoning
            params = response.params or {}
            instruction = response.instruction or self.action_instructions.get(
                action, ""
            )
            if state.get("locale") == None:
                locale = response.locale or "zh-CN"
                # å°† locale æ·»åŠ åˆ° state
                state["locale"] = locale

            logger.info(f"å†³ç­–ç»“æœ: {response}")
            end_time = datetime.now()
            time_entry = {
                "step_name": "central decision" + start_time.isoformat(),
                "start_time": start_time.isoformat(),
                "end_time": end_time.isoformat(),
                "duration": (end_time - start_time).total_seconds(),
            }
            global_statistics.add_time_entry(time_entry)

            return CentralDecision(
                action=action,
                reasoning=reasoning,
                params=params,
                instruction=instruction,
            )

        except Exception as e:
            import traceback

            logger.error(
                f"å†³ç­–è§£æå¤±è´¥:  (å°è¯• {retry_count + 1}/{max_retries}): {str(e)}"
            )
            logger.error("è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼š\n" + traceback.format_exc())
            if retry_count < max_retries - 1:
                return self.make_decision(state, config, retry_count + 1)
            # å¼‚å¸¸æƒ…å†µä¸‹è¿”å›é»˜è®¤å†³ç­–
            end_time = datetime.now()
            time_entry = {
                "step_name": "central_decision" + start_time.isoformat(),
                "start_time": start_time.isoformat(),
                "end_time": end_time.isoformat(),
                "duration": (end_time - start_time).total_seconds(),
            }
            global_statistics.add_time_entry(time_entry)
            return CentralDecision(
                action=CentralAgentAction.THINK,
                reasoning="å†³ç­–è§£æå¤±è´¥ï¼Œé»˜è®¤é€‰æ‹©æ€è€ƒåŠ¨ä½œ",
                params={},
                instruction=self.action_instructions[CentralAgentAction.THINK],
            )

    def _build_decision_prompt(
        self,
        state: State,
        config: RunnableConfig,
    ) -> List[Union[AIMessage, HumanMessage]]:
        """
        æ„å»ºä¸­æ¢Agentå†³ç­–æç¤ºè¯ï¼Œä½¿ç”¨ç»Ÿä¸€çš„promptæ¨¡æ¿

        Args:
            context: å†³ç­–ä¸Šä¸‹æ–‡ï¼ˆå·²åŒ…å«æ‰€æœ‰å…³é”®å‚æ•°ï¼‰
            config: è¿è¡Œé…ç½®
            action_options: å¯ç”¨åŠ¨ä½œé€‰é¡¹

        Returns:
            æ ¼å¼åŒ–çš„æç¤ºè¯æ¶ˆæ¯åˆ—è¡¨
        """
        messages_history = state.get("messages", [])
        SOP = state.get("sop", None)
        converted_messages = []
        for msg in messages_history:
            if isinstance(msg, (HumanMessage, AIMessage)):
                converted_messages.append(
                    {
                        "role": msg.type,
                        "content": msg.content,
                        "additional_kwargs": getattr(msg, "additional_kwargs", {}),
                    }
                )
            else:
                converted_messages.append(msg)

        # æå–ç”¨æˆ·åé¦ˆç›¸å…³çš„ state å˜é‡ï¼ˆå…·ä½“æ¸²æŸ“é€»è¾‘å·²è¿ç§»åˆ° central_agent.md æ¨¡æ¿ï¼‰
        need_human_interaction = state.get("need_human_interaction", False)
        human_interaction_type = state.get("human_interaction_type", "")
        hitl_feedback = state.get("hitl_feedback", "")

        context = {
            "available_actions": [action.value for action in CentralAgentAction],
            "available_sub_agents": self.available_sub_agents,
            "sub_agents_description": self.sub_agents_description,
            "current_action": "decision",
            "messages_history": converted_messages,
            "locale": state.get("locale", "zh-CN"),  # ç¡®ä¿localeè¢«ä¼ é€’åˆ°æ¨¡æ¿
            "hitl_feedback": hitl_feedback,
            "SOP": SOP,
            "need_human_interaction": need_human_interaction,
            "human_interaction_type": human_interaction_type,
        }
        action_options = list(CentralAgentAction)
        # åŠ è½½æ­£ç¡®çš„æ¨¡æ¿åç§°å¹¶åˆå¹¶åŠ¨ä½œé€‰é¡¹
        context_with_actions = {
            **context,
            **config,
            "available_actions": ", ".join([a.value for a in action_options]),
        }
        return apply_prompt_template(
            "central_agent", state, extra_context=context_with_actions
        )

    def execute_action(
        self, decision: CentralDecision, state: State, config: RunnableConfig
    ) -> Command:
        """
        æ‰§è¡Œå†³ç­–åŠ¨ä½œï¼Œè°ƒåº¦å¯¹åº”çš„åŠ¨ä½œå¤„ç†å™¨

        Args:
            decision: å†³ç­–ç»“æœ
            state: å½“å‰ç³»ç»ŸçŠ¶æ€
            config: è¿è¡Œé…ç½®

        Returns:
            åŠ¨ä½œæ‰§è¡Œç»“æœCommandå¯¹è±¡
        """
        handler = self.action_handlers.get(decision.action)
        if not handler:
            error_msg = f"æœªçŸ¥åŠ¨ä½œ: {decision.action}"
            logger.error(error_msg)
            return Command(
                update={
                    "messages": [
                        AIMessage(
                            content=f"é”™è¯¯ï¼šæœªçŸ¥åŠ¨ä½œ: {decision.action}",
                            name="central_error",
                        )
                    ],
                    "locale": state.get("locale"),
                    "current_node": "central_agent",
                    "memory_stack": self.memory_stack.to_dict(),
                },
                goto="central_agent",
            )

        return handler(decision, state, config)

    def _handle_think(
        self, decision: CentralDecision, state: State, config: RunnableConfig
    ) -> Command:
        """å¤„ç†æ€è€ƒåŠ¨ä½œï¼Œåˆ†æå½“å‰çŠ¶æ€ç”Ÿæˆä¸‹ä¸€æ­¥è®¡åˆ’"""
        logger.info("ä¸­æ¢Agentæ­£åœ¨æ€è€ƒ...")
        start_time = datetime.now()
        context = {
            "current_action": "think",
            "current_progress": state.get("observations", []),
            "decision_reasoning": decision.reasoning,
            "instruction": decision.instruction,
            "locale": state.get("locale", "zh-CN"),  # ç¡®ä¿localeè¢«ä¼ é€’åˆ°æ¨¡æ¿
        }

        # åº”ç”¨ç»Ÿä¸€çš„å†³ç­–æç¤ºæ¨¡æ¿
        messages = apply_prompt_template("central_agent", state, extra_context=context)

        llm = get_llm_by_type(AGENT_LLM_MAP.get("central_agent", "default"))
        response = llm.invoke(messages)

        # è®°å½•æ€è€ƒè¿‡ç¨‹åˆ°è®°å¿†æ ˆ
        memory_entry = MemoryStackEntry(
            timestamp=datetime.now().isoformat(),
            action="think",
            content=response.content,
        )
        self.memory_stack.push(memory_entry)

        logger.info(f"central_think: {response.content}")
        end_time = datetime.now()
        time_entry = {
            "step_name": "central_think" + start_time.isoformat(),
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration": (end_time - start_time).total_seconds(),
        }
        global_statistics.add_time_entry(time_entry)
        return Command(
            update={
                "messages": [AIMessage(content=response.content, name="central_think")],
                "current_node": "central_agent",
                "memory_stack": json.dumps(
                    [entry.to_dict() for entry in self.memory_stack.get_all()]
                ),
                "locale": state.get("locale"),
            },
            goto="central_agent",
        )

    def _handle_reflect(
        self, decision: CentralDecision, state: State, config: RunnableConfig
    ) -> Command:
        """å¤„ç†åæ€åŠ¨ä½œï¼Œè¯„ä¼°ä¹‹å‰çš„æ­¥éª¤å¹¶æ¸…ç†è®°å¿†æ ˆ"""
        logger.info("ä¸­æ¢Agentæ­£åœ¨åæ€...")
        start_time = datetime.now()

        # è·å–åæ€ç›®æ ‡å’Œä¸Šä¸‹æ–‡
        # recent_memory = self.memory_stack.get_recent(5)  # è·å–æœ€è¿‘5æ¡è®°å¿†

        context = {
            "current_action": "reflect",
            "decision_reasoning": decision.reasoning,
            "instruction": decision.instruction,
            "locale": state.get("locale", "zh-CN"),  # ç¡®ä¿localeè¢«ä¼ é€’åˆ°æ¨¡æ¿
        }

        # åº”ç”¨åæ€æç¤ºæ¨¡æ¿
        messages = apply_prompt_template("central_agent", state, extra_context=context)

        llm = get_llm_by_type(AGENT_LLM_MAP.get("central_agent", "default"))
        response = llm.invoke(messages)

        # è§£æåæ€ç»“æœçš„JSON
        try:
            reflection_data = json.loads(repair_json_output(response.content))
            analysis = reflection_data.get("analysis", "åæ€åˆ†æ")
            pop_count = reflection_data.get("pop_count", 0)
            reasoning = reflection_data.get("reasoning", "åæ€å®Œæˆ")

            # éªŒè¯pop_countæ˜¯æœ‰æ•ˆæ•°å­—
            if not isinstance(pop_count, int) or pop_count < 0:
                logger.warning(f"æ— æ•ˆçš„pop_count: {pop_count}ï¼Œè®¾ç½®ä¸º0")
                pop_count = 0

        except Exception as e:
            logger.error(f"åæ€ç»“æœè§£æå¤±è´¥: {e}")
            analysis = response.content
            pop_count = 0
            reasoning = "JSONè§£æå¤±è´¥ï¼Œä¿æŒç°æœ‰è®°å¿†æ ˆ"

        logger.debug(f"reflectå†³å®šæ¸…ç†{pop_count}æ¡æ¶ˆæ¯")
        # æ‰§è¡Œè®°å¿†æ ˆæ¸…ç†
        removed_items = []
        if pop_count > 0:
            reflection_content = (
                f"åæ€åˆ†æ: {analysis}\n"
                f"åæ€åŸå› : {reasoning}\n"
                f"æ¸…ç†äº† {pop_count} æ¡è®°å¿†ã€‚"
            )

            memory_entry = MemoryStackEntry(
                timestamp=datetime.now().isoformat(),
                action="reflect",
                content=reflection_content,
            )

            self.memory_stack.push_with_pop(memory_entry, pop_count)

            removed_items = self.memory_stack.pop(pop_count)

            logger.info(f"æˆåŠŸä»è®°å¿†æ ˆä¸­ç§»é™¤äº† {pop_count} é¡¹è®°å¿†")
            # logger.info(
            #     f"ä»è®°å¿†æ ˆä¸­ç§»é™¤äº† {len(removed_items)} é¡¹: {[item.action for item in removed_items]}"
            # )
        else:
            logger.info("ä¸ç§»é™¤ä»»ä½•è®°å¿†æ ˆé¡¹ç›®")

        logger.info(f"central_reflect: {analysis}")
        end_time = datetime.now()
        time_entry = {
            "step_name": "central_reflect" + start_time.isoformat(),
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration": (end_time - start_time).total_seconds(),
        }
        global_statistics.add_time_entry(time_entry)
        return Command(
            update={
                "messages": [AIMessage(content=analysis, name="central_reflect")],
                "reflection": {
                    "analysis": analysis,
                    "pop_count": len(removed_items),
                    "reasoning": reasoning,
                    "removed_items": removed_items,
                },
                "current_node": "central_agent",
                "memory_stack": json.dumps(
                    [entry.to_dict() for entry in self.memory_stack.get_all()]
                ),
                "locale": state.get("locale"),
            },
            goto="central_agent",
        )

    def _handle_summarize(
        self, decision: CentralDecision, state: State, config: RunnableConfig
    ) -> Command:
        """å¤„ç†æ€»ç»“åŠ¨ä½œï¼Œå½’çº³å½“å‰å·²è·å¾—çš„ä¿¡æ¯"""
        logger.info("ä¸­æ¢Agentæ­£åœ¨æ€»ç»“...")
        start_time = datetime.now()

        context = {
            "current_action": "summarize",
            "summarization_focus": decision.reasoning,
            "instruction": decision.instruction,
            "locale": state.get("locale", "zh-CN"),  # ç¡®ä¿localeè¢«ä¼ é€’åˆ°æ¨¡æ¿
        }

        # æ‰“å°ä¸Šä¸‹æ–‡ç”¨äºè°ƒè¯•
        logger.debug(
            f"Summarize context: {json.dumps(context, ensure_ascii=False, indent=2)}"
        )

        # åº”ç”¨ç»Ÿä¸€çš„æ€»ç»“æç¤ºæ¨¡æ¿
        messages = apply_prompt_template("central_agent", state, extra_context=context)

        llm = get_llm_by_type(AGENT_LLM_MAP.get("central_agent", "default"))
        response = llm.invoke(messages)

        # æ›´æ–°è®°å¿†æ ˆï¼Œæ›¿æ¢æœ€æ–°çš„æ€»ç»“ç»“æœ
        new_entry = MemoryStackEntry(
            timestamp=datetime.now().isoformat(),
            action="summarize",
            content=context.get("summarization_focus", ""),
            result={"summary_result": response.content},
        )

        # logger.info("NEW_ENTRY", new_entry)
        # logger.info("*"*100)

        self.memory_stack.push_with_pop(new_entry)

        # logger.info(f"central_summarize: {response.content}")
        end_time = datetime.now()
        time_entry = {
            "step_name": "central_summarize" + start_time.isoformat(),
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration": (end_time - start_time).total_seconds(),
        }
        global_statistics.add_time_entry(time_entry)
        return Command(
            update={
                "messages": [
                    AIMessage(content=response.content, name="central_summarize")
                ],
                "summary": response.content,
                "current_node": "central_agent",
                "memory_stack": json.dumps(
                    [entry.to_dict() for entry in self.memory_stack.get_all()]
                ),
                "locale": state.get("locale"),
            },
            goto="central_agent",
        )

    def _handle_delegate(
        self, decision: CentralDecision, state: State, config: RunnableConfig
    ) -> Command:
        """å¤„ç†å§”æ´¾åŠ¨ä½œï¼Œè°ƒåº¦å­Agentæ‰§è¡Œä¸“é¡¹ä»»åŠ¡"""
        agent_type = decision.params.agent_type
        task_description = decision.params.task_description
        # agent_type = decision.agent_type
        # task_description = decision.task_description or "æœªæŒ‡å®šä»»åŠ¡"

        # éªŒè¯å­Agentç±»å‹æœ‰æ•ˆæ€§
        if not agent_type or agent_type not in self.available_sub_agents:
            error_msg = (
                f"æ— æ•ˆçš„å­Agentç±»å‹: {agent_type}ï¼Œå¯ç”¨ç±»å‹: "
                f"{self.available_sub_agents}"
            )
            logger.error(f"central_error: {error_msg}")
            return Command(
                update={
                    "messages": [AIMessage(content=error_msg, name="central_error")],
                    "current_node": "central_agent",
                },
                goto="central_agent",
            )

        logger.info(f"ä¸­æ¢Agentå§”æ´¾ {agent_type} æ‰§è¡Œä»»åŠ¡: {task_description}")

        # è®°å½•å§”æ´¾åŠ¨ä½œåˆ°è®°å¿†æ ˆ
        memory_entry = MemoryStackEntry(
            timestamp=datetime.now().isoformat(),
            action="delegate",
            agent_type=agent_type,
            content=f"å§”æ´¾ä»»åŠ¡: {task_description}",
        )
        self.memory_stack.push(memory_entry)

        # æ„å»ºå­Agentæ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆåŒ…å«è®°å¿†æ ˆæ‘˜è¦ï¼‰
        delegation_context = {
            "task_description": task_description,
            "agent_type": agent_type,
            "memory_context": self.memory_stack.get_summary(include_full_history=True),
            "original_query": state.get("user_query", ""),
        }
        # è‹¥ä¸ºå†…å®¹ä¿®æ”¹å¯¼è‡´çš„ reporter å§”æ´¾ï¼Œæ¸…ç† hitl_feedback ä»¥é¿å… reporter åå¤å¤„ç†åŒä¸€æ¡åé¦ˆ
        hitl_feedback = state.get("hitl_feedback", "")
        clear_hitl_feedback = False
        if (
            agent_type == "reporter"
            and isinstance(hitl_feedback, str)
            and hitl_feedback.upper().startswith("[CONTENT_MODIFY]")
        ):
            clear_hitl_feedback = True
            modify_request = hitl_feedback[len("[CONTENT_MODIFY]") :].strip()
            if modify_request:
                delegation_context["content_modify_request"] = modify_request
            delegation_context["skip_hitl_feedback"] = True

        # ä¼ é€’ decision.params ä¸­çš„é¢å¤–å­—æ®µï¼ˆå¦‚ interaction_type, question ç­‰ï¼‰
        # è¿™å¯¹äº Human Agent æ¥è¯´æ˜¯å¿…éœ€çš„
        if hasattr(decision.params, "model_dump"):  # Pydantic v2
            params_dict = decision.params.model_dump()
            for key, value in params_dict.items():
                if key not in delegation_context and value is not None:
                    delegation_context[key] = value
        elif hasattr(decision.params, "dict"):  # Pydantic v1
            params_dict = decision.params.dict()
            for key, value in params_dict.items():
                if key not in delegation_context and value is not None:
                    delegation_context[key] = value
        elif isinstance(decision.params, dict):
            for key, value in decision.params.items():
                if key not in delegation_context and value is not None:
                    delegation_context[key] = value

        logger.info(f"central_delegate: å§”æ´¾{agent_type}æ‰§è¡Œ: {task_description}")
        return Command(
            update={
                "messages": [
                    AIMessage(
                        content=f"å§”æ´¾{agent_type}æ‰§è¡Œ: {task_description}",
                        name="central_delegate",
                    )
                ],
                "delegation_context": delegation_context,
                "current_node": "central_agent",
                "memory_stack": json.dumps(
                    [entry.to_dict() for entry in self.memory_stack.get_all()]
                ),
                "locale": state.get("locale"),
                **({"hitl_feedback": ""} if clear_hitl_feedback else {}),
            },
            goto=agent_type,
        )

    def _handle_finish(
        self, decision: CentralDecision, state: State, config: RunnableConfig
    ) -> Command:
        """å¤„ç†å®ŒæˆåŠ¨ä½œï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¹¶ç»“æŸä»»åŠ¡"""
        logger.info("ä¸­æ¢Agentå®Œæˆä»»åŠ¡...")

        final_report = state.get("final_report", None)
        if not final_report:
            logger.info("æœªæ‰¾åˆ°æœ€ç»ˆæŠ¥å‘Šï¼Œå§”æ´¾Reporter Agentç”ŸæˆæŠ¥å‘Š...")

            # è®°å½•å§”æ´¾åŠ¨ä½œåˆ°è®°å¿†æ ˆ
            memory_entry = MemoryStackEntry(
                timestamp=datetime.now().isoformat(),
                action="delegate",
                agent_type="reporter",
                content="æœªç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šï¼Œå§”æ´¾Reporter Agentç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š",
            )
            self.memory_stack.push(memory_entry)

            # æ„å»ºReporteræ‰§è¡Œä¸Šä¸‹æ–‡
            delegation_context = {
                "task_description": "æ ¹æ®æ‰€æœ‰æ”¶é›†åˆ°çš„ä¿¡æ¯ç”Ÿæˆå®Œæ•´çš„æœ€ç»ˆæŠ¥å‘Š",
                "agent_type": "reporter",
                "memory_context": self.memory_stack.get_summary(
                    include_full_history=True
                ),
                "original_query": state.get("user_query", ""),
                "report_type": "final_report",
                "execution_history": [
                    entry.to_dict() for entry in self.memory_stack.get_all()
                ],
            }

            logger.info("central_delegate_reporter: å§”æ´¾Reporter Agentç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
            return Command(
                update={
                    "messages": [
                        AIMessage(
                            content="å§”æ´¾Reporter Agentç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š",
                            name="central_delegate_reporter",
                        )
                    ],
                    "delegation_context": delegation_context,
                    "current_node": "central_agent",
                    "memory_stack": json.dumps(
                        [entry.to_dict() for entry in self.memory_stack.get_all()]
                    ),
                    "pending_finish": True,  # æ ‡è®°ç­‰å¾…æŠ¥å‘Šå®Œæˆåå†finish
                },
                goto="reporter",
            )
        logger.info(f"final_report: {final_report}")

        # æ„å»ºæ‰§è¡Œæ‘˜è¦ï¼ˆåŒ…å«å®Œæ•´è®°å¿†æ ˆå†å²ï¼‰
        execution_summary = {
            "user_query": state.get("user_query", "æœªçŸ¥æŸ¥è¯¢"),
            "execution_history": [
                entry.to_dict() for entry in self.memory_stack.get_all()
            ],
            "final_report": final_report,
            "completion_time": datetime.now().isoformat(),
            "statistics": global_statistics.get_statistics(),
        }

        # ä¿å­˜æ‰§è¡Œæ‘˜è¦åˆ°æ–‡ä»¶
        os.makedirs("./reports", exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"./reports/execution_report_{timestamp}.json"

        try:
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(execution_summary, f, ensure_ascii=False, indent=4)
            report_msg = f"ä»»åŠ¡å®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜: {filename}"
        except Exception as e:
            logger.error(f"æŠ¥å‘Šä¿å­˜å¤±è´¥: {str(e)}")
            report_msg = f"ä»»åŠ¡å®Œæˆï¼Œä½†æŠ¥å‘Šä¿å­˜å¤±è´¥: {str(e)}"
            execution_summary["error"] = str(e)

        logger.info(report_msg)
        logger.info(global_statistics.get_statistics())
        return Command(
            goto="zip_data",  # ç»“æŸæ‰§è¡Œ
        )
