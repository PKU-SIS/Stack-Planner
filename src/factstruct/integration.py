"""
FactStruct Stage 1 é›†æˆæ¨¡å—

æä¾›äº†ä¸ç°æœ‰ç³»ç»Ÿé›†æˆçš„ä¾¿æ·æ¥å£ã€‚
"""

from typing import List, Optional, Callable, Tuple
from langchain_core.language_models import BaseChatModel

from src.utils.logger import logger
from src.llms.llm import get_llm_by_type
from src.config.agents import AGENT_LLM_MAP
from src.tools.get_docs_info import search_docs
from .batch_mab import BatchMAB
from .embedder import Embedder
from .llm_wrapper import FactStructLLMWrapper
from .document import FactStructDocument
from .outline_node import OutlineNode
from .memory import Memory


def create_search_engine_adapter(
    search_func: Callable = None,
) -> Callable[[str, int], List[FactStructDocument]]:
    """
    åˆ›å»ºæœç´¢å¼•æ“é€‚é…å™¨

    å°†ç°æœ‰çš„ search_docs å‡½æ•°é€‚é…ä¸º FactStruct éœ€è¦çš„æ ¼å¼ã€‚

    å‚æ•°:
        search_func: æœç´¢å‡½æ•°ï¼Œç­¾å (question: str, top_k: int) -> List[dict]
                    å¦‚æœä¸æä¾›ï¼Œä½¿ç”¨é»˜è®¤çš„ search_docs

    è¿”å›:
        é€‚é…åçš„æœç´¢å‡½æ•°ï¼Œç­¾å (query: str, k: int) -> List[FactStructDocument]
    """
    if search_func is None:
        search_func = search_docs

    def adapter(query: str, k: int) -> List[FactStructDocument]:
        """
        é€‚é…åçš„æœç´¢å‡½æ•°

        å‚æ•°:
            query: æœç´¢æŸ¥è¯¢
            k: è¿”å›æ–‡æ¡£æ•°é‡

        è¿”å›:
            FactStructDocument åˆ—è¡¨
        """
        from datetime import datetime

        # è°ƒç”¨åŸå§‹æœç´¢å‡½æ•°
        results = search_func(query, top_k=k)

        # è½¬æ¢ä¸º FactStructDocument
        documents = []
        for i, result in enumerate(results):
            doc_id = f"doc_{hash(result.get('content', ''))}_{i}"
            doc = FactStructDocument(
                id=doc_id,
                text=result.get("content", ""),
                source_type=result.get("source", "unknown"),
                timestamp=datetime.now(),  # å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                url=None,
                title=None,
            )
            documents.append(doc)

        return documents

    return adapter


def run_factstruct_stage1(
    query: str,
    llm: Optional[BaseChatModel] = None,
    max_iterations: int = 20,
    batch_size: int = 5,
    initial_docs: Optional[List[FactStructDocument]] = None,
    search_engine: Optional[Callable] = None,
) -> Tuple[OutlineNode, Memory]:
    """
    è¿è¡Œ FactStruct Stage 1ï¼ˆä¾¿æ·æ¥å£ï¼‰

    å‚æ•°:
        query: ç”¨æˆ·æŸ¥è¯¢
        llm: LLM å®ä¾‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ "outline" ç±»å‹çš„ LLMï¼‰
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤ 20ï¼‰
        batch_size: æ‰¹é‡å¤§å°ï¼ˆé»˜è®¤ 5ï¼‰
        initial_docs: åˆå§‹æ–‡æ¡£åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        search_engine: æœç´¢å¼•æ“å‡½æ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ search_docsï¼‰

    è¿”å›:
        (outline_root, memory): æœ€ç»ˆå¤§çº²æ ¹èŠ‚ç‚¹å’Œè®°å¿†æ¨¡å—
    """
    # åˆå§‹åŒ–ç»„ä»¶
    if llm is None:
        # ä½¿ç”¨ AGENT_LLM_MAP è·å– outline å¯¹åº”çš„ LLM ç±»å‹ï¼ˆæ˜ å°„åˆ° "basic"ï¼‰
        llm_type = AGENT_LLM_MAP.get("outline", "basic")
        llm = get_llm_by_type(llm_type)

    if search_engine is None:
        search_engine = create_search_engine_adapter()

    embedder = Embedder()
    llm_wrapper = FactStructLLMWrapper(llm)

    # åˆ›å»º Batch-MAB å®ä¾‹
    batch_mab = BatchMAB(
        llm_wrapper=llm_wrapper,
        embedder=embedder,
        search_engine=search_engine,
        max_iterations=max_iterations,
        batch_size=batch_size,
    )

    # è¿è¡Œç®—æ³•
    outline_root, memory = batch_mab.run(
        initial_query=query,
        initial_docs=initial_docs,
    )

    return outline_root, memory


def outline_node_to_text(outline_root: OutlineNode) -> str:
    """
    å°† OutlineNode è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼ï¼ˆç”¨äºä¿å­˜åˆ° Stateï¼‰

    å‚æ•°:
        outline_root: å¤§çº²æ ¹èŠ‚ç‚¹

    è¿”å›:
        æ–‡æœ¬æ ¼å¼çš„å¤§çº²
    """
    return outline_root.to_text_tree()


def outline_node_to_markdown(
    outline_root: OutlineNode,
    max_depth: Optional[int] = None,
    include_root: bool = True,
) -> str:
    """
    å°† OutlineNode è½¬æ¢ä¸º Markdown æ ¼å¼

    å‚æ•°:
        outline_root: å¤§çº²æ ¹èŠ‚ç‚¹
        max_depth: æœ€å¤§å±‚çº§æ·±åº¦ï¼ˆNone è¡¨ç¤ºä¸é™åˆ¶æ·±åº¦ï¼Œæ‰“å°å®Œæ•´å¤§çº²ï¼‰
                  - æ ¹èŠ‚ç‚¹ä¸ºç¬¬1å±‚
                  - å¦‚æœ include_root=Trueï¼Œmax_depth=3 è¡¨ç¤ºæ ¹+2å±‚å­èŠ‚ç‚¹
        include_root: æ˜¯å¦åŒ…å«æ ¹èŠ‚ç‚¹ï¼ˆé»˜è®¤Trueï¼‰

    è¿”å›:
        Markdown æ ¼å¼çš„å¤§çº²å­—ç¬¦ä¸²
    """

    def node_to_markdown(
        node: OutlineNode, current_level: int = 1, parent_indent: str = ""
    ) -> str:
        """
        é€’å½’å°†èŠ‚ç‚¹è½¬æ¢ä¸ºMarkdownæ ¼å¼

        å‚æ•°:
            node: å½“å‰èŠ‚ç‚¹
            current_level: å½“å‰å±‚çº§ï¼ˆ1è¡¨ç¤ºæ ¹èŠ‚ç‚¹ï¼Œ2è¡¨ç¤ºç¬¬ä¸€å±‚å­èŠ‚ç‚¹ï¼Œä»¥æ­¤ç±»æ¨ï¼‰
            parent_indent: çˆ¶èŠ‚ç‚¹çš„ç¼©è¿›å­—ç¬¦ä¸²
        """
        # æ£€æŸ¥æ·±åº¦é™åˆ¶
        if max_depth is not None and current_level > max_depth:
            return ""

        result = ""

        # æ ¹èŠ‚ç‚¹ç‰¹æ®Šå¤„ç†
        if current_level == 1 and include_root:
            result = f"- {node.title}\n"
            # æ ¹èŠ‚ç‚¹çš„å­èŠ‚ç‚¹åº”è¯¥æœ‰2ä¸ªç©ºæ ¼ç¼©è¿›
            child_indent = "  "
        else:
            # éæ ¹èŠ‚ç‚¹ï¼šç¼©è¿› = çˆ¶èŠ‚ç‚¹ç¼©è¿› + 2ä¸ªç©ºæ ¼
            child_indent = parent_indent + "  "

        # å¤„ç†å­èŠ‚ç‚¹
        for child in node.children:
            # è®¡ç®—å½“å‰å­èŠ‚ç‚¹çš„ç¼©è¿›
            # å¦‚æœæ˜¯æ ¹èŠ‚ç‚¹çš„å­èŠ‚ç‚¹ï¼ˆlevel 2ï¼‰ï¼Œç¼©è¿›æ˜¯2ä¸ªç©ºæ ¼
            # å¦‚æœæ˜¯å­èŠ‚ç‚¹çš„å­èŠ‚ç‚¹ï¼Œç¼©è¿›æ˜¯çˆ¶èŠ‚ç‚¹ç¼©è¿› + 2ä¸ªç©ºæ ¼
            result += f"{child_indent}- {child.title}\n"

            # é€’å½’å¤„ç†å­èŠ‚ç‚¹çš„å­èŠ‚ç‚¹
            if max_depth is None or current_level + 1 <= max_depth:
                child_markdown = node_to_markdown(
                    child, current_level + 1, child_indent
                )
                result += child_markdown

        return result

    markdown_text = node_to_markdown(outline_root, 1)
    return markdown_text.strip()


def outline_node_to_json(outline_root: OutlineNode) -> str:
    """
    å°† OutlineNode è½¬æ¢ä¸º JSON æ ¼å¼ï¼ˆå…¼å®¹ç°æœ‰çš„ outline æ ¼å¼ï¼‰

    å‚æ•°:
        outline_root: å¤§çº²æ ¹èŠ‚ç‚¹

    è¿”å›:
        JSON å­—ç¬¦ä¸²æ ¼å¼çš„å¤§çº²
    """

    def node_to_dict(node: OutlineNode) -> dict:
        """é€’å½’å°†èŠ‚ç‚¹è½¬æ¢ä¸ºå­—å…¸"""
        result = {"title": node.title, "children": []}
        for child in node.children:
            result["children"].append(node_to_dict(child))
        return result

    import json

    outline_dict = node_to_dict(outline_root)
    return json.dumps(outline_dict, ensure_ascii=False, indent=2)


def memory_to_dict(memory: Memory) -> dict:
    """
    å°† Memory å®ä¾‹è½¬æ¢ä¸ºå­—å…¸ï¼ˆç”¨äºåºåˆ—åŒ–åˆ° Stateï¼‰

    æ³¨æ„ï¼šembedding ä¿¡æ¯ä¼šè¢«ä¸¢å¼ƒï¼Œåªä¿ç•™æ–‡æ¡£å…ƒæ•°æ®ã€‚

    å‚æ•°:
        memory: Memory å®ä¾‹

    è¿”å›:
        å­—å…¸æ ¼å¼çš„å†…å­˜æ•°æ®
    """
    return {
        "total_documents": len(memory.documents),
        "node_to_docs": {
            node_id: list(doc_ids) for node_id, doc_ids in memory.node_to_docs.items()
        },
        "documents": {
            doc_id: doc.to_dict() for doc_id, doc in memory.documents.items()
        },
    }


def visualize_outline_with_citations(
    outline_root: OutlineNode,
    memory: Memory,
    output_path: Optional[str] = None,
    print_text: bool = True,
) -> str:
    """
    å¯è§†åŒ–å¤§çº²æ ‘åŠå…¶å¼•æ–‡æ˜ å°„å…³ç³»ã€‚

    å‚æ•°:
        outline_root: å¤§çº²æ ¹èŠ‚ç‚¹
        memory: Memory å®ä¾‹ï¼ŒåŒ…å«èŠ‚ç‚¹åˆ°æ–‡æ¡£çš„æ˜ å°„
        output_path: å›¾ç‰‡è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼Œéœ€è¦å®‰è£… graphvizï¼‰
        print_text: æ˜¯å¦æ‰“å°æ–‡æœ¬æ ¼å¼

    è¿”å›:
        æ–‡æœ¬æ ¼å¼çš„å¤§çº²æ ‘ï¼ˆå¸¦å¼•æ–‡æ˜ å°„ï¼‰
    """
    lines = []
    lines.append("=" * 80)
    lines.append("å¤§çº²æ ‘ä¸å¼•æ–‡æ˜ å°„å…³ç³»")
    lines.append("=" * 80)

    def format_node(node: OutlineNode, indent: int = 0) -> None:
        """é€’å½’æ ¼å¼åŒ–èŠ‚ç‚¹"""
        prefix = "  " * indent

        # è·å–è¯¥èŠ‚ç‚¹çš„å¼•æ–‡
        doc_ids = memory.node_to_docs.get(node.id, set())
        docs = [
            memory.documents.get(doc_id)
            for doc_id in doc_ids
            if doc_id in memory.documents
        ]

        # èŠ‚ç‚¹æ ‡é¢˜
        citation_count = len(docs)
        if citation_count > 0:
            lines.append(
                f"{prefix}â”œâ”€ {node.title} [ID: {node.id}] ğŸ“š {citation_count} ç¯‡å¼•æ–‡"
            )
        else:
            lines.append(f"{prefix}â”œâ”€ {node.title} [ID: {node.id}] âš ï¸ æ— å¼•æ–‡")

        # æ˜¾ç¤ºå¼•æ–‡è¯¦æƒ…ï¼ˆæˆªæ–­æ˜¾ç¤ºï¼‰
        for i, doc in enumerate(docs[:3]):  # æœ€å¤šæ˜¾ç¤º3ç¯‡
            if doc:
                doc_title = (doc.title or doc.text[:50] + "...") if doc.text else "æœªçŸ¥"
                lines.append(f"{prefix}â”‚    â””â”€ ğŸ“„ [{i+1}] {doc_title[:60]}")

        if len(docs) > 3:
            lines.append(f"{prefix}â”‚    â””â”€ ... è¿˜æœ‰ {len(docs) - 3} ç¯‡å¼•æ–‡")

        # é€’å½’å¤„ç†å­èŠ‚ç‚¹
        for child in node.children:
            format_node(child, indent + 1)

    format_node(outline_root)

    # ç»Ÿè®¡ä¿¡æ¯
    all_nodes = outline_root.get_all_nodes()
    nodes_with_citations = sum(
        1
        for n in all_nodes
        if n.id in memory.node_to_docs and memory.node_to_docs[n.id]
    )

    lines.append("")
    lines.append("=" * 80)
    lines.append("ç»Ÿè®¡ä¿¡æ¯")
    lines.append("=" * 80)
    lines.append(f"æ€»èŠ‚ç‚¹æ•°: {len(all_nodes)}")
    lines.append(f"æœ‰å¼•æ–‡çš„èŠ‚ç‚¹æ•°: {nodes_with_citations}")
    lines.append(f"æ— å¼•æ–‡çš„èŠ‚ç‚¹æ•°: {len(all_nodes) - nodes_with_citations}")
    lines.append(f"å¼•æ–‡è¦†ç›–ç‡: {nodes_with_citations / len(all_nodes) * 100:.1f}%")
    lines.append(f"æ€»æ–‡æ¡£æ•°: {len(memory.documents)}")
    lines.append("=" * 80)

    text_output = "\n".join(lines)

    if print_text:
        logger.info(f"\n{text_output}")

    # å°è¯•ç”Ÿæˆ graphviz å›¾ç‰‡
    if output_path:
        try:
            _generate_graphviz_image(outline_root, memory, output_path)
            logger.info(f"å¤§çº²å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜åˆ°: {output_path}")
        except Exception as e:
            logger.warning(f"æ— æ³•ç”Ÿæˆ graphviz å›¾ç‰‡: {e}")

    return text_output


def _generate_graphviz_image(
    outline_root: OutlineNode,
    memory: Memory,
    output_path: str,
) -> None:
    """
    ä½¿ç”¨ graphviz ç”Ÿæˆå¤§çº²æ ‘å¯è§†åŒ–å›¾ç‰‡ã€‚

    å‚æ•°:
        outline_root: å¤§çº²æ ¹èŠ‚ç‚¹
        memory: Memory å®ä¾‹
        output_path: è¾“å‡ºè·¯å¾„ï¼ˆä¸å«æ‰©å±•åï¼‰
    """
    try:
        from graphviz import Digraph
    except ImportError:
        raise ImportError("éœ€è¦å®‰è£… graphviz: pip install graphviz")

    dot = Digraph(comment="Outline Tree with Citations")
    dot.attr(rankdir="TB", splines="ortho")
    dot.attr("node", shape="box", style="rounded,filled", fontname="SimHei")

    def add_node(node: OutlineNode) -> None:
        """é€’å½’æ·»åŠ èŠ‚ç‚¹"""
        doc_ids = memory.node_to_docs.get(node.id, set())
        doc_count = len(doc_ids)

        # æ ¹æ®å¼•æ–‡æ•°é‡è®¾ç½®é¢œè‰²
        if doc_count == 0:
            color = "#ffcccc"  # çº¢è‰² - æ— å¼•æ–‡
        elif doc_count <= 2:
            color = "#ffffcc"  # é»„è‰² - å°‘é‡å¼•æ–‡
        else:
            color = "#ccffcc"  # ç»¿è‰² - æœ‰å¼•æ–‡

        # æˆªæ–­æ ‡é¢˜
        title = node.title[:30] + "..." if len(node.title) > 30 else node.title
        label = f"{title}\\nğŸ“š {doc_count} docs"

        dot.node(node.id, label, fillcolor=color)

        for child in node.children:
            add_node(child)
            dot.edge(node.id, child.id)

    add_node(outline_root)

    # ä¿å­˜å›¾ç‰‡
    dot.render(output_path, format="png", cleanup=True)
