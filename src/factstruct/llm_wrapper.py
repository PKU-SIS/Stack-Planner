"""
LLM Wrapper: LLM æ‰¹é‡æ–¹æ³•åŒ…è£…å™¨

å®ç°äº† Stage 1 æ‰€éœ€çš„æ‰¹é‡ LLM è°ƒç”¨æ–¹æ³•ï¼š
- batch_generate_queries: æ‰¹é‡ç”ŸæˆæŸ¥è¯¢
- batch_refine_outline: æ‰¹é‡ä¿®çº²
- generate_initial_outline: ç”Ÿæˆåˆå§‹å¤§çº²
"""

import json
import re
from typing import List, Tuple, Dict
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.language_models import BaseChatModel

from src.utils.logger import logger
from src.prompts import get_prompt_template
from .outline_node import OutlineNode
from .document import FactStructDocument
# from jinja2 import Template




class FactStructLLMWrapper:
    """
    FactStruct LLM æ–¹æ³•åŒ…è£…å™¨

    å°è£…äº† Stage 1 æ‰€éœ€çš„æ‰€æœ‰ LLM è°ƒç”¨æ–¹æ³•ã€‚
    """

    def __init__(self, llm: BaseChatModel):
        """
        åˆå§‹åŒ– LLM åŒ…è£…å™¨

        å‚æ•°:
            llm: LangChain BaseChatModel å®ä¾‹
        """
        self.llm = llm

    def generate_initial_outline(
        self,
        query: str,
        docs: List[FactStructDocument],
        central_guidance=None,
        replan_result=None,
        instruction=None,
    ) -> OutlineNode:
        """
        ç”Ÿæˆåˆå§‹å¤§çº²

        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢
            docs: åˆå§‹æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨

        è¿”å›:
            æ ¹ OutlineNode
        """
    
    
        # æ ¼å¼åŒ–æ–‡æ¡£ä¿¡æ¯
        docs_text = self._format_documents(docs)

        parts = []

        parts.append(
            "ä½ æ˜¯ä¸€ä¸ªç ”ç©¶åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯**ç”Ÿæˆä¸€ä¸ªåˆå§‹ç ”ç©¶å¤§çº²éª¨æ¶**ï¼Œ"
            "ç”¨äºåç»­é€æ­¥æ‰©å±•ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æ€§å®Œæˆæœ€ç»ˆå¤§çº²ã€‚\n"
        )

        parts.append("## ç”¨æˆ·æŸ¥è¯¢\n")
        parts.append(query + "\n")

        if docs_text:
            parts.append("## åˆå§‹æ–‡æ¡£ï¼ˆä»…ä¾›å‚è€ƒï¼Œä¸è¦æ±‚å®Œå…¨è¦†ç›–ï¼‰\n")
            parts.append(docs_text + "\n")

        if central_guidance:
            parts.append("## ä¸­æ¢æ™ºèƒ½ä½“æ€»ä½“æŒ‡å¯¼\n")
            parts.append("è¯·åœ¨æ„å»ºåˆå§‹å¤§çº²æ—¶å‚è€ƒä»¥ä¸‹æ–¹å‘æ€§å»ºè®®ï¼š\n")
            parts.append(central_guidance + "\n")

        if replan_result:
            parts.append("## Replan Result\n")
            if isinstance(replan_result, dict):
                for k, v in replan_result.items():
                    parts.append(f"- {k}: {v}\n")
            else:
                parts.append(str(replan_result) + "\n")

        if instruction:
            parts.append("## å¤§çº²æ™ºèƒ½ä½“æŒ‡å¯¼\n")
            parts.append(instruction + "\n")

        parts.append(
            """
        ## ç”Ÿæˆè¦æ±‚ï¼ˆéå¸¸é‡è¦ï¼‰

        1. **è¿™æ˜¯åˆå§‹åŒ–é˜¶æ®µï¼Œåªç”Ÿæˆæœ€å°å¯ç”¨çš„å¤§çº²éª¨æ¶**
        2. ä¸€çº§èŠ‚ç‚¹æ•°é‡å»ºè®® **3â€“5 ä¸ª**
        3. ä»…åœ¨å¿…è¦æ—¶ä¸ºä¸€çº§èŠ‚ç‚¹æ·»åŠ äºŒçº§èŠ‚ç‚¹ï¼Œ**é¿å…å±•å¼€è¿‡ç»†**
        4. ä¸è¦æ±‚è¦†ç›–æ‰€æœ‰ç»†èŠ‚ï¼Œå…è®¸åç»­é€šè¿‡ expandation å·¥å…·è¡¥å……
        5. æ¯ä¸ªèŠ‚ç‚¹åªéœ€æä¾›æ¸…æ™°ã€æ¦‚æ‹¬æ€§çš„æ ‡é¢˜
        6. é¿å…â€œç©·ä¸¾å¼â€æˆ–â€œç™¾ç§‘å…¨ä¹¦å¼â€ç»“æ„

        ## è¾“å‡ºæ ¼å¼è¦æ±‚
        - ä»…è¾“å‡º JSON
        - ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—
        - JSON ç»“æ„å¦‚ä¸‹ï¼š

        {
        "title": "æ ¹èŠ‚ç‚¹æ ‡é¢˜",
        "children": [
            {
            "title": "ä¸€çº§èŠ‚ç‚¹æ ‡é¢˜",
            "children": []
            }
        ]
        }
        """
        )


        prompt = "\n".join(parts)
        logger.info(f"å¤§çº²åˆå§‹è¾“å…¥ prompt:{prompt}")
        try:
            messages = [HumanMessage(content=prompt)]
            logger.info(f"initial outline prompt:{messages}")
            response = self.llm.invoke(messages)
            content = response.content.strip()

            # å°è¯•æå– JSONï¼ˆå¯èƒ½è¢« markdown ä»£ç å—åŒ…è£¹ï¼‰
            json_str = self._extract_json(content)
            outline_data = json.loads(json_str)

            # æ„å»º OutlineNode æ ‘
            # root = self._build_outline_tree(outline_data, parent=None, node_counter=[0])
            root = self._build_outline_tree(outline_data, parent=None)

            # self._inherit_mab_state_for_existing_nodes(None, root)
            new_node_ids = []
            self._inherit_mab_state_for_existing_nodes(None, root, new_node_ids=new_node_ids)
            logger.info(
                f"Generated initial outline with {len(root.get_all_nodes())} nodes"
            )
            return root

        except Exception as e:
            import traceback

            logger.error(f"Failed to generate initial outline: {e}")
            logger.error(f"Detailed error:\n{traceback.format_exc()}")
            # è¿”å›ä¸€ä¸ªç®€å•çš„é»˜è®¤å¤§çº²
            return OutlineNode(
                id="root_0",
                title=query,
                parent=None,
                children=[],
            )

    def batch_generate_queries(self, nodes: List[OutlineNode]) -> List[str]:
        """
        æ‰¹é‡ç”ŸæˆæŸ¥è¯¢ï¼ˆå•æ¬¡ LLM è°ƒç”¨ï¼‰

        å‚æ•°:
            nodes: éœ€è¦ç”ŸæˆæŸ¥è¯¢çš„èŠ‚ç‚¹åˆ—è¡¨

        è¿”å›:
            æŸ¥è¯¢å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œä¸ nodes ä¸€ä¸€å¯¹åº”
        """
        if not nodes:
            return []

        # æ„å»ºæ‰¹é‡æŸ¥è¯¢çš„ prompt
        nodes_info = []
        for i, node in enumerate(nodes, 1):
            parent_context = node.get_parent_context()
            context_str = f"ï¼ˆä¸Šä¸‹æ–‡ï¼š{parent_context}ï¼‰" if parent_context else ""
            nodes_info.append(f"{i}. èŠ‚ç‚¹: '{node.title}'{context_str}")

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªç ”ç©¶åŠ©æ‰‹ã€‚è¯·ä¸ºä»¥ä¸‹ {len(nodes)} ä¸ªå¤§çº²èŠ‚ç‚¹åˆ†åˆ«ç”Ÿæˆä¸€ä¸ªç²¾ç¡®çš„æœç´¢æŸ¥è¯¢ã€‚

        ## èŠ‚ç‚¹åˆ—è¡¨
        {chr(10).join(nodes_info)}

        ## è¦æ±‚
        1. ä¸ºæ¯ä¸ªèŠ‚ç‚¹ç”Ÿæˆä¸€ä¸ªç²¾ç¡®ã€å…·ä½“çš„æœç´¢æŸ¥è¯¢
        2. æŸ¥è¯¢åº”è¯¥èƒ½å¤Ÿå¸®åŠ©æ£€ç´¢åˆ°ä¸è¯¥èŠ‚ç‚¹ä¸»é¢˜ç›¸å…³çš„æ–‡æ¡£
        3. å¦‚æœèŠ‚ç‚¹æœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè¯·åœ¨æŸ¥è¯¢ä¸­ä½“ç°
        4. è¾“å‡ºæ ¼å¼å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼š
        æŸ¥è¯¢ 1: [æŸ¥è¯¢å†…å®¹]
        æŸ¥è¯¢ 2: [æŸ¥è¯¢å†…å®¹]
        ...
        æŸ¥è¯¢ {len(nodes)}: [æŸ¥è¯¢å†…å®¹]

        è¯·åªè¾“å‡ºæŸ¥è¯¢ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼ã€‚"""

        try:
            messages = [HumanMessage(content=prompt)]
            response = self.llm.invoke(messages)
            content = response.content.strip()

            # è§£ææŸ¥è¯¢
            queries = self._parse_batch_queries(content, len(nodes))

            if len(queries) != len(nodes):
                logger.warning(
                    f"Expected {len(nodes)} queries, got {len(queries)}. "
                    "Using node titles as fallback."
                )
                # ä½¿ç”¨èŠ‚ç‚¹æ ‡é¢˜ä½œä¸ºå¤‡ç”¨æŸ¥è¯¢
                queries = [node.title for node in nodes]

            return queries

        except Exception as e:
            import traceback

            logger.error(f"Failed to batch generate queries: {e}")
            logger.error(f"Detailed error:\n{traceback.format_exc()}")
            # ä½¿ç”¨èŠ‚ç‚¹æ ‡é¢˜ä½œä¸ºå¤‡ç”¨æŸ¥è¯¢
            return [node.title for node in nodes]

    def batch_refine_outline(
        self,
        current_outline: OutlineNode,
        node_doc_pairs: List[Tuple[OutlineNode, List[FactStructDocument]]],
        memory: "Memory" = None,
    ) -> Tuple[
        OutlineNode,
        List[Tuple[OutlineNode, List[OutlineNode]]],
        Dict[str, List[FactStructDocument]],
    ]:
        """
        æ‰¹é‡ä¿®çº²ï¼ˆå•æ¬¡ LLM è°ƒç”¨ï¼‰

        è¿™æ˜¯ Stage 1 æœ€å¤æ‚çš„æ–¹æ³•ï¼Œè¦æ±‚ LLM åœ¨å•æ¬¡è°ƒç”¨ä¸­ç†è§£å¹¶æ‰§è¡Œ K ä¸ªç‹¬ç«‹çš„å±€éƒ¨ä¿®æ”¹ã€‚

        å‚æ•°:
            current_outline: å½“å‰å¤§çº²æ ¹èŠ‚ç‚¹
            node_doc_pairs: (èŠ‚ç‚¹, æ–°æ–‡æ¡£åˆ—è¡¨) çš„å…ƒç»„åˆ—è¡¨
            memory: Memory å®ä¾‹ï¼Œç”¨äºè·å–èŠ‚ç‚¹çš„ç´¯ç§¯æ–‡æ¡£æ˜ å°„

        è¿”å›:
            (ä¿®è®¢åçš„å¤§çº²æ ¹èŠ‚ç‚¹, expanded_nodes_list, new_node_doc_mapping)
            expanded_nodes_list: [(çˆ¶èŠ‚ç‚¹, [æ–°å­èŠ‚ç‚¹1, æ–°å­èŠ‚ç‚¹2, ...]), ...] çš„åˆ—è¡¨ï¼Œ
                                è®°å½•å“ªäº›èŠ‚ç‚¹è¢«æ‰©å±•äº†ä»¥åŠå®ƒä»¬çš„æ–°å­èŠ‚ç‚¹
            new_node_doc_mapping: {æ–°å­èŠ‚ç‚¹ID: [åŒ¹é…çš„æ–‡æ¡£åˆ—è¡¨]} çš„å­—å…¸ï¼Œ
                                è®°å½•æ¯ä¸ªæ–°å­èŠ‚ç‚¹ä¸æ–‡æ¡£çš„åŒ¹é…å…³ç³»
        """
        if not node_doc_pairs:
            return current_outline, [], {}

        # æ„å»ºæ‰¹é‡ä¿®çº²çš„ prompt
        outline_text = current_outline.to_text_tree()

        optimization_tasks = []
        for i, (node, docs) in enumerate(node_doc_pairs, 1):
            docs_text = self._format_documents(docs, max_chars=500)  # é™åˆ¶æ–‡æ¡£é•¿åº¦
            parent_context = node.get_parent_context()
            context_str = (
                f"ï¼ˆä¸Šä¸‹æ–‡ï¼š{parent_context} > {node.title}ï¼‰"
                if parent_context
                else f"ï¼ˆèŠ‚ç‚¹ï¼š{node.title}ï¼‰"
            )

            optimization_tasks.append(
            f"""
            ä¼˜åŒ–ä»»åŠ¡ {i}:
            - èŠ‚ç‚¹: '{node.title}'
            - ä¸Šä¸‹æ–‡: {context_str}
            - æ–°ä¿¡æ¯: {docs_text}
            - è¦æ±‚: åœ¨è¯¥èŠ‚ç‚¹ä¸‹å¢åŠ  2-4 ä¸ªå¹¶åˆ—çš„å­ç« èŠ‚ã€‚**æ¯ä¸ªå­ç« èŠ‚çš„æ ‡é¢˜å¿…é¡»ç›´æ¥æ¥æºäºæˆ–å¯¹åº”ä¸Šè¿°"æ–°ä¿¡æ¯"ä¸­çš„æŸä¸ªå…·ä½“å†…å®¹ç‚¹**ï¼Œç¡®ä¿å­ç« èŠ‚ä¸æ–‡æ¡£æœ‰æ˜ç¡®çš„å¯¹åº”å…³ç³»ã€‚"""
            )

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªç ”ç©¶åŠ©æ‰‹ã€‚æˆ‘ä»¬åˆšåˆšæ£€ç´¢äº† {len(node_doc_pairs)} ä¸ªèŠ‚ç‚¹ï¼Œè·å¾—äº†æ–°ä¿¡æ¯ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®è¿™äº›æ–°ä¿¡æ¯ï¼Œå¯¹å¤§çº²è¿›è¡Œ {len(node_doc_pairs)} æ¬¡ *ç‹¬ç«‹çš„å±€éƒ¨ä¼˜åŒ–*ã€‚

        ## å½“å‰ç ”ç©¶å¤§çº²
        {outline_text}

        {chr(10).join(optimization_tasks)}

        ## è¦æ±‚
        1. å¯¹æ¯ä¸ªä¼˜åŒ–ä»»åŠ¡ï¼Œ**ç‹¬ç«‹åœ°**è¿›è¡Œå±€éƒ¨ä¿®æ”¹
        2. **é‡è¦**ï¼šä¸ºæ¯ä¸ªç›®æ ‡å¶å­èŠ‚ç‚¹ç”Ÿæˆ 2-4 ä¸ªå¹¶åˆ—çš„å­èŠ‚ç‚¹ï¼Œé¿å…åªç”Ÿæˆå•ä¸ªå­èŠ‚ç‚¹å¯¼è‡´å¤§çº²å˜æˆ"æ–œæ ‘"
        3. å­èŠ‚ç‚¹ä¹‹é—´åº”è¯¥æ˜¯å¹¶åˆ—å…³ç³»ï¼Œè¦†ç›–è¯¥ä¸»é¢˜çš„ä¸åŒæ–¹é¢ï¼Œè€Œä¸æ˜¯å±‚å±‚åµŒå¥—
        4. ä¿®æ”¹æ—¶åªå½±å“ç›®æ ‡èŠ‚ç‚¹åŠå…¶å­èŠ‚ç‚¹ï¼Œä¸è¦å½±å“å…¶ä»–ä¸ç›¸å…³çš„èŠ‚ç‚¹
        5. ä¿®æ”¹åçš„å¤§çº²åº”è¯¥ä¿æŒå±‚æ¬¡ç»“æ„æ¸…æ™°ã€å®½åº¦å‡è¡¡
        6. **å…³é”®**ï¼šæ¯ä¸ªæ–°ç”Ÿæˆçš„å­èŠ‚ç‚¹æ ‡é¢˜å¿…é¡»èƒ½å¤Ÿåœ¨å¯¹åº”çš„"æ–°ä¿¡æ¯"æ–‡æ¡£ä¸­æ‰¾åˆ°æ˜ç¡®çš„å†…å®¹æ”¯æ’‘ï¼Œä¸è¦ç”Ÿæˆä¸æ–‡æ¡£å†…å®¹æ— å…³çš„ç©ºæ³›æ ‡é¢˜ã€‚å­èŠ‚ç‚¹æ ‡é¢˜åº”è¯¥å…·ä½“ã€æœ‰ä¿¡æ¯é‡ï¼Œèƒ½å¤Ÿç›´æ¥å¯¹åº”åˆ°æŸä¸ªæ–‡æ¡£çš„æ ¸å¿ƒå†…å®¹
        7. è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯ JSONï¼Œç»“æ„å¦‚ä¸‹ï¼š
        {{
            "title": "æ ¹èŠ‚ç‚¹æ ‡é¢˜",
            "children": [
                {{
                    "title": "å­èŠ‚ç‚¹1æ ‡é¢˜",
                    "children": []
                }},
                {{
                    "title": "å­èŠ‚ç‚¹2æ ‡é¢˜ï¼ˆè¢«æ‰©å±•çš„å¶å­èŠ‚ç‚¹ï¼‰",
                    "children": [
                        {{
                            "title": "å¹¶åˆ—å­èŠ‚ç‚¹A",
                            "children": []
                        }},
                        {{
                            "title": "å¹¶åˆ—å­èŠ‚ç‚¹B",
                            "children": []
                        }},
                        {{
                            "title": "å¹¶åˆ—å­èŠ‚ç‚¹C",
                            "children": []
                        }}
                    ]
                }}
            ]
        }}

        è¯·åªè¾“å‡º JSONï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šæ€§æ–‡å­—ã€‚è¾“å‡ºå®Œæ•´çš„ä¿®è®¢åå¤§çº²æ ‘ã€‚"""

        try:
            logger.info(f"batch_refine_outline prompt{prompt}")
            messages = [HumanMessage(content=prompt)]
            response = self.llm.invoke(messages)
            logger.info(f"batch_refine_outline response{response}")
            content = response.content.strip()

            # æå– JSON
            json_str = self._extract_json(content)
            outline_data = json.loads(json_str)

            # æ„å»ºæ–°çš„ OutlineNode æ ‘
            # new_root = self._build_outline_tree(outline_data, parent=None, node_counter=[0])
            new_root = self._build_outline_tree(outline_data, parent=None)
            # éªŒè¯ï¼šæ£€æŸ¥è¿”å›çš„å¤§çº²æ˜¯å¦çœŸçš„åŒ…å«äº†å¯¹ç›®æ ‡èŠ‚ç‚¹çš„ä¿®æ”¹
            # è¿™æ˜¯ä¸€ä¸ªå¯å‘å¼éªŒè¯ï¼Œæ£€æŸ¥ç›®æ ‡èŠ‚ç‚¹æ˜¯å¦ä»ç„¶å­˜åœ¨ï¼ˆå¯èƒ½è¢«ä¿®æ”¹æˆ–ç§»åŠ¨ï¼‰
            validation_passed = self._validate_batch_refine_result(
                current_outline, new_root, node_doc_pairs
            )

            if not validation_passed:
                logger.warning(
                    "Batch refine validation failed: returned outline may not contain expected changes. "
                    "Returning original outline."
                )
                return current_outline, [], {}

            # é‡è¦ï¼šè¯†åˆ«å“ªäº›èŠ‚ç‚¹è¢«æ‰©å±•äº†ï¼Œå¹¶æ„å»º expanded_nodes_list å’Œæ–°å­èŠ‚ç‚¹çš„æ–‡æ¡£æ˜ å°„
            expanded_nodes_list, new_node_doc_mapping = self._identify_expanded_nodes(
                current_outline, new_root, node_doc_pairs, memory
            )

            # å…ˆç»§æ‰¿æ‰€æœ‰ç°æœ‰èŠ‚ç‚¹çš„çŠ¶æ€ï¼ˆé€šè¿‡è·¯å¾„åŒ¹é…ï¼‰
            # self._inherit_mab_state_for_existing_nodes(current_outline, new_root)
            new_node_ids = []
            self._inherit_mab_state_for_existing_nodes(current_outline, new_root, new_node_ids=new_node_ids)
            logger.info(
                f"Refined outline with {len(new_root.get_all_nodes())} nodes, "
                f"{len(expanded_nodes_list)} nodes expanded, "
                f"{len(new_node_doc_mapping)} new nodes mapped to documents"
            )
            return new_root, expanded_nodes_list, new_node_doc_mapping

        except Exception as e:
            import traceback

            logger.error(f"Failed to batch refine outline: {e}")
            logger.error(f"Detailed error:\n{traceback.format_exc()}")
            # è¿”å›åŸå¤§çº²ï¼ˆä¸ä¿®æ”¹ï¼‰
            return current_outline, [], {}

    def _format_documents(
        self,
        docs: List[FactStructDocument],
        max_chars: int = 1000,
    ) -> str:
        """æ ¼å¼åŒ–æ–‡æ¡£åˆ—è¡¨ä¸ºæ–‡æœ¬"""
        if not docs:
            return "æ— æ–‡æ¡£"

        formatted = []
        total_chars = 0

        for i, doc in enumerate(docs[:5], 1):  # æœ€å¤šæ˜¾ç¤º 5 ä¸ªæ–‡æ¡£
            doc_text = f"\næ–‡æ¡£ {i}:\n"
            if doc.title:
                doc_text += f"æ ‡é¢˜: {doc.title}\n"
            if doc.url:
                doc_text += f"æ¥æº: {doc.url}\n"

            # æˆªæ–­æ–‡æ¡£å†…å®¹
            content = doc.text[:max_chars]
            if len(doc.text) > max_chars:
                content += "..."

            doc_text += f"å†…å®¹: {content}\n"

            if total_chars + len(doc_text) > max_chars * 3:  # æ€»ä½“é™åˆ¶
                formatted.append(f"\n... è¿˜æœ‰ {len(docs) - i} ä¸ªæ–‡æ¡£")
                break

            formatted.append(doc_text)
            total_chars += len(doc_text)

        return "".join(formatted)

    def _extract_json(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå– JSONï¼ˆå¯èƒ½è¢« markdown ä»£ç å—åŒ…è£¹ï¼‰"""
        # å°è¯•æå–ä»£ç å—ä¸­çš„ JSON
        json_match = re.search(r"```(?:json)?\s*(\{.*\})\s*```", text, re.DOTALL)
        if json_match:
            return json_match.group(1)

        # å°è¯•ç›´æ¥æå– JSON å¯¹è±¡
        json_match = re.search(r"\{.*\}", text, re.DOTALL)
        if json_match:
            return json_match.group(0)

        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›åŸæ–‡æœ¬
        return text

    def _parse_batch_queries(self, content: str, expected_count: int) -> List[str]:
        """è§£ææ‰¹é‡æŸ¥è¯¢è¾“å‡º"""
        queries = []

        # å°è¯•åŒ¹é… "æŸ¥è¯¢ N: [å†…å®¹]" æ ¼å¼
        pattern = r"æŸ¥è¯¢\s*(\d+)\s*:\s*(.+?)(?=æŸ¥è¯¢\s*\d+\s*:|$)"
        matches = re.findall(pattern, content, re.DOTALL | re.IGNORECASE)

        if matches:
            # æŒ‰ç¼–å·æ’åº
            matches.sort(key=lambda x: int(x[0]))
            queries = [match[1].strip() for match in matches]
        else:
            # å¤‡ç”¨ï¼šæŒ‰è¡Œåˆ†å‰²
            lines = [line.strip() for line in content.split("\n") if line.strip()]
            queries = lines[:expected_count]

        return queries

    # def _build_outline_tree(
    #     self,
    #     data: dict,
    #     parent: OutlineNode = None,
    #     node_counter: List[int] = None,
    # ) -> OutlineNode:
    #     """é€’å½’æ„å»º OutlineNode æ ‘"""
    #     if node_counter is None:
    #         node_counter = [0]

    #     node_counter[0] += 1
    #     node_id = f"node_{node_counter[0]}"

    #     node = OutlineNode(
    #         id=node_id,
    #         title=data.get("title", "æœªå‘½åèŠ‚ç‚¹"),
    #         parent=parent,
    #         children=[],
    #     )

    #     # é€’å½’æ„å»ºå­èŠ‚ç‚¹
    #     for child_data in data.get("children", []):
    #         child = self._build_outline_tree(
    #             child_data, parent=node, node_counter=node_counter
    #         )
    #         node.add_child(child)

    #     return node
    def _build_outline_tree(
        self,
        data: dict,
        parent: OutlineNode = None,
    ) -> OutlineNode:
        """é€’å½’æ„å»º OutlineNode æ ‘ï¼ˆåªæ„ç»“æ„ï¼Œä¸åˆ†é… idï¼‰"""

        node = OutlineNode(
            id=None,  # ğŸ”¥ è¿™é‡Œå…ˆä¸åˆ†é…
            title=data.get("title", "æœªå‘½åèŠ‚ç‚¹"),
            parent=parent,
            children=[],
        )

        for child_data in data.get("children", []):
            child = self._build_outline_tree(
                child_data, parent=node
            )
            node.add_child(child)

        return node



    def _identify_expanded_nodes(
        self,
        old_outline: OutlineNode,
        new_outline: OutlineNode,
        node_doc_pairs: List[Tuple[OutlineNode, List[FactStructDocument]]],
        memory: "Memory" = None,
    ) -> Tuple[
        List[Tuple[OutlineNode, List[OutlineNode]]], Dict[str, List[FactStructDocument]]
    ]:
        """
        è¯†åˆ«å“ªäº›èŠ‚ç‚¹è¢«æ‰©å±•äº†ï¼ˆä»å¶å­èŠ‚ç‚¹å˜æˆäº†æœ‰å­èŠ‚ç‚¹çš„å†…éƒ¨èŠ‚ç‚¹ï¼‰ï¼Œ
        å¹¶ä¸ºæ¯ä¸ªæ–°å­èŠ‚ç‚¹åŒ¹é…ç›¸å…³æ–‡æ¡£ã€‚

        å‚æ•°:
            old_outline: æ—§å¤§çº²æ ¹èŠ‚ç‚¹
            new_outline: æ–°å¤§çº²æ ¹èŠ‚ç‚¹
            node_doc_pairs: ç›®æ ‡èŠ‚ç‚¹-æ–‡æ¡£å¯¹åˆ—è¡¨ï¼ˆè¿™äº›èŠ‚ç‚¹æ˜¯æˆ‘ä»¬å¸Œæœ›è¢«æ‰©å±•çš„ï¼‰
            memory: Memory å®ä¾‹ï¼Œç”¨äºè·å–èŠ‚ç‚¹çš„ç´¯ç§¯æ–‡æ¡£

        è¿”å›:
            (expanded_nodes_list, new_node_doc_mapping)
            expanded_nodes_list: [(çˆ¶èŠ‚ç‚¹, [æ–°å­èŠ‚ç‚¹1, æ–°å­èŠ‚ç‚¹2, ...]), ...] çš„åˆ—è¡¨
                                ä½¿ç”¨åˆ—è¡¨è€Œä¸æ˜¯å­—å…¸ï¼Œå› ä¸º OutlineNode ä¸å¯å“ˆå¸Œ
            new_node_doc_mapping: {æ–°å­èŠ‚ç‚¹ID: [åŒ¹é…çš„æ–‡æ¡£åˆ—è¡¨]} çš„å­—å…¸
        """

        def get_node_path(node: OutlineNode) -> str:
            """è·å–èŠ‚ç‚¹çš„å®Œæ•´è·¯å¾„ï¼ˆä»æ ¹åˆ°å½“å‰èŠ‚ç‚¹ï¼‰"""
            path_parts = []
            current = node
            while current is not None:
                path_parts.insert(0, current.title)
                current = current.parent
            return " > ".join(path_parts)

        def find_node_by_path(root: OutlineNode, target_path: str) -> OutlineNode:
            """æ ¹æ®è·¯å¾„æŸ¥æ‰¾èŠ‚ç‚¹"""
            for node in root.get_all_nodes():
                if get_node_path(node) == target_path:
                    return node
            return None

        def match_child_to_docs(
            child_node: OutlineNode, docs: List[FactStructDocument]
        ) -> List[FactStructDocument]:
            """
            ä¸ºæ–°å­èŠ‚ç‚¹åŒ¹é…æœ€ç›¸å…³çš„æ–‡æ¡£ã€‚
            ä½¿ç”¨ç®€å•çš„æ–‡æœ¬åŒ¹é…ç­–ç•¥ï¼šæ£€æŸ¥å­èŠ‚ç‚¹æ ‡é¢˜ä¸­çš„å…³é”®è¯æ˜¯å¦å‡ºç°åœ¨æ–‡æ¡£ä¸­ã€‚
            """
            if not docs:
                return []

            child_title_lower = child_node.title.lower()
            # æå–å­èŠ‚ç‚¹æ ‡é¢˜ä¸­çš„å…³é”®è¯ï¼ˆå»æ‰å¸¸è§åœç”¨è¯ï¼‰
            stopwords = {
                "çš„",
                "å’Œ",
                "ä¸",
                "åœ¨",
                "æ˜¯",
                "äº†",
                "æœ‰",
                "ä¸º",
                "the",
                "a",
                "an",
                "and",
                "or",
                "of",
                "in",
                "to",
                "for",
            }
            keywords = [
                w
                for w in child_title_lower.split()
                if w not in stopwords and len(w) > 1
            ]

            matched_docs = []
            for doc in docs:
                doc_text_lower = (doc.text + " " + (doc.title or "")).lower()
                # è®¡ç®—åŒ¹é…çš„å…³é”®è¯æ•°é‡
                match_count = sum(1 for kw in keywords if kw in doc_text_lower)
                if match_count > 0:
                    matched_docs.append((match_count, doc))

            # æŒ‰åŒ¹é…åº¦æ’åºï¼Œè¿”å›åŒ¹é…çš„æ–‡æ¡£
            matched_docs.sort(key=lambda x: x[0], reverse=True)

            if matched_docs:
                return [doc for _, doc in matched_docs]
            else:
                # å¦‚æœæ²¡æœ‰æ˜ç¡®åŒ¹é…ï¼Œè¿”å›æ‰€æœ‰æ–‡æ¡£ï¼ˆç»§æ‰¿çˆ¶èŠ‚ç‚¹çš„å…¨éƒ¨æ–‡æ¡£ï¼‰
                return docs

        expanded_nodes_list = []
        new_node_doc_mapping: Dict[str, List[FactStructDocument]] = {}

        # å¯¹äºæ¯ä¸ªç›®æ ‡èŠ‚ç‚¹ï¼Œæ£€æŸ¥å®ƒæ˜¯å¦è¢«æ‰©å±•äº†
        for target_node, new_docs in node_doc_pairs:
            # è·å–ç›®æ ‡èŠ‚ç‚¹åœ¨æ—§å¤§çº²ä¸­çš„è·¯å¾„
            old_path = get_node_path(target_node)

            # æ£€æŸ¥ç›®æ ‡èŠ‚ç‚¹åœ¨æ—§å¤§çº²ä¸­æ˜¯å¦æ˜¯å¶å­èŠ‚ç‚¹
            if not target_node.is_leaf():
                # å¦‚æœç›®æ ‡èŠ‚ç‚¹åœ¨æ—§å¤§çº²ä¸­å·²ç»æœ‰å­èŠ‚ç‚¹ï¼Œè·³è¿‡ï¼ˆæˆ‘ä»¬ä¸å¤„ç†è¿™ç§æƒ…å†µï¼‰
                continue

            # åœ¨æ–°å¤§çº²ä¸­æŸ¥æ‰¾å¯¹åº”çš„èŠ‚ç‚¹ï¼ˆé€šè¿‡è·¯å¾„åŒ¹é…ï¼‰
            new_matched_node = find_node_by_path(new_outline, old_path)

            # å¦‚æœè·¯å¾„åŒ¹é…å¤±è´¥ï¼Œå°è¯•é€šè¿‡æ ‡é¢˜åŒ¹é…ï¼ˆèŠ‚ç‚¹å¯èƒ½è¢«é‡å‘½åä½†è·¯å¾„å˜åŒ–ä¸å¤§ï¼‰
            if new_matched_node is None:
                # å°è¯•æŸ¥æ‰¾æ ‡é¢˜ç›¸åŒä¸”ä½ç½®ç›¸ä¼¼çš„èŠ‚ç‚¹
                new_matched_node = self._find_similar_node_by_title(
                    new_outline, target_node
                )

            if new_matched_node is None:
                logger.debug(
                    f"Could not find matched node for '{target_node.title}' "
                    f"(path: {old_path}) in new outline"
                )
                continue

            # æ£€æŸ¥æ–°èŠ‚ç‚¹æ˜¯å¦æœ‰å­èŠ‚ç‚¹ï¼ˆå³æ˜¯å¦è¢«æ‰©å±•äº†ï¼‰
            if new_matched_node.children:
                # èŠ‚ç‚¹è¢«æ‰©å±•äº†ï¼è®°å½•æ–°å­èŠ‚ç‚¹
                expanded_nodes_list.append((target_node, new_matched_node.children))

                # è·å–è¯¥èŠ‚ç‚¹çš„ç´¯ç§¯æ–‡æ¡£ï¼ˆåŒ…æ‹¬ä¹‹å‰è¿­ä»£ç§¯ç´¯çš„ + æœ¬è½®æ–°å¢çš„ï¼‰
                # ä¼˜å…ˆä½¿ç”¨ memory ä¸­çš„ç´¯ç§¯æ–‡æ¡£ï¼Œå¦‚æœ memory ä¸å¯ç”¨åˆ™ä½¿ç”¨æœ¬è½®æ–°æ–‡æ¡£
                all_docs = new_docs  # é»˜è®¤ä½¿ç”¨æœ¬è½®æ–°æ–‡æ¡£
                if memory is not None:
                    accumulated_docs = memory.get_docs_by_node(target_node.id)
                    if accumulated_docs:
                        all_docs = accumulated_docs
                        logger.debug(
                            f"Using {len(all_docs)} accumulated docs for node '{target_node.title}'"
                        )

                # ä¸ºæ¯ä¸ªæ–°å­èŠ‚ç‚¹åŒ¹é…æ–‡æ¡£
                for child_node in new_matched_node.children:
                    matched_docs = match_child_to_docs(child_node, all_docs)
                    new_node_doc_mapping[child_node.id] = matched_docs
                    logger.debug(
                        f"Child node '{child_node.title}' matched {len(matched_docs)} documents"
                    )

                logger.info(
                    f"Node '{target_node.title}' expanded: "
                    f"{len(new_matched_node.children)} new children, "
                    f"all mapped to documents (from {len(all_docs)} available docs)"
                )

        return expanded_nodes_list, new_node_doc_mapping

    def _find_similar_node_by_title(
        self,
        root: OutlineNode,
        target_node: OutlineNode,
    ) -> OutlineNode:
        """
        é€šè¿‡æ ‡é¢˜å’Œçˆ¶èŠ‚ç‚¹ä¸Šä¸‹æ–‡æŸ¥æ‰¾ç›¸ä¼¼èŠ‚ç‚¹

        è¿™ä¸ªæ–¹æ³•ç”¨äºå¤„ç†èŠ‚ç‚¹è¢«é‡å‘½åçš„æƒ…å†µã€‚
        """
        # è·å–ç›®æ ‡èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹ä¸Šä¸‹æ–‡
        parent_context = target_node.get_parent_context()

        # åœ¨æ–°å¤§çº²ä¸­æŸ¥æ‰¾æ ‡é¢˜ç›¸åŒçš„èŠ‚ç‚¹
        for node in root.get_all_nodes():
            if node.title == target_node.title:
                # æ£€æŸ¥çˆ¶èŠ‚ç‚¹ä¸Šä¸‹æ–‡æ˜¯å¦åŒ¹é…
                node_parent_context = node.get_parent_context()
                if node_parent_context == parent_context:
                    return node

        # å¦‚æœæ‰¾ä¸åˆ°å®Œå…¨åŒ¹é…çš„ï¼Œè¿”å›ç¬¬ä¸€ä¸ªæ ‡é¢˜ç›¸åŒçš„èŠ‚ç‚¹
        for node in root.get_all_nodes():
            if node.title == target_node.title:
                return node

        return None


    def _inherit_mab_state_for_existing_nodes(
        self,
        old_root: OutlineNode,
        new_root: OutlineNode,
        new_node_ids: List[str] = None,
    ):
        """
        ä¸ºç°æœ‰èŠ‚ç‚¹ç»§æ‰¿ MAB çŠ¶æ€ï¼ˆpull_count, reward_historyï¼‰
        æ„Ÿè§‰å°±æ˜¯å› ä¸ºæœ‰ä¸ª new_rootæœ‰ä¸ª old_rootæ‰€ä»¥åšäº†ä¸ªå¤åˆ¶ç²˜è´´ã€‚
        é€šè¿‡èŠ‚ç‚¹è·¯å¾„ï¼ˆä»æ ¹åˆ°å½“å‰èŠ‚ç‚¹çš„è·¯å¾„ï¼‰åŒ¹é…æ¥æ‰¾åˆ°å¯¹åº”çš„èŠ‚ç‚¹å¹¶ç»§æ‰¿çŠ¶æ€ã€‚
        è¿™ä¸ªæ–¹æ³•åªå¤„ç†æ—§å¤§çº²ä¸­å·²å­˜åœ¨çš„èŠ‚ç‚¹ï¼Œä¸åŒ…æ‹¬æ–°æ‰©å±•çš„å­èŠ‚ç‚¹ã€‚

        åŒ¹é…ç­–ç•¥ï¼š
        1. ä¼˜å…ˆä½¿ç”¨å®Œæ•´è·¯å¾„åŒ¹é…ï¼ˆæ ¹ > çˆ¶ > å½“å‰ï¼‰
        2. å¦‚æœè·¯å¾„åŒ¹é…å¤±è´¥ï¼Œå›é€€åˆ°æ ‡é¢˜åŒ¹é…
        3. å¦‚æœéƒ½å¤±è´¥ï¼ŒèŠ‚ç‚¹çŠ¶æ€é‡ç½®ä¸ºåˆå§‹å€¼ï¼ˆpull_count=0, reward_history=[]ï¼‰
        """

        if new_node_ids is None:
            new_node_ids = []

        if old_root is None:
            # ç¬¬ä¸€æ¬¡åˆå§‹åŒ–
            for node in new_root.get_all_nodes():
                node.id = OutlineNode.allocate_id()
                new_node_ids.append(node.id)  # æ”¶é›†æ–°èŠ‚ç‚¹
            return


        def get_node_path(node: OutlineNode) -> str:
            """è·å–èŠ‚ç‚¹çš„å®Œæ•´è·¯å¾„ï¼ˆä»æ ¹åˆ°å½“å‰èŠ‚ç‚¹ï¼‰"""
            path_parts = []
            current = node
            while current is not None:
                path_parts.insert(0, current.title)
                current = current.parent
            return " > ".join(path_parts)

        # æ„å»ºæ—§èŠ‚ç‚¹çš„è·¯å¾„æ˜ å°„ï¼ˆè·¯å¾„ -> èŠ‚ç‚¹ï¼‰
        old_nodes_by_path = {}
        old_nodes_by_title = {}
        for node in old_root.get_all_nodes():
            path = get_node_path(node)
            old_nodes_by_path[path] = node
            # ä¹Ÿä¿ç•™æ ‡é¢˜æ˜ å°„ä½œä¸ºå¤‡ç”¨ï¼ˆå¯èƒ½ä¼šæœ‰é‡å¤æ ‡é¢˜ï¼Œä½†è‡³å°‘èƒ½æ‰¾åˆ°ç¬¬ä¸€ä¸ªï¼‰
            if node.title not in old_nodes_by_title:
                old_nodes_by_title[node.title] = node



        def inherit_recursive(new_node: OutlineNode):
            """é€’å½’ç»§æ‰¿çŠ¶æ€"""
            new_path = get_node_path(new_node)

            # ç­–ç•¥1ï¼šä¼˜å…ˆä½¿ç”¨è·¯å¾„åŒ¹é…ï¼ˆæœ€å‡†ç¡®ï¼‰
            if new_path in old_nodes_by_path:
                old_node = old_nodes_by_path[new_path]
                new_node.pull_count = old_node.pull_count
                new_node.reward_history = old_node.reward_history.copy()
                new_node.id = old_node.id#å¢åŠ node_idçš„ç»§æ‰¿
                logger.debug(
                    f"State inherited for node '{new_node.title}' via path match "
                    f"(pull_count={old_node.pull_count})"
                )
            # ç­–ç•¥2ï¼šå›é€€åˆ°æ ‡é¢˜åŒ¹é…ï¼ˆå¯èƒ½ä¸å¤Ÿå‡†ç¡®ï¼Œä½†æ¯”ä¸¢å¤±çŠ¶æ€å¥½ï¼‰
            elif new_node.title in old_nodes_by_title:
                old_node = old_nodes_by_title[new_node.title]
                new_node.pull_count = old_node.pull_count
                new_node.reward_history = old_node.reward_history.copy()
                logger.debug(
                    f"State inherited for node '{new_node.title}' via title match "
                    f"(path may differ, pull_count={old_node.pull_count})"
                )
            # ç­–ç•¥3ï¼šæ— æ³•åŒ¹é…ï¼Œä¿æŒé»˜è®¤çŠ¶æ€ï¼ˆpull_count=0, reward_history=[]ï¼‰
            else:
                new_node.id = OutlineNode.allocate_id()
                new_node_ids.append(new_node.id)  # æ”¶é›†æ–°èŠ‚ç‚¹
                logger.debug(
                    f"Node '{new_node.title}' (path: {new_path}) not found in old outline, "
                    "using default state"
                )

            # é€’å½’å¤„ç†å­èŠ‚ç‚¹
            for child in new_node.children:
                inherit_recursive(child)

        inherit_recursive(new_root)

    def _validate_batch_refine_result(
        self,
        old_outline: OutlineNode,
        new_outline: OutlineNode,
        node_doc_pairs: List[Tuple[OutlineNode, List[FactStructDocument]]],
    ) -> bool:
        """
        éªŒè¯æ‰¹é‡ä¿®çº²ç»“æœ

        æ£€æŸ¥è¿”å›çš„æ–°å¤§çº²æ˜¯å¦çœŸçš„åŒ…å«äº†å¯¹ç›®æ ‡èŠ‚ç‚¹çš„ä¿®æ”¹ã€‚
        è¿™æ˜¯ä¸€ä¸ªå¯å‘å¼éªŒè¯ï¼Œä¸»è¦æ£€æŸ¥ï¼š
        1. æ–°å¤§çº²æ˜¯å¦æ¯”æ—§å¤§çº²æœ‰å˜åŒ–ï¼ˆèŠ‚ç‚¹æ•°é‡æˆ–ç»“æ„ï¼‰
        2. ç›®æ ‡èŠ‚ç‚¹çš„æ ‡é¢˜æ˜¯å¦åœ¨æ–°å¤§çº²ä¸­å­˜åœ¨ï¼ˆå¯èƒ½è¢«ä¿®æ”¹æˆ–ç§»åŠ¨ï¼‰

        å‚æ•°:
            old_outline: æ—§å¤§çº²æ ¹èŠ‚ç‚¹
            new_outline: æ–°å¤§çº²æ ¹èŠ‚ç‚¹
            node_doc_pairs: ç›®æ ‡èŠ‚ç‚¹-æ–‡æ¡£å¯¹åˆ—è¡¨

        è¿”å›:
            True è¡¨ç¤ºéªŒè¯é€šè¿‡ï¼ŒFalse è¡¨ç¤ºéªŒè¯å¤±è´¥
        """
        # éªŒè¯1ï¼šæ£€æŸ¥å¤§çº²æ˜¯å¦æœ‰å˜åŒ–
        old_node_count = len(old_outline.get_all_nodes())
        new_node_count = len(new_outline.get_all_nodes())

        # å¦‚æœèŠ‚ç‚¹æ•°é‡æ²¡æœ‰å˜åŒ–ï¼Œä¸”ç»“æ„å®Œå…¨ç›¸åŒï¼Œå¯èƒ½ LLM æ²¡æœ‰æ‰§è¡Œä¿®æ”¹
        if old_node_count == new_node_count:
            old_titles = {node.title for node in old_outline.get_all_nodes()}
            new_titles = {node.title for node in new_outline.get_all_nodes()}
            if old_titles == new_titles:
                logger.warning(
                    "Batch refine returned outline with no changes in structure or titles"
                )
                return False

        # éªŒè¯2ï¼šæ£€æŸ¥ç›®æ ‡èŠ‚ç‚¹çš„æ ‡é¢˜æ˜¯å¦åœ¨æ–°å¤§çº²ä¸­å­˜åœ¨
        # ï¼ˆå³ä½¿èŠ‚ç‚¹è¢«ä¿®æ”¹æˆ–ç§»åŠ¨ï¼Œæ ‡é¢˜åº”è¯¥ä»ç„¶å­˜åœ¨ï¼Œæˆ–è€…æœ‰ç›¸ä¼¼çš„æ–°æ ‡é¢˜ï¼‰
        target_titles = {node.title for node, _ in node_doc_pairs}
        new_titles = {node.title for node in new_outline.get_all_nodes()}

        # è‡³å°‘åº”è¯¥æœ‰ä¸€äº›ç›®æ ‡èŠ‚ç‚¹çš„æ ‡é¢˜åœ¨æ–°å¤§çº²ä¸­å‡ºç°
        # æˆ–è€…æ–°å¤§çº²ä¸­æœ‰æ˜æ˜¾çš„æ–°èŠ‚ç‚¹ï¼ˆè¯´æ˜è¿›è¡Œäº†æ‰©å±•ï¼‰
        matched_titles = target_titles & new_titles
        if not matched_titles and new_node_count <= old_node_count:
            logger.warning(
                f"Batch refine validation: None of target titles {target_titles} "
                f"found in new outline, and no expansion detected"
            )
            return False

        # éªŒè¯3ï¼šæ£€æŸ¥æ–°å¤§çº²æ˜¯å¦æœ‰æ˜æ˜¾çš„æ‰©å±•ï¼ˆæ–°å¢èŠ‚ç‚¹ï¼‰
        if new_node_count > old_node_count:
            logger.debug(
                f"Batch refine validation passed: outline expanded "
                f"({old_node_count} -> {new_node_count} nodes)"
            )
            return True

        # å¦‚æœä»¥ä¸ŠéªŒè¯éƒ½é€šè¿‡ï¼Œè®¤ä¸ºéªŒè¯æˆåŠŸ
        logger.debug(
            f"Batch refine validation passed: {len(matched_titles)}/{len(target_titles)} "
            f"target titles found in new outline"
        )
        return True



    def compress_under_parent(
        self,
        outline_root: "OutlineNode",
        parent_node: "OutlineNode",
        child_nodes: List["OutlineNode"],
        memory: "Memory" = None,
    ) -> Tuple[
        "OutlineNode",
        List[Tuple["OutlineNode", List["OutlineNode"]]],
        # Dict[str, List["FactStructDocument"]],
        Dict[str, List[str]],
        Dict[str, List[str]],
    ]:
        """
        åœ¨æŒ‡å®šçˆ¶èŠ‚ç‚¹ä¸‹å‹ç¼©å¤šä¸ªç›¸ä¼¼å­èŠ‚ç‚¹

        è¿”å›:
            new_root: å‹ç¼©åçš„å¤§çº²æ ¹èŠ‚ç‚¹
            compressed_nodes_list: [(çˆ¶èŠ‚ç‚¹, [æ–°ç”Ÿæˆå­èŠ‚ç‚¹])]
            new_node_doc_mapping: {æ–°èŠ‚ç‚¹ID: [æ–‡æ¡£åˆ—è¡¨]}
            merged_node_mapping: {æ–°èŠ‚ç‚¹ID: [è¢«å‹ç¼©çš„æ—§èŠ‚ç‚¹IDåˆ—è¡¨]}
        """
        print("len(parent_node.children)",len(parent_node.children))
        print("child_nodes",child_nodes)
        if not parent_node.children:
            logger.info(f"çˆ¶èŠ‚ç‚¹ '{parent_node.title}' æ²¡æœ‰å­èŠ‚ç‚¹ï¼Œè·³è¿‡å‹ç¼©")
            return outline_root, [], {}, {}

        elif len(parent_node.children) <= 2:
            # 1 æˆ– 2 ä¸ªå­èŠ‚ç‚¹ï¼Œè¿›è¡Œç»“æ„æŠ˜å ï¼ˆä¸èµ° LLMï¼‰
            original_children = child_nodes

            # 1ï¸âƒ£ æå‡å­™èŠ‚ç‚¹
            self.flatten_children(parent_node, original_children)

            # 2ï¸âƒ£ æ›´æ–° memory
            merged_docs = []
            merged_child_ids = []

            if memory:
                merged_docs = []
                for child in original_children:
                    doc_ids = memory.node_to_docs.get(child.id, set())
                    if doc_ids:
                        merged_docs.extend(doc_ids)
                        del memory.node_to_docs[child.id]

                if merged_docs:
                    merged_doc_objs = [memory.documents[doc_id] for doc_id in merged_docs if doc_id in memory.documents]
                    memory.map_node_to_docs(parent_node.id, merged_doc_objs)

            logger.info(
                f"çˆ¶èŠ‚ç‚¹ '{parent_node.title}' å­èŠ‚ç‚¹æ•°é‡ä¸º {len(original_children)}ï¼Œå·²è¿›è¡Œç»“æ„æŠ˜å "
            )

            return (
                outline_root,
                [(parent_node, original_children)],
                {parent_node.id: merged_docs},
                {parent_node.id: [child.id for child in original_children]},
            )


        # å¤šå­èŠ‚ç‚¹å‹ç¼©é€»è¾‘
        # 1ï¸âƒ£ æ„é€ å½“å‰å¤§çº²æ–‡æœ¬
        outline_text = outline_root.to_text_tree()

        # 2ï¸âƒ£ æ„é€ å­èŠ‚ç‚¹æè¿°ï¼ˆç®€è¦æ–‡çŒ®ä¿¡æ¯ï¼‰
        children_desc = []
        merged_source_ids = []

        for node in child_nodes:
            merged_source_ids.append(node.id)
            docs = memory.node_to_docs.get(node.id, []) if memory else []

            if docs:
                doc_summaries = []
                for doc in docs:
                    if doc.title:
                        doc_summaries.append(doc.title().strip()) #doc.title.strip()
                    elif doc.text:
                        doc_summaries.append(doc.text[:50].strip() + "â€¦")
                docs_brief = (
                    f"{len(docs)} ç¯‡ç›¸å…³æ–‡çŒ®ï¼Œä¸»é¢˜åŒ…æ‹¬ï¼š" + "ï¼›".join(doc_summaries[:5])
                )
                if len(doc_summaries) > 5:
                    docs_brief += f" ç­‰ï¼ˆå…± {len(doc_summaries)} ä¸ªä¸»é¢˜é”šç‚¹ï¼‰"
            else:
                docs_brief = "æ— ç›´æ¥æ–‡çŒ®ï¼ˆç”±ä¸Šå±‚è¯­ä¹‰æ‹†åˆ†è€Œæ¥ï¼‰"

            children_desc.append(
                f"- å­èŠ‚ç‚¹æ ‡é¢˜: {node.title}\n- æ–‡çŒ®ä¿¡æ¯æ‘˜è¦: {docs_brief}"
            )

        parent_context = parent_node.get_parent_context()
        context_str = f"{parent_context} > {parent_node.title}" if parent_context else parent_node.title



        # 3ï¸âƒ£ æ„é€ å‹ç¼© prompt
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªç ”ç©¶åŠ©æ‰‹ï¼Œæ­£åœ¨å¯¹ç ”ç©¶å¤§çº²è¿›è¡Œ**ç»“æ„å‹ç¼©ä¼˜åŒ–**ã€‚
        ä½ å¿…é¡»å¯¹çˆ¶èŠ‚ç‚¹ä¸‹çš„å­èŠ‚ç‚¹è‡³å°‘æ‰§è¡Œä¸€æ¬¡åˆå¹¶æˆ–å‹ç¼©æ“ä½œï¼Œç”Ÿæˆæ–°çš„å­èŠ‚ç‚¹ã€‚
        æ–°ç”Ÿæˆçš„å­èŠ‚ç‚¹æ ‡é¢˜å¿…é¡»å…·ä½“ä¸”ä¿¡æ¯é‡å……è¶³ï¼Œä¸èƒ½æ²¿ç”¨åŸå­èŠ‚ç‚¹æ ‡é¢˜åŸå°ä¸åŠ¨ã€‚

        ## å½“å‰å¤§çº²
        {outline_text}

        ## å‹ç¼©ç›®æ ‡
        çˆ¶èŠ‚ç‚¹ï¼š{context_str}

        è¯¥çˆ¶èŠ‚ç‚¹ä¸‹å­˜åœ¨å¤šä¸ªè¯­ä¹‰é«˜åº¦ç›¸ä¼¼ã€ä¿¡æ¯é‡åå°‘çš„å­èŠ‚ç‚¹ï¼Œéœ€è¦è¿›è¡Œåˆå¹¶å‹ç¼©ã€‚

        ## å¾…å‹ç¼©å­èŠ‚ç‚¹
        {chr(10).join(children_desc)}

        ## è¦æ±‚
        1. ä½ çš„ä»»åŠ¡æ˜¯å¯¹ã€ŒæŸä¸€çˆ¶èŠ‚ç‚¹ä¸‹çš„å­èŠ‚ç‚¹ã€**ç‹¬ç«‹åœ°**è¿›è¡Œå±€éƒ¨ä¿®æ”¹è¯­ä¹‰å±‚çº§å‹ç¼©ä¸ç»“æ„é‡ç»„ã€‚
        2. å½“å‰çˆ¶èŠ‚ç‚¹çš„å­èŠ‚ç‚¹æ•°é‡ â‰¥ 3ï¼Œå­èŠ‚ç‚¹å‡ä¸ºåŒä¸€è¯­ä¹‰å±‚çº§ï¼Œä¸æ¶‰åŠè·¨çˆ¶èŠ‚ç‚¹è°ƒæ•´ã€‚
        3. åœ¨ä¸ä¸¢å¤±å…³é”®ä¿¡æ¯çš„å‰æä¸‹ï¼Œå¯¹**éƒ¨åˆ†æˆ–å…¨éƒ¨**å­èŠ‚ç‚¹è¿›è¡Œè¯­ä¹‰åˆå¹¶ï¼Œç”Ÿæˆæ–°çš„å­èŠ‚ç‚¹
        ## å­èŠ‚ç‚¹æ•°é‡å‹ç¼©è§„åˆ™ï¼ˆå¼ºçº¦æŸï¼Œå¿…é¡»éµå®ˆï¼‰

        å½“å‰çˆ¶èŠ‚ç‚¹ä¸‹å…±æœ‰ N = {len(children_desc)} ä¸ªå­èŠ‚ç‚¹ã€‚
        å‹ç¼©åçš„å­èŠ‚ç‚¹æ•°é‡å¿…é¡»æ»¡è¶³ä»¥ä¸‹è§„åˆ™ï¼š
        1. å¦‚æœ N = 3 â†’ å¿…é¡»å‹ç¼©ä¸º 2 ä¸ªå­èŠ‚ç‚¹
        2. å¦‚æœ N = 4 â†’ å¿…é¡»å‹ç¼©ä¸º 2 æˆ– 3 ä¸ªå­èŠ‚ç‚¹
        3. å¦‚æœ N â‰¥ 5 â†’ å¿…é¡»å‹ç¼©ä¸º âŒŠN/2âŒ‹ æˆ– âŒˆN/2âŒ‰ ä¸ªå­èŠ‚ç‚¹
        4. æ— è®ºä»»ä½•æƒ…å†µï¼š
        - å­èŠ‚ç‚¹æ•°é‡å¿…é¡» < N
        - å­èŠ‚ç‚¹æ•°é‡å¿…é¡» â‰¥ 2
        - ä¸å…è®¸ä¿ç•™åŸæ•°é‡ä¸å˜
        - ä¸å…è®¸å‹ç¼©ä¸º 1 ä¸ª

        å¦‚æœä½ çš„è¾“å‡ºä¸æ»¡è¶³ä¸Šè¿°æ•°é‡è§„åˆ™ï¼Œåˆ™è§†ä¸ºç»“æ„é”™è¯¯ã€‚
        ä½ å¿…é¡»åœ¨è¯­ä¹‰åˆç†çš„å‰æä¸‹ï¼Œé€šè¿‡åˆå¹¶æ“ä½œï¼Œä½¿æœ€ç»ˆå­èŠ‚ç‚¹æ•°é‡ä¸¥æ ¼ç¬¦åˆè§„åˆ™ã€‚
        4. å‹ç¼©åçš„æ–°çš„å­èŠ‚ç‚¹ä¹‹é—´åº”è¯¥æ˜¯å¹¶åˆ—å…³ç³»ï¼Œè¦†ç›–è¯¥ä¸»é¢˜çš„ä¸åŒæ–¹é¢ï¼Œè€Œä¸æ˜¯å±‚å±‚åµŒå¥—ï¼Œæ–°ç”Ÿæˆçš„å­èŠ‚ç‚¹éœ€è¦åœ¨è¯­ä¹‰ä¸Šå®Œæ•´è¦†ç›–å…¶æ‰€åˆå¹¶çš„åŸå­èŠ‚ç‚¹çš„æ ¸å¿ƒä¿¡æ¯
        5. ä»…å…è®¸ä¿®æ”¹å½“å‰çˆ¶èŠ‚ç‚¹çš„å­èŠ‚ç‚¹ï¼Œå­èŠ‚ç‚¹å¿…é¡»è¦æ˜¯å¶å­èŠ‚ç‚¹ï¼Œéå¶å­èŠ‚ç‚¹ä¸å‚ä¸åˆå¹¶ï¼Œçˆ¶èŠ‚ç‚¹ä¹‹å¤–çš„ä»»ä½•èŠ‚ç‚¹ç»“æ„ã€é¡ºåºã€å±‚çº§å‡ä¸å¾—ä¿®æ”¹ã€‚çˆ¶èŠ‚ç‚¹çš„title ä¸èƒ½æ›´æ”¹
        6. åˆå¹¶åï¼Œçˆ¶èŠ‚ç‚¹ä¸‹ä»…ä¿ç•™ï¼Œæ–°ç”Ÿæˆçš„å­èŠ‚ç‚¹ï¼Œä»¥åŠæœªå‚ä¸åˆå¹¶çš„åŸå§‹å­èŠ‚ç‚¹ï¼Œæœªå‚ä¸åˆå¹¶çš„å­èŠ‚ç‚¹ï¼Œå…¶æ ‡é¢˜ä¸è¯­ä¹‰éœ€ä¿æŒä¸å˜
        7. **å…³é”®**ï¼šæ¯ä¸ªæ–°ç”Ÿæˆçš„å­èŠ‚ç‚¹æ ‡é¢˜å¿…é¡»èƒ½å¤Ÿåœ¨å¯¹åº”çš„"æ–°ä¿¡æ¯"æ–‡æ¡£ä¸­æ‰¾åˆ°æ˜ç¡®çš„å†…å®¹æ”¯æ’‘ï¼Œä¸è¦ç”Ÿæˆä¸æ–‡æ¡£å†…å®¹æ— å…³çš„ç©ºæ³›æ ‡é¢˜ã€‚å­èŠ‚ç‚¹æ ‡é¢˜åº”è¯¥å…·ä½“ã€æœ‰ä¿¡æ¯é‡ï¼Œèƒ½å¤Ÿç›´æ¥å¯¹åº”åˆ°æŸä¸ªæ–‡æ¡£çš„æ ¸å¿ƒå†…å®¹
        8. è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯ JSONï¼Œç»“æ„å¦‚ä¸‹ï¼š
        {{
            "title": "æ ¹èŠ‚ç‚¹æ ‡é¢˜",
            "children": [
                {{
                    "title": "å­èŠ‚ç‚¹1æ ‡é¢˜",
                    "children": []
                }},
                {{
                    "title": "å­èŠ‚ç‚¹2æ ‡é¢˜ï¼ˆè¢«æ‰©å±•çš„å¶å­èŠ‚ç‚¹ï¼‰",
                    "children": [
                        {{
                            "title": "å¹¶åˆ—å­èŠ‚ç‚¹A",
                            "children": []
                        }},
                        {{
                            "title": "å¹¶åˆ—å­èŠ‚ç‚¹B",
                            "children": []
                        }},
                        {{
                            "title": "å¹¶åˆ—å­èŠ‚ç‚¹C",
                            "children": []
                        }}
                    ]
                }}
            ]
        }}

        è¯·åªè¾“å‡º JSONï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šæ€§æ–‡å­—ã€‚è¾“å‡ºå®Œæ•´çš„ä¿®è®¢åå¤§çº²æ ‘ã€‚"""


        try:
            logger.info(f"compress_under_parent prompt:\n{prompt}")
            messages = [HumanMessage(content=prompt)]
            response = self.llm.invoke(messages)
            content = response.content.strip()
            logger.info(f"content{content}")
            # 4ï¸âƒ£ è§£æ JSON å¹¶é‡å»ºå¤§çº²æ ‘
            json_str = self._extract_json(content)
            outline_data = json.loads(json_str)
            # new_root = self._build_outline_tree(outline_data, parent=None, node_counter=[0])
            new_root = self._build_outline_tree(outline_data, parent=None)
            # ç»§æ‰¿ MAB çŠ¶æ€
            new_node_ids = []
            self._inherit_mab_state_for_existing_nodes(outline_root, new_root, new_node_ids=new_node_ids)
            #åŸç‰ˆæœ¬
            # self._inherit_mab_state_for_existing_nodes(outline_root, new_root)

            # æ‰¾åˆ°å‹ç¼©åçš„çˆ¶èŠ‚ç‚¹åŠå…¶æ–°å­èŠ‚ç‚¹
            def get_node_path(node):
                path_parts = []
                current = node
                while current is not None:
                    path_parts.insert(0, current.title)
                    current = current.parent
                return " > ".join(path_parts)

            def find_node_by_path(root, target_path):
                for node in root.get_all_nodes():
                    if get_node_path(node) == target_path:
                        return node
                return None
            
            # 5ï¸âƒ£ æ‰¾åˆ°å‹ç¼©åçš„çˆ¶èŠ‚ç‚¹åŠå…¶æ–°å­èŠ‚ç‚¹
            target_path = get_node_path(parent_node)
            new_parent = find_node_by_path(new_root, target_path)
            # new_parent = new_root.find_node_by_path(parent_node.get_path_titles())
            if not new_parent:
                logger.warning("Parent node not found after compression")
                return outline_root, [], {}, {}

            # new_children = new_parent.children or []
            new_children = []
            # new_node_ids æ˜¯ id åˆ—è¡¨
            for node_id in new_node_ids:
                node = new_root.find_node_by_id(node_id)
                if node:
                    new_children.append(node)
                else:
                    logger.warning(f"Node with id {node_id} not found in new_root")

            compressed_nodes_list = [(new_parent, new_children)]

            # 6ï¸âƒ£ æ„å»º merged_node_mapping å’Œ new_node_doc_mapping
            merged_node_mapping = {}
            new_node_doc_mapping = {}
            for child in new_children:
                merged_node_mapping[child.id] = merged_source_ids
                merged_docs = []
                for old_id in merged_source_ids:
                    merged_docs.extend(memory.node_to_docs.get(old_id, []))
                if merged_docs:
                    new_node_doc_mapping[child.id] = merged_docs

        
            logger.info(f"Compression success: { len(parent_node.children)} -> {len(new_children)} nodes")
            return new_root, compressed_nodes_list, new_node_doc_mapping, merged_node_mapping

        except Exception as e:
            import traceback
            logger.error(f"Failed to compress under parent '{parent_node.title}': {e}")
            logger.error(traceback.format_exc())
            return outline_root, [], {}, {}


    def flatten_children(self,parent_node, child_nodes):
        """
        å°† child_nodes çš„å­èŠ‚ç‚¹ï¼ˆå­™èŠ‚ç‚¹ï¼‰æå‡ä¸º parent_node çš„ childrenã€‚
        å¦‚æœæ‰€æœ‰ child éƒ½æ²¡æœ‰ childrenï¼Œåˆ™ parent_node å˜ä¸ºå¶å­èŠ‚ç‚¹ã€‚
        """
        new_children = []

        for child in child_nodes:
            if child.children:
                new_children.extend(child.children)

        parent_node.children = new_children  # å¯èƒ½æ˜¯ []ï¼Œè¿™æ˜¯åˆæ³•çš„


    def update_under_parent(
        self,
        outline_root: "OutlineNode",
        parent_node: "OutlineNode",
        child_nodes: List["OutlineNode"],
        memory: "Memory" = None,
    ) -> Tuple[
        "OutlineNode",
        List[Tuple["OutlineNode", List["OutlineNode"]]],
        # Dict[str, List["FactStructDocument"]],
        Dict[str, List[str]],
        Dict[str, List[str]],
    ]:
        """
        Update æŒ‡å®šçˆ¶èŠ‚ç‚¹ï¼ˆä¸åŒäº compressionï¼‰
        
        è§„åˆ™ï¼š
        - è‹¥å­èŠ‚ç‚¹æ•° == 0 â†’ å…è®¸ä¿®æ”¹çˆ¶èŠ‚ç‚¹æ ‡é¢˜
        - è‹¥å­èŠ‚ç‚¹æ•° > 0 â†’ ä¸å…è®¸æ”¹å˜ç»“æ„ï¼Œåªå…è®¸æ›´æ–°æ ‡é¢˜/è¯­ä¹‰
        """
        logger.info(f"Running update_under_parent on '{parent_node.title}'")
        logger.info(f"Children count: {len(parent_node.children)}")
        
        # ================================
        # ğŸŸ¢ æƒ…å†µ 1ï¼šæ²¡æœ‰å­èŠ‚ç‚¹
        # ================================
        if len(parent_node.children) == 0:
        
            logger.info(f"çˆ¶èŠ‚ç‚¹ '{parent_node.title}' æ²¡æœ‰å­èŠ‚ç‚¹ï¼Œè·³è¿‡æ ‡é¢˜ä¿®æ”¹")
            
            # åªæ›´æ–°æ–‡æ¡£æ˜ å°„,æ–‡æ¡£æ˜ å°„åº”è¯¥ä¹Ÿä¸ç”¨ï¼Œå·²ç»åœ¨å¤–é¢çš„å‡½æ•°é‡Œåšäº†
            # merged_docs = []
            # if memory:
            #     for doc in new_docs:
            #         merged_docs.append(doc)
            #     if merged_docs:
            #         memory.map_node_to_docs(parent_node.id, merged_docs)

            updated_nodes_list = [(parent_node, [])]

            # æ›´æ–°åçš„èŠ‚ç‚¹æ˜ å°„
            updated_node_mapping = {parent_node.id: []}

            # æ–‡æ¡£æ˜ å°„
            # new_node_doc_mapping = {parent_node.id: merged_docs}
            # merged_docs: List[FactStructDocument]

            # doc_ids = [doc.id for doc in merged_docs]
            doc_ids=[]
            new_node_doc_mapping = {parent_node.id: doc_ids}

            logger.info(f"Update success: '{parent_node.title}' (no children)")

            return (
                outline_root,
                updated_nodes_list,
                new_node_doc_mapping,
                updated_node_mapping,
            )

        # ================================
        # ğŸŸ¢ æƒ…å†µ 2ï¼šå­˜åœ¨å­èŠ‚ç‚¹
        # ================================

        outline_text = outline_root.to_text_tree()

        # æ„é€ è¾“å…¥æ–‡æ¡£çš„æ–‡æ¡£æ‘˜è¦
        # doc_desc = []
        # for doc in new_docs:
        #     if doc.title and doc.text:
        #         doc_desc.append("æ ‡é¢˜"+doc.title.strip()+"å†…å®¹"+doc.text[:100].strip() + "â€¦")
        #     elif doc.text:
        #         doc_desc.append(doc.text[:100].strip() + "â€¦")

        # new_docs_brief = "\n".join(f"- {d}" for d in doc_desc[:10])
        # if not new_docs:
        #     new_docs_brief = "æ— æ–°å¢æ–‡æ¡£"

        parent_context = parent_node.get_parent_context()
        context_str = (
            f"{parent_context} > {parent_node.title}"
            if parent_context
            else parent_node.title
        )

        children_titles = [c.title for c in parent_node.children]
        # 2ï¸âƒ£ æ„é€ å­èŠ‚ç‚¹æè¿°ï¼ˆç®€è¦æ–‡çŒ®ä¿¡æ¯ï¼‰
        children_desc = []
        merged_source_ids = []

        for node in child_nodes:
            merged_source_ids.append(node.id)
            docs = memory.node_to_docs.get(node.id, []) if memory else []

            if docs:
                doc_summaries = []
                for doc in docs:
                    if doc.title:
                        doc_summaries.append(doc.title().strip())   # âš  ä¿®æ­£è¿™é‡Œ
                    elif doc.text:
                        doc_summaries.append(doc.text[:50].strip() + "â€¦")

                docs_brief = (
                    f"{len(docs)} ç¯‡ç›¸å…³æ–‡çŒ®ï¼Œä¸»é¢˜åŒ…æ‹¬ï¼š" + "ï¼›".join(doc_summaries[:5])
                )

                if len(doc_summaries) > 5:
                    docs_brief += f" ç­‰ï¼ˆå…± {len(doc_summaries)} ä¸ªä¸»é¢˜é”šç‚¹ï¼‰"

            else:
                docs_brief = "æ— ç›´æ¥æ–‡çŒ®ï¼ˆç”±ä¸Šå±‚è¯­ä¹‰æ‹†åˆ†è€Œæ¥ï¼‰"

            children_desc.append(
                f"- å­èŠ‚ç‚¹æ ‡é¢˜: {node.title}\n  æ–‡çŒ®ä¿¡æ¯æ‘˜è¦: {docs_brief}"
            )


            # 3ï¸âƒ£ æ„é€ å‹ç¼© prompt
            prompt = f"""
            ä½ æ˜¯ç ”ç©¶åŠ©æ‰‹ï¼Œéœ€è¦æ ¹æ®æ–°å¢æ–‡æ¡£å¯¹ç ”ç©¶å¤§çº²è¿›è¡Œã€å±€éƒ¨è¯­ä¹‰å¼ºåŒ–æ›´æ–°ã€‘ã€‚
            
            âš  æœ¬ä»»åŠ¡ä¸æ˜¯å‹ç¼©ï¼Œä¹Ÿä¸æ˜¯æ‰©å±•ï¼Œè€Œæ˜¯åœ¨ä¿æŒç»“æ„å®Œå…¨ä¸å˜çš„å‰æä¸‹ï¼Œå¯¹ç°æœ‰å­èŠ‚ç‚¹è¿›è¡Œ

            ## å½“å‰å®Œæ•´å¤§çº²
            {outline_text}

            ## ç›®æ ‡çˆ¶èŠ‚ç‚¹
            {context_str}
            è¯¥çˆ¶èŠ‚ç‚¹ä¸‹å­˜åœ¨å¤šä¸ªè¯­ä¹‰é«˜åº¦ç›¸ä¼¼ã€ä¿¡æ¯é‡åå°‘çš„å­èŠ‚ç‚¹ï¼Œéœ€è¦è¿›è¡Œåˆå¹¶å‹ç¼©ã€‚

            ## å½“å‰å­èŠ‚ç‚¹åŠå…¶æ”¯æ’‘æ–‡çŒ®
            {chr(10).join(children_desc)}


            ---
            ## å¼ºçº¦æŸè§„åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰

            1. ä¸å…è®¸å¢åŠ å­èŠ‚ç‚¹æ•°é‡
            2. ä¸å…è®¸å‡å°‘å­èŠ‚ç‚¹æ•°é‡
            3. ä¸å…è®¸æ”¹å˜å±‚çº§ç»“æ„
            4. ä¸å…è®¸ä¿®æ”¹çˆ¶èŠ‚ç‚¹æ ‡é¢˜
            5. åªå…è®¸ä¿®æ”¹å½“å‰çˆ¶èŠ‚ç‚¹ä¸‹çš„ã€å¶å­å­èŠ‚ç‚¹æ ‡é¢˜ã€‘
            6. è‡³å°‘å¿…é¡»ä¿®æ”¹ 1 ä¸ªå­èŠ‚ç‚¹æ ‡é¢˜ï¼ˆä¸å¯å…¨éƒ¨ä¿æŒä¸å˜ï¼‰
            7. ä¿®æ”¹å¿…é¡»åŸºäºæ–°å¢æ–‡æ¡£å†…å®¹
            8. æ›´æ–°åçš„å­èŠ‚ç‚¹æ ‡é¢˜å¿…é¡»æ›´å…·ä½“ã€æ›´å…·ä¿¡æ¯é‡
            9. ä¸å…è®¸ç”Ÿæˆä¸æ–‡æ¡£æ— å…³çš„ç©ºæ³›æ¦‚æ‹¬æ ‡é¢˜
            10. è¾“å‡ºå®Œæ•´ JSON æ ‘

            å¦‚æœä½ çš„è¾“å‡ºä¸åŸç»“æ„å®Œå…¨ä¸€è‡´ï¼Œåˆ™è§†ä¸ºé”™è¯¯ã€‚
            {{
                "title": "æ ¹èŠ‚ç‚¹æ ‡é¢˜",
                "children": [
                    {{
                        "title": "å­èŠ‚ç‚¹1æ ‡é¢˜",
                        "children": []
                    }},
                    {{
                        "title": "å­èŠ‚ç‚¹2æ ‡é¢˜ï¼ˆè¢«æ‰©å±•çš„å¶å­èŠ‚ç‚¹ï¼‰",
                        "children": [
                            {{
                                "title": "å¹¶åˆ—å­èŠ‚ç‚¹A",
                                "children": []
                            }},
                            {{
                                "title": "å¹¶åˆ—å­èŠ‚ç‚¹B",
                                "children": []
                            }},
                            {{
                                "title": "å¹¶åˆ—å­èŠ‚ç‚¹C",
                                "children": []
                            }}
                        ]
                    }}
                ]
            }}

            è¯·åªè¾“å‡º JSONï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šæ€§æ–‡å­—ã€‚è¾“å‡ºå®Œæ•´çš„ä¿®è®¢åå¤§çº²æ ‘ã€‚"""



        try:
            logger.info(f"update_under_parent prompt:\n{prompt}")

            messages = [HumanMessage(content=prompt)]
            response = self.llm.invoke(messages)
            content = response.content.strip()
            logger.info(f"content{content}")
            json_str = self._extract_json(content)
            outline_data = json.loads(json_str)

            new_root = self._build_outline_tree(outline_data, parent=None)

            # ç»§æ‰¿ MAB çŠ¶æ€
            new_node_ids = []
            self._inherit_mab_state_for_existing_nodes(
                outline_root, new_root, new_node_ids=new_node_ids
            )
            logger.info(f"new_node_ids{new_node_ids}")
            # ========= è·¯å¾„å·¥å…·å‡½æ•° =========
            def get_node_path(node):
                path_parts = []
                current = node
                while current is not None:
                    path_parts.insert(0, current.title)
                    current = current.parent
                return " > ".join(path_parts)

            def find_node_by_path(root, target_path):
                for node in root.get_all_nodes():
                    if get_node_path(node) == target_path:
                        return node
                return None


            # ========= æ‰¾æ›´æ–°åçš„çˆ¶èŠ‚ç‚¹ =========
            target_path = get_node_path(parent_node)
            new_parent = find_node_by_path(new_root, target_path)

            if not new_parent:
                logger.warning("Parent node not found after update")
                return outline_root, [], {}, {}

            # ========= ç”¨ new_node_ids æ‰¾åˆ°æ›´æ–°åçš„å­èŠ‚ç‚¹ =========
            new_children = []

            for node_id in new_node_ids:
                node = new_root.find_node_by_id(node_id)
                if node:
                    new_children.append(node)
                else:
                    logger.warning(f"Node with id {node_id} not found in new_root")

            updated_nodes_list = [(new_parent, new_children)]
            logger.info(f"new_children{new_children}")
            # ========= æ„å»º updated_node_mapping =========
            # update æ˜¯ 1 å¯¹ 1 è¯­ä¹‰å¢å¼º
            # new_node_ids å’Œ old_child_ids åº”è¯¥ç­‰é•¿
            old_child_ids = [child.id for child in parent_node.children]

            updated_node_mapping = {}
            new_node_doc_mapping = {}
            # new_doc_ids = [doc.id for doc in new_docs] if new_docs else []
            for child in new_children:
                updated_node_mapping[child.id] = merged_source_ids
                merged_docs = []
                for old_id in merged_source_ids:
                    merged_docs.extend(memory.node_to_docs.get(old_id, []))
                
                # all_docs = merged_docs + new_doc_ids
                if merged_docs:#all_docs:
                    new_node_doc_mapping[child.id] = merged_docs
                    # new_node_doc_mapping[child.id] = all_docs


            logger.info(
                f"Update success: {len(old_child_ids)} -> {len(new_children)} nodes under '{parent_node.title}'"
            )

            return (
                new_root,
                updated_nodes_list,
                new_node_doc_mapping,
                updated_node_mapping,
            )



        except Exception as e:
            import traceback
            logger.error(
                f"Failed to update under parent '{parent_node.title}': {e}"
            )
            logger.error(traceback.format_exc())
            return outline_root, [], {}, {}





if __name__ == "__main__":
    """
    ä½¿ç”¨çœŸå® Memory + çœŸå® Outline æµ‹è¯• compress_under_parent
    æµ‹è¯•åœºæ™¯ï¼š
    å‹ç¼© â€œä¸­æ€§ç²’ç»†èƒåœ¨è„‘ç¼ºè¡€æ€¥æ€§æœŸçš„ä½œç”¨â€ ä¸‹çš„ 4 ä¸ªå­èŠ‚ç‚¹
    """

    from src.factstruct.memory import Memory
    from src.factstruct.document import FactStructDocument

    print("========== START REAL DEBUG ==========")

    # -----------------------
    # 1ï¸âƒ£ æ„é€ çœŸå® Memory
    # -----------------------
    memory = Memory()

    # åˆ›å»º 3 ä¸ªæµ‹è¯•æ–‡æ¡£
    from datetime import datetime

    doc1 = FactStructDocument(
        id="doc_1",
        cite_id="CIT001",
        source_type="journal",
        title="ä¸­æ€§ç²’ç»†èƒå‹Ÿé›†æœºåˆ¶ç ”ç©¶",
        text="æ€¥æ€§æœŸä¸­æ€§ç²’ç»†èƒé€šè¿‡è¶‹åŒ–å› å­è¢«å‹Ÿé›†åˆ°ç¼ºè¡€åŒºåŸŸã€‚",
        embedding=None,
        timestamp=datetime.now()
    )

    doc2 = FactStructDocument(
        id="doc_2",
        cite_id="CIT002",
        source_type="journal",
        title="è¡€è„‘å±éšœç ´åæœºåˆ¶",
        text="ä¿ƒç‚å› å­é‡Šæ”¾å¯¼è‡´è¡€è„‘å±éšœé€šé€æ€§å¢åŠ ã€‚",
        embedding=None,
        timestamp=datetime.now()
    )

    doc3 = FactStructDocument(
        id="doc_3",
        cite_id="CIT003",
        source_type="journal",
        title="ç‚ç—‡ä¸ç¥ç»æŸä¼¤",
        text="ç‚ç—‡ååº”åŠ å‰§è„‘æ°´è‚¿ä¸ç¥ç»æŸä¼¤ã€‚",
        embedding=None,
        timestamp=datetime.now()
    )


    # -----------------------
    # 2ï¸âƒ£ æ„é€ çœŸå® Outline
    # -----------------------
    root = OutlineNode(
        id="node_0",
        title="ä¸­æ€§ç²’ç»†èƒåœ¨è„‘ç¼ºè¡€ä¸­çš„ä½œç”¨",
        pull_count=2,
        reward_history=[0.8, 0.9],
        word_limit=500
    )

    acute = OutlineNode(
        id="node_1",
        title="ä¸­æ€§ç²’ç»†èƒåœ¨è„‘ç¼ºè¡€æ€¥æ€§æœŸçš„ä½œç”¨",
        pull_count=1,
        reward_history=[0.7],
        word_limit=300
    )

    n3 = OutlineNode(
        id="node_2",
        title="ä¸­æ€§ç²’ç»†èƒçš„å‹Ÿé›†ä¸æ¿€æ´»æœºåˆ¶",
        pull_count=0,
        reward_history=[],
        word_limit=100
    )
    n4 = OutlineNode(
        id="node_3",
        title="ä¿ƒç‚å› å­é‡Šæ”¾ä¸è¡€-è„‘å±éšœç ´å",
        pull_count=0,
        reward_history=[],
        word_limit=100
    )
    n5 = OutlineNode(
        id="node_4",
        title="ç‚ç—‡ååº”å¯¹è„‘æ°´è‚¿ä¸ç¥ç»æŸä¼¤çš„å½±å“",
        pull_count=0,
        reward_history=[],
        word_limit=100
    )
    n6 = OutlineNode(
        id="node_5",
        title="ä¸­æ€§ç²’ç»†èƒåœ¨ç¥ç»ä¿®å¤ä¸­çš„æ½œåœ¨ä½œç”¨",
        pull_count=0,
        reward_history=[],
        word_limit=100
    )


    acute.add_child(n3)
    acute.add_child(n4)
    acute.add_child(n5)
    acute.add_child(n6)

    root.add_child(acute)

    # -----------------------
    # 3ï¸âƒ£ å»ºç«‹çœŸå®èŠ‚ç‚¹-æ–‡æ¡£æ˜ å°„
    # -----------------------
    memory.map_node_to_docs("node_3", [doc1])
    memory.map_node_to_docs("node_4", [doc2])
    memory.map_node_to_docs("node_3", [doc3])

    print("\n--- BEFORE ---")
    # print(root.to_text_tree())
    print(root.to_text_tree(include_word_limit=True,include_mab_state=True))
    print("Memory node_to_docs:", memory.node_to_docs)

    # -----------------------
    # 4ï¸âƒ£ åˆ›å»º wrapper
    # -----------------------
    # wrapper = FactStructLLMWrapper(llm=None)
    # === LLM ===
    from src.config.agents import AGENT_LLM_MAP
    from src.llms.llm import get_llm_by_type
    llm_type = AGENT_LLM_MAP.get("outline", "basic")
    llm = get_llm_by_type(llm_type)

    wrapper = FactStructLLMWrapper(llm)
    wrapper._inherit_mab_state_for_existing_nodes(old_root=None, new_root=root)
    # -----------------------
    # 5ï¸âƒ£ æµ‹è¯• 2 å­èŠ‚ç‚¹æŠ˜å ï¼ˆä¸èµ° LLMï¼‰
    # åªå‹ç¼© node_8 å’Œ node_9
    # -----------------------
    # new_root, compressed_list, new_doc_map, merged_map = wrapper.compress_under_parent(
    #     outline_root=root,
    #     parent_node=acute,
    #     child_nodes=[n3, n4],
    #     memory=memory,
    # )

    # print("\n--- AFTER STRUCTURE ---")
    # print(new_root.to_text_tree(include_word_limit=True,include_mab_state=True))

    # print("\nCompressed list:")
    # for p, children in compressed_list:
    #     print("Parent:", p.title)
    #     print("Affected children:", [c.title for c in children])

    # print("\nNew node doc mapping:", new_doc_map)
    # print("Merged node mapping:", merged_map)

    # print("\nMemory after compression:")
    # print(memory.node_to_docs)

    # # -----------------------
    # # 6ï¸âƒ£ éªŒè¯ç»“æ„å®Œæ•´æ€§
    # # -----------------------
    # def validate_tree(node):
    #     for child in node.children:
    #         assert child.parent == node, f"Parent pointer broken at {child.title}"
    #         validate_tree(child)

    # validate_tree(new_root)

    # print("\nâœ… Tree structure valid.")
    # print("========== END DEBUG ==========")


    # -----------------------
    # 5ï¸âƒ£ æµ‹è¯• update_under_parent
    # -----------------------

    print("\n========== TEST UPDATE ==========")

    # æ„é€ æ–°å¢æ–‡æ¡£ï¼ˆæ¨¡æ‹Ÿ retrieval æ–°ç»“æœï¼‰
    from datetime import datetime

    new_doc = FactStructDocument(
        id="doc_4",
        cite_id="CIT004",
        source_type="journal",
        title="æ€¥æ€§æœŸç‚ç—‡çº§è”ååº”ç ”ç©¶",
        text="ä¸­æ€§ç²’ç»†èƒé‡Šæ”¾NETså¹¶æ¿€æ´»ç‚ç—‡çº§è”ååº”ã€‚",
        embedding=None,
        timestamp=datetime.now()
    )

    # æ³¨æ„ï¼šupdate ç‰ˆæœ¬ä¸åº”è¯¥ç›´æ¥æ”¹ memory
    # åªä¼ å…¥ parent + memory + ç”±å‡½æ•°è¿”å› new_doc_map

    new_root, updated_list, new_doc_map, updated_node_map = wrapper.update_under_parent(
        outline_root=root,
        parent_node=acute,      # æµ‹è¯•æœ‰å­èŠ‚ç‚¹æƒ…å†µ
        child_nodes=acute.children,
        memory=memory,
    )

    print("\n--- AFTER UPDATE STRUCTURE ---")
    print(new_root.to_text_tree(include_word_limit=True, include_mab_state=True))

    print("\nUpdated list:")
    for p, children in updated_list:
        print("Parent:", p.title)
        print("Children:", [c.title for c in children])

    print("\nNew node doc mapping:", new_doc_map)
    print("Updated node mapping:", updated_node_map)

    print("\n========== TEST UPDATE (NO CHILDREN) ==========")

    leaf_node = n6   # node_6 æ²¡æœ‰å­èŠ‚ç‚¹

    new_root2, updated_list2, new_doc_map2, updated_node_map2 = wrapper.update_under_parent(
        outline_root=new_root,
        parent_node=leaf_node,
        child_nodes=[],
        memory=memory,
    )

    print("\n--- AFTER UPDATE (NO CHILDREN) ---")
    print(new_root2.to_text_tree(include_word_limit=True, include_mab_state=True))

    print("\nNew node doc mapping:", new_doc_map2)
    print("Updated node mapping:", updated_node_map2)
